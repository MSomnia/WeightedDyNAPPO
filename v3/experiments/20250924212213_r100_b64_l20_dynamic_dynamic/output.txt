======================================================================
RUNNING IMPROVED DyNA PPO WITH BETTER SURROGATE LEARNING
======================================================================
======================================================================
IMPROVED DyNA PPO ALGORITHM
======================================================================
Configuration:
  Number of experiment rounds N = 100
  Number of model-based training rounds M = 5
  Minimum model score τ = 0.2
  Batch size B = 64
  Warm-up phase: True
  Surrogate model method: dynamic
======================================================================

=== WARM-UP PHASE ===
Generating 50 warm-up samples...
Warm-up statistics:
  Mean reward: 11.865
  Std reward: 3.605
  Min/Max: 0.000 / 16.407

Pre-training surrogate models on warm-up data...

Training on 46 samples (removed 4 outliers)
Reward range: [7.39, 16.41], mean: 12.72
  Created 8 candidate models for data size 46
Current R2 threshold: -0.3
  rf-xs: R2 = -0.176 (std: 0.298)
  rf-s: R2 = -0.097 (std: 0.325)
  knn-xs: R2 = -0.147 (std: 0.123)
  knn-s: R2 = -0.147 (std: 0.123)
  ridge: R2 = -0.252 (std: 0.388)
  gb-xs: R2 = -0.364 (std: 0.460)
  gp: R2 = -45.380 (std: 11.700)
  svr-rbf-s: R2 = -0.262 (std: 0.547)
Initial models trained: 6
Initial R2 scores - Mean: -5.853, Max: -0.097

======================================================================
EXPERIMENT ROUND 1/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.300
Total data collected: 50

--- Round 1 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0200
Exploration rate: 0.300

--- Generated Sequences (Diversity: 1.000) ---
  GTCACGGATATTTTCGAGGT
  GGGCGATACCCCTAACAAAC
  TGCGCACACGATTTCATACC
  CGTCCCGTATTTGGACACTT
  ATTAAGTCAATACAAGCGCT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.248
  Max reward: 17.241
  With intrinsic bonuses: 13.264

Policy Update:
  Adaptive update: clip_ratio=0.30, entropy_coef=0.020
    Epoch 0: policy_loss=-0.0000, value_loss=0.9796, entropy=1.3836, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0812

=== Surrogate Model Training ===
Total samples: 114

Training on 107 samples (removed 7 outliers)
Reward range: [8.46, 16.93], mean: 13.18
  Created 11 candidate models for data size 107
Current R2 threshold: -0.3
  rf-m: R2 = -0.122 (std: 0.236)
  rf-l: R2 = -0.102 (std: 0.251)
  gb-m: R2 = -0.298 (std: 0.280)
  gb-l: R2 = -0.297 (std: 0.269)
  xgb-m: R2 = -0.336 (std: 0.417)
  knn-m: R2 = -0.046 (std: 0.318)
  knn-tuned: R2 = -0.046 (std: 0.318)
  mlp-m: R2 = -3.863 (std: 1.815)
  svr-rbf: R2 = 0.003 (std: 0.173)
  svr-poly: R2 = 0.003 (std: 0.173)
  ridge: R2 = -0.112 (std: 0.186)

Model-based training with 9 models
Best R2: 0.003, Mean R2: -0.474
Running 3 virtual training rounds
Current Method: dynamic
    Using uniform weights (insufficient data)
  Adaptive update: clip_ratio=0.30, entropy_coef=0.010
    Epoch 0: policy_loss=0.0000, value_loss=0.9856, entropy=1.3824, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0755
  Round 1/3: Mean predicted reward = 13.267
Current Method: dynamic
    Using uniform weights (insufficient data)
  Adaptive update: clip_ratio=0.30, entropy_coef=0.010
    Epoch 0: policy_loss=-0.0000, value_loss=0.9868, entropy=1.3789, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1012
  Round 2/3: Mean predicted reward = 13.185
Current Method: dynamic
    Using uniform weights (insufficient data)
  Adaptive update: clip_ratio=0.30, entropy_coef=0.010
    Epoch 0: policy_loss=0.0000, value_loss=0.9850, entropy=1.3729, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1329
  Round 3/3: Mean predicted reward = 13.177

  === Progress Analysis ===
  Status: NORMAL

--- Round 1 Results ---
  Mean Oracle Reward: 13.218
  Min Oracle Reward: 9.088
  Max Oracle Reward: 17.345
  Std Oracle Reward: 1.782
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -0.474, Max: 0.003, Count: 11
  New best mean reward!
  Total Sequences Evaluated: 114
    Oracle Count: 64 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}]

======================================================================
EXPERIMENT ROUND 2/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.300
Total data collected: 114

--- Round 2 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0200
Exploration rate: 0.300

--- Generated Sequences (Diversity: 1.000) ---
  TTGAATCGGCAAGACCTTCC
  GTGTTGTCAGGTCGTGTGGA
  TGCAGGTTGGGTATGTCATC
  ACGCTGCCGAACGTTATAAC
  GTGAACGTCGACTCGTTCCT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.694
  Max reward: 16.884
  With intrinsic bonuses: 13.669

Policy Update:
  Adaptive update: clip_ratio=0.30, entropy_coef=0.020
    Epoch 0: policy_loss=0.0000, value_loss=0.9834, entropy=1.3642, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1214

=== Surrogate Model Training ===
Total samples: 178

Training on 169 samples (removed 9 outliers)
Reward range: [9.19, 16.97], mean: 13.44
  Created 11 candidate models for data size 169
Current R2 threshold: -0.3
  rf-m: R2 = -0.320 (std: 0.292)
  rf-l: R2 = -0.288 (std: 0.305)
  gb-m: R2 = -0.417 (std: 0.384)
  gb-l: R2 = -0.415 (std: 0.386)
  xgb-m: R2 = -0.532 (std: 0.514)
  knn-m: R2 = -0.384 (std: 0.255)
  knn-tuned: R2 = -0.384 (std: 0.255)
  mlp-m: R2 = -3.517 (std: 1.577)
  svr-rbf: R2 = -0.139 (std: 0.199)
  svr-poly: R2 = -0.139 (std: 0.199)
  ridge: R2 = -0.226 (std: 0.213)

Model-based training with 4 models
Best R2: -0.139, Mean R2: -0.615
Running 2 virtual training rounds
Current Method: dynamic
    Using uniform weights (insufficient data)
  Adaptive update: clip_ratio=0.30, entropy_coef=0.010
    Epoch 0: policy_loss=-0.0000, value_loss=0.9843, entropy=1.3571, kl_div=0.0000
  Round 1/2: Mean predicted reward = 13.741
Current Method: dynamic
    Using uniform weights (insufficient data)
  Adaptive update: clip_ratio=0.30, entropy_coef=0.010
    Epoch 0: policy_loss=0.0000, value_loss=0.9856, entropy=1.3490, kl_div=0.0000
  Round 2/2: Mean predicted reward = 13.746

  === Progress Analysis ===
  Status: WARNING
  • R2 scores negative. Models struggling to learn. Try collecting more diverse data.

--- Round 2 Results ---
  Mean Oracle Reward: 13.673
  Min Oracle Reward: 6.093
  Max Oracle Reward: 17.208
  Std Oracle Reward: 1.642
  Sequence Diversity: 1.000
  Models Used: 4
  Model R2 - Mean: -0.615, Max: -0.139, Count: 11
  New best mean reward!
  Total Sequences Evaluated: 178
    Oracle Count: 128 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}]

======================================================================
EXPERIMENT ROUND 3/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.300
Total data collected: 178

--- Round 3 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0200
Exploration rate: 0.300

--- Generated Sequences (Diversity: 1.000) ---
  CCTATATTGCCGGATCTTGA
  GCCCGCGTTCTTCACGCACT
  TCGCAACGGGTAGCTAAACA
  TTACGCATAAGCTGTCATGA
  GTTAGGAGATGCGCGGCGGA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.857
  Max reward: 18.660
  With intrinsic bonuses: 13.976

Policy Update:
  Adaptive update: clip_ratio=0.30, entropy_coef=0.020
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=1.3403, kl_div=0.0000
    Early stopping at epoch 2: KL divergence = 0.0959

=== Surrogate Model Training ===
Total samples: 242

Training on 228 samples (removed 14 outliers)
Reward range: [9.52, 17.34], mean: 13.60
  Created 11 candidate models for data size 228
Current R2 threshold: -0.3
  rf-m: R2 = -0.056 (std: 0.132)
  rf-l: R2 = -0.055 (std: 0.120)
  gb-m: R2 = -0.094 (std: 0.247)
  gb-l: R2 = -0.093 (std: 0.247)
  xgb-m: R2 = -0.285 (std: 0.203)
  knn-m: R2 = -0.149 (std: 0.189)
  knn-tuned: R2 = -0.149 (std: 0.189)
  mlp-m: R2 = -2.732 (std: 1.044)
  svr-rbf: R2 = -0.012 (std: 0.124)
  svr-poly: R2 = -0.012 (std: 0.124)
  ridge: R2 = -0.100 (std: 0.088)

Model-based training with 10 models
Best R2: -0.012, Mean R2: -0.340
Running 2 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-m:0.104 rf-l:0.104 gb-m:0.100 gb-l:0.100 xgb-m:0.083 knn-m:0.095 knn-tuned:0.095 svr-rbf:0.109 svr-poly:0.109 ridge:0.100 
  Adaptive update: clip_ratio=0.30, entropy_coef=0.010
    Epoch 0: policy_loss=-0.0000, value_loss=0.9915, entropy=1.3308, kl_div=0.0000
  Round 1/2: Mean predicted reward = 13.833
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-m:0.104 rf-l:0.104 gb-m:0.100 gb-l:0.100 xgb-m:0.083 knn-m:0.095 knn-tuned:0.095 svr-rbf:0.109 svr-poly:0.109 ridge:0.100 
  Adaptive update: clip_ratio=0.30, entropy_coef=0.010
    Epoch 0: policy_loss=0.0000, value_loss=0.9822, entropy=1.3262, kl_div=0.0000
  Round 2/2: Mean predicted reward = 13.760

  === Progress Analysis ===
  Status: WARNING
  • R2 scores negative. Models struggling to learn. Try collecting more diverse data.

--- Round 3 Results ---
  Mean Oracle Reward: 13.888
  Min Oracle Reward: 8.563
  Max Oracle Reward: 18.508
  Std Oracle Reward: 1.828
  Sequence Diversity: 1.000
  Models Used: 10
  Model R2 - Mean: -0.340, Max: -0.012, Count: 11
  New best mean reward!
  Total Sequences Evaluated: 242
    Oracle Count: 192 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}]

======================================================================
EXPERIMENT ROUND 4/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.280
Total data collected: 242
  Consistent improvement, increasing LR to 0.000045

--- Round 4 Configuration ---
Learning rate: 0.000045
Entropy coefficient: 0.0100
Exploration rate: 0.280

--- Generated Sequences (Diversity: 1.000) ---
  ACTCAGGCGTATACGGGCTC
  ATCGCAAACTGGATTGGATC
  CCGAGGCCTATTCAAGGGTA
  AGGGATCCCGAGTGCACATT
  GGTGGTCACATACCTCCAGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.614
  Max reward: 16.951
  With intrinsic bonuses: 13.790

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.010
    Epoch 0: policy_loss=-0.0000, value_loss=0.9834, entropy=1.3215, kl_div=0.0000
    Epoch 1: policy_loss=-0.0143, value_loss=0.9834, entropy=1.3196, kl_div=0.0261
    Early stopping at epoch 2: KL divergence = 0.0530

=== Surrogate Model Training ===
Total samples: 306

Training on 289 samples (removed 17 outliers)
Reward range: [9.72, 17.34], mean: 13.65
  Created 11 candidate models for data size 289
Current R2 threshold: -0.3
  rf-m: R2 = -0.177 (std: 0.106)
  rf-l: R2 = -0.145 (std: 0.108)
  gb-m: R2 = -0.200 (std: 0.270)
  gb-l: R2 = -0.203 (std: 0.270)
  xgb-m: R2 = -0.574 (std: 0.544)
  knn-m: R2 = -0.217 (std: 0.146)
  knn-tuned: R2 = -0.217 (std: 0.146)
  mlp-m: R2 = -0.850 (std: 0.527)
  svr-rbf: R2 = -0.043 (std: 0.106)
  svr-poly: R2 = -0.043 (std: 0.106)
  ridge: R2 = -0.058 (std: 0.067)

Model-based training with 9 models
Best R2: -0.043, Mean R2: -0.248
Running 2 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-m:0.107 rf-l:0.111 gb-m:0.105 gb-l:0.105 knn-m:0.103 knn-tuned:0.103 svr-rbf:0.123 svr-poly:0.123 ridge:0.121 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9854, entropy=1.3177, kl_div=0.0000
  Round 1/2: Mean predicted reward = 13.761
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-m:0.107 rf-l:0.111 gb-m:0.105 gb-l:0.105 knn-m:0.103 knn-tuned:0.103 svr-rbf:0.123 svr-poly:0.123 ridge:0.121 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9841, entropy=1.3173, kl_div=0.0000
  Round 2/2: Mean predicted reward = 13.742

  === Progress Analysis ===
  Status: WARNING
  • R2 scores negative. Models struggling to learn. Try collecting more diverse data.

--- Round 4 Results ---
  Mean Oracle Reward: 13.627
  Min Oracle Reward: 8.256
  Max Oracle Reward: 17.040
  Std Oracle Reward: 1.546
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -0.248, Max: -0.043, Count: 11
  Total Sequences Evaluated: 306
    Oracle Count: 256 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}]

======================================================================
EXPERIMENT ROUND 5/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.250
Total data collected: 306

--- Round 5 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0100
Exploration rate: 0.250

--- Generated Sequences (Diversity: 1.000) ---
  CCCTGACTGCATGAGGGAAT
  CGAGGTCACATGGTATGCCA
  AGTCCAGGATTTGCAACGGC
  CTGGAGAGGTTCCCGCATCA
  CCTATCTCACAAGGTAGGTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.766
  Max reward: 16.642
  With intrinsic bonuses: 13.920

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.010
    Epoch 0: policy_loss=-0.0000, value_loss=0.9852, entropy=1.3142, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1892

=== Surrogate Model Training ===
Total samples: 370

Training on 351 samples (removed 19 outliers)
Reward range: [10.00, 17.34], mean: 13.70
  Created 14 candidate models for data size 351
Current R2 threshold: -0.3
  rf-tuned-l: R2 = -0.055 (std: 0.136)
  rf-tuned-xl: R2 = -0.074 (std: 0.168)
  gb-tuned-l: R2 = -0.073 (std: 0.150)
  gb-tuned-xl: R2 = -0.073 (std: 0.150)
  xgb-xl: R2 = -0.285 (std: 0.233)
  xgb-l: R2 = -0.285 (std: 0.233)
  mlp-adaptive-xl: R2 = -0.546 (std: 0.247)
  mlp-l: R2 = -0.510 (std: 0.327)
  svr-rbf-xl: R2 = 0.003 (std: 0.129)
  svr-poly-l: R2 = 0.003 (std: 0.129)
  knn-tuned-sqrt: R2 = -0.022 (std: 0.183)
  knn-tuned-l: R2 = -0.022 (std: 0.183)
  ridge: R2 = -0.028 (std: 0.091)
  gp: R2 = -96.133 (std: 10.393)

Model-based training with 11 models
Best R2: 0.003, Mean R2: -7.007
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.091 gb-tuned-l:0.091 gb-tuned-xl:0.091 xgb-xl:0.074 xgb-l:0.074 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.096 knn-tuned-l:0.096 ridge:0.096 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9868, entropy=1.3011, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1612
  Round 1/3: Mean predicted reward = 13.645
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.091 gb-tuned-l:0.091 gb-tuned-xl:0.091 xgb-xl:0.074 xgb-l:0.074 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.096 knn-tuned-l:0.096 ridge:0.096 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9850, entropy=1.2894, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2235
  Round 2/3: Mean predicted reward = 13.687
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.091 gb-tuned-l:0.091 gb-tuned-xl:0.091 xgb-xl:0.074 xgb-l:0.074 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.096 knn-tuned-l:0.096 ridge:0.096 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9847, entropy=1.2733, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2029
  Round 3/3: Mean predicted reward = 13.584

  === Progress Analysis ===
  Status: NORMAL

--- Round 5 Results ---
  Mean Oracle Reward: 13.731
  Min Oracle Reward: 9.524
  Max Oracle Reward: 16.614
  Std Oracle Reward: 1.406
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -7.007, Max: 0.003, Count: 14
  Total Sequences Evaluated: 370
    Oracle Count: 320 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}]

======================================================================
EXPERIMENT ROUND 6/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.220
Total data collected: 370

--- Round 6 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0100
Exploration rate: 0.220

--- Generated Sequences (Diversity: 1.000) ---
  GCTATGTCTCCGGGACCAGA
  CCCTAGATGATTCCGCGGAG
  GGCGATCATCCCCGATGATG
  GGCAGGGATCACATATCCTG
  GTGACCTCCAGGTAAATGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.862
  Max reward: 17.608
  With intrinsic bonuses: 13.935

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.010
    Epoch 0: policy_loss=-0.0000, value_loss=0.9836, entropy=1.2614, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2178

=== Surrogate Model Training ===
Total samples: 434

Training on 410 samples (removed 24 outliers)
Reward range: [10.11, 17.21], mean: 13.73
  Created 14 candidate models for data size 410
Current R2 threshold: -0.3
  rf-tuned-l: R2 = -0.059 (std: 0.045)
  rf-tuned-xl: R2 = -0.055 (std: 0.058)
  gb-tuned-l: R2 = -0.052 (std: 0.044)
  gb-tuned-xl: R2 = -0.052 (std: 0.044)
  xgb-xl: R2 = -0.316 (std: 0.124)
  xgb-l: R2 = -0.316 (std: 0.124)
  mlp-adaptive-xl: R2 = -0.446 (std: 0.150)
  mlp-l: R2 = -0.524 (std: 0.236)
  svr-rbf-xl: R2 = 0.047 (std: 0.038)
  svr-poly-l: R2 = 0.047 (std: 0.038)
  knn-tuned-sqrt: R2 = -0.088 (std: 0.099)
  knn-tuned-l: R2 = -0.088 (std: 0.099)
  ridge: R2 = 0.008 (std: 0.042)
  gp: R2 = -99.321 (std: 13.131)

Model-based training with 9 models
Best R2: 0.047, Mean R2: -7.230
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.108 rf-tuned-xl:0.109 gb-tuned-l:0.109 gb-tuned-xl:0.109 svr-rbf-xl:0.120 svr-poly-l:0.120 knn-tuned-sqrt:0.105 knn-tuned-l:0.105 ridge:0.116 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9833, entropy=1.2460, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2180
  Round 1/3: Mean predicted reward = 13.850
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.108 rf-tuned-xl:0.109 gb-tuned-l:0.109 gb-tuned-xl:0.109 svr-rbf-xl:0.120 svr-poly-l:0.120 knn-tuned-sqrt:0.105 knn-tuned-l:0.105 ridge:0.116 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9876, entropy=1.2285, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2597
  Round 2/3: Mean predicted reward = 13.643
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.108 rf-tuned-xl:0.109 gb-tuned-l:0.109 gb-tuned-xl:0.109 svr-rbf-xl:0.120 svr-poly-l:0.120 knn-tuned-sqrt:0.105 knn-tuned-l:0.105 ridge:0.116 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9815, entropy=1.2124, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2863
  Round 3/3: Mean predicted reward = 13.749

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 6 Results ---
  Mean Oracle Reward: 13.814
  Min Oracle Reward: 6.287
  Max Oracle Reward: 17.673
  Std Oracle Reward: 1.760
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -7.230, Max: 0.047, Count: 14
  Total Sequences Evaluated: 434
    Oracle Count: 384 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}]

======================================================================
EXPERIMENT ROUND 7/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.190
Total data collected: 434
  Consistent improvement, increasing LR to 0.000240

--- Round 7 Configuration ---
Learning rate: 0.000240
Entropy coefficient: 0.0100
Exploration rate: 0.190

--- Generated Sequences (Diversity: 1.000) ---
  AGGCGGTCATCCCTCAGGGA
  ACGTGCGCAATTTACCCGGG
  TCGTCGCGGGAAACCTCCGG
  CCTAAGGGAGCGGCTCCGTC
  ATACATCGATGGCGCGCCTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.761
  Max reward: 18.861
  With intrinsic bonuses: 13.819

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.010
    Epoch 0: policy_loss=0.0000, value_loss=0.9851, entropy=1.1944, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2813

=== Surrogate Model Training ===
Total samples: 498

Training on 472 samples (removed 26 outliers)
Reward range: [10.00, 17.34], mean: 13.75
  Created 14 candidate models for data size 472
Current R2 threshold: -0.3
  rf-tuned-l: R2 = -0.068 (std: 0.045)
  rf-tuned-xl: R2 = -0.077 (std: 0.038)
  gb-tuned-l: R2 = -0.021 (std: 0.024)
  gb-tuned-xl: R2 = -0.021 (std: 0.024)
  xgb-xl: R2 = -0.400 (std: 0.078)
  xgb-l: R2 = -0.400 (std: 0.078)
  mlp-adaptive-xl: R2 = -0.460 (std: 0.273)
  mlp-l: R2 = -0.670 (std: 0.355)
  svr-rbf-xl: R2 = -0.011 (std: 0.063)
  svr-poly-l: R2 = -0.011 (std: 0.063)
  knn-tuned-sqrt: R2 = -0.157 (std: 0.081)
  knn-tuned-l: R2 = -0.157 (std: 0.081)
  ridge: R2 = -0.044 (std: 0.036)
  gp: R2 = -93.939 (std: 13.660)

Model-based training with 9 models
Best R2: -0.011, Mean R2: -6.888
Running 2 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.110 rf-tuned-xl:0.109 gb-tuned-l:0.116 gb-tuned-xl:0.116 svr-rbf-xl:0.117 svr-poly-l:0.117 knn-tuned-sqrt:0.101 knn-tuned-l:0.101 ridge:0.113 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9863, entropy=1.1843, kl_div=0.0000
  Round 1/2: Mean predicted reward = 13.963
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.110 rf-tuned-xl:0.109 gb-tuned-l:0.116 gb-tuned-xl:0.116 svr-rbf-xl:0.117 svr-poly-l:0.117 knn-tuned-sqrt:0.101 knn-tuned-l:0.101 ridge:0.113 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9787, entropy=1.1729, kl_div=0.0000
  Round 2/2: Mean predicted reward = 13.962

  === Progress Analysis ===
  Status: WARNING
  • R2 scores negative. Models struggling to learn. Try collecting more diverse data.
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 7 Results ---
  Mean Oracle Reward: 13.737
  Min Oracle Reward: 3.778
  Max Oracle Reward: 19.053
  Std Oracle Reward: 2.258
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -6.888, Max: -0.011, Count: 14
  Total Sequences Evaluated: 498
    Oracle Count: 448 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}]

======================================================================
EXPERIMENT ROUND 8/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.080
Total data collected: 498
  Performance plateaued, reducing LR to 0.000055

--- Round 8 Configuration ---
Learning rate: 0.000055
Entropy coefficient: 0.0050
Exploration rate: 0.080

--- Generated Sequences (Diversity: 1.000) ---
  TGAAGCTAAGCCTCGGGTCC
  GCGTACGCAGGACGACGTTC
  GCCAGTCGTAAGAGGCTTCC
  TCACCTCACTGGTAGTAGAG
  CGTACGGTCCGAATGAGATC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.075
  Max reward: 16.294
  With intrinsic bonuses: 14.105

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=1.1441, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0803

=== Surrogate Model Training ===
Total samples: 562

Training on 536 samples (removed 26 outliers)
Reward range: [9.98, 17.59], mean: 13.80
  Created 13 candidate models for data size 536
Current R2 threshold: -0.3
  rf-tuned-l: R2 = -0.020 (std: 0.038)
  rf-tuned-xl: R2 = -0.039 (std: 0.050)
  gb-tuned-l: R2 = -0.003 (std: 0.035)
  gb-tuned-xl: R2 = -0.003 (std: 0.035)
  xgb-xl: R2 = -0.252 (std: 0.125)
  xgb-l: R2 = -0.252 (std: 0.125)
  mlp-adaptive-xl: R2 = -0.291 (std: 0.165)
  mlp-l: R2 = -0.352 (std: 0.112)
  svr-rbf-xl: R2 = 0.044 (std: 0.029)
  svr-poly-l: R2 = 0.044 (std: 0.029)
  knn-tuned-sqrt: R2 = -0.103 (std: 0.033)
  knn-tuned-l: R2 = -0.103 (std: 0.033)
  ridge: R2 = -0.009 (std: 0.039)

Model-based training with 12 models
Best R2: 0.044, Mean R2: -0.103
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.086 gb-tuned-l:0.090 gb-tuned-xl:0.090 xgb-xl:0.070 xgb-l:0.070 mlp-adaptive-xl:0.067 svr-rbf-xl:0.094 svr-poly-l:0.094 knn-tuned-sqrt:0.081 knn-tuned-l:0.081 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9843, entropy=1.1415, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0743
  Round 1/3: Mean predicted reward = 13.898
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.086 gb-tuned-l:0.090 gb-tuned-xl:0.090 xgb-xl:0.070 xgb-l:0.070 mlp-adaptive-xl:0.067 svr-rbf-xl:0.094 svr-poly-l:0.094 knn-tuned-sqrt:0.081 knn-tuned-l:0.081 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9803, entropy=1.1359, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0953
  Round 2/3: Mean predicted reward = 13.864
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.086 gb-tuned-l:0.090 gb-tuned-xl:0.090 xgb-xl:0.070 xgb-l:0.070 mlp-adaptive-xl:0.067 svr-rbf-xl:0.094 svr-poly-l:0.094 knn-tuned-sqrt:0.081 knn-tuned-l:0.081 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9835, entropy=1.1296, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0903
  Round 3/3: Mean predicted reward = 14.011

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 8 Results ---
  Mean Oracle Reward: 14.083
  Min Oracle Reward: 9.672
  Max Oracle Reward: 16.331
  Std Oracle Reward: 1.517
  Sequence Diversity: 1.000
  Models Used: 12
  Model R2 - Mean: -0.103, Max: 0.044, Count: 13
  New best mean reward!
  Total Sequences Evaluated: 562
    Oracle Count: 512 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}]

======================================================================
EXPERIMENT ROUND 9/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.065
Total data collected: 562

--- Round 9 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.065

--- Generated Sequences (Diversity: 1.000) ---
  GGCGCTCGCTACGAAGTGAC
  CCGATAAGTTCCCGGCTGGA
  GACTGAAGGCTGGGCTCACC
  TAGGTACGACGTTCAGCGAC
  ACTACTGCCCGACAGGGTTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.205
  Max reward: 18.072
  With intrinsic bonuses: 14.248

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9852, entropy=1.1268, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0630

=== Surrogate Model Training ===
Total samples: 626

Training on 597 samples (removed 29 outliers)
Reward range: [10.00, 17.65], mean: 13.86
  Created 13 candidate models for data size 597
Current R2 threshold: -0.3
  rf-tuned-l: R2 = -0.027 (std: 0.063)
  rf-tuned-xl: R2 = -0.035 (std: 0.083)
  gb-tuned-l: R2 = -0.026 (std: 0.066)
  gb-tuned-xl: R2 = -0.026 (std: 0.066)
  xgb-xl: R2 = -0.247 (std: 0.103)
  xgb-l: R2 = -0.247 (std: 0.103)
  mlp-adaptive-xl: R2 = -0.397 (std: 0.292)
  mlp-l: R2 = -0.295 (std: 0.224)
  svr-rbf-xl: R2 = 0.027 (std: 0.065)
  svr-poly-l: R2 = 0.027 (std: 0.065)
  knn-tuned-sqrt: R2 = -0.127 (std: 0.028)
  knn-tuned-l: R2 = -0.127 (std: 0.028)
  ridge: R2 = -0.050 (std: 0.059)

Model-based training with 12 models
Best R2: 0.027, Mean R2: -0.119
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.088 gb-tuned-l:0.089 gb-tuned-xl:0.089 xgb-xl:0.071 xgb-l:0.071 mlp-l:0.068 svr-rbf-xl:0.094 svr-poly-l:0.094 knn-tuned-sqrt:0.080 knn-tuned-l:0.080 ridge:0.087 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9792, entropy=1.1207, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0681
  Round 1/3: Mean predicted reward = 13.864
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.088 gb-tuned-l:0.089 gb-tuned-xl:0.089 xgb-xl:0.071 xgb-l:0.071 mlp-l:0.068 svr-rbf-xl:0.094 svr-poly-l:0.094 knn-tuned-sqrt:0.080 knn-tuned-l:0.080 ridge:0.087 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9800, entropy=1.1178, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0685
  Round 2/3: Mean predicted reward = 13.894
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.088 gb-tuned-l:0.089 gb-tuned-xl:0.089 xgb-xl:0.071 xgb-l:0.071 mlp-l:0.068 svr-rbf-xl:0.094 svr-poly-l:0.094 knn-tuned-sqrt:0.080 knn-tuned-l:0.080 ridge:0.087 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9813, entropy=1.1126, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0783
  Round 3/3: Mean predicted reward = 13.926

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 9 Results ---
  Mean Oracle Reward: 14.193
  Min Oracle Reward: 8.283
  Max Oracle Reward: 17.985
  Std Oracle Reward: 1.599
  Sequence Diversity: 1.000
  Models Used: 12
  Model R2 - Mean: -0.119, Max: 0.027, Count: 13
  New best mean reward!
  Total Sequences Evaluated: 626
    Oracle Count: 576 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}]

======================================================================
EXPERIMENT ROUND 10/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 626
  Consistent improvement, increasing LR to 0.000360

--- Round 10 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  ACACAGTACTGTTCCGAGGT
  AGGGAGCCGATGCCTCCAGT
  ATCGGCCGTATCCCGAGAGG
  ATTCGCAGGCAGCTGGACCG
  GCTTCTGGAAGTCCACAGCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.108
  Max reward: 19.262
  With intrinsic bonuses: 14.135

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9800, entropy=1.1073, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.7394

=== Surrogate Model Training ===
Total samples: 690

Training on 657 samples (removed 33 outliers)
Reward range: [9.98, 17.65], mean: 13.87
  Created 13 candidate models for data size 657
Current R2 threshold: -0.3
  rf-tuned-l: R2 = -0.008 (std: 0.032)
  rf-tuned-xl: R2 = -0.010 (std: 0.029)
  gb-tuned-l: R2 = -0.003 (std: 0.047)
  gb-tuned-xl: R2 = -0.003 (std: 0.047)
  xgb-xl: R2 = -0.208 (std: 0.075)
  xgb-l: R2 = -0.208 (std: 0.075)
  mlp-adaptive-xl: R2 = -0.267 (std: 0.127)
  mlp-l: R2 = -0.342 (std: 0.197)
  svr-rbf-xl: R2 = 0.046 (std: 0.024)
  svr-poly-l: R2 = 0.046 (std: 0.024)
  knn-tuned-sqrt: R2 = -0.078 (std: 0.046)
  knn-tuned-l: R2 = -0.078 (std: 0.046)
  ridge: R2 = -0.020 (std: 0.044)

Model-based training with 12 models
Best R2: 0.046, Mean R2: -0.087
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.088 gb-tuned-l:0.088 gb-tuned-xl:0.088 xgb-xl:0.072 xgb-l:0.072 mlp-adaptive-xl:0.068 svr-rbf-xl:0.093 svr-poly-l:0.093 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.087 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9832, entropy=1.0710, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8352
  Round 1/3: Mean predicted reward = 13.915
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.088 gb-tuned-l:0.088 gb-tuned-xl:0.088 xgb-xl:0.072 xgb-l:0.072 mlp-adaptive-xl:0.068 svr-rbf-xl:0.093 svr-poly-l:0.093 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.087 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=1.0323, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8880
  Round 2/3: Mean predicted reward = 14.028
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.088 gb-tuned-l:0.088 gb-tuned-xl:0.088 xgb-xl:0.072 xgb-l:0.072 mlp-adaptive-xl:0.068 svr-rbf-xl:0.093 svr-poly-l:0.093 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.087 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9794, entropy=0.9910, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.9940
  Round 3/3: Mean predicted reward = 13.925

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 10 Results ---
  Mean Oracle Reward: 14.155
  Min Oracle Reward: 9.180
  Max Oracle Reward: 19.150
  Std Oracle Reward: 1.887
  Sequence Diversity: 1.000
  Models Used: 12
  Model R2 - Mean: -0.087, Max: 0.046, Count: 13
  Total Sequences Evaluated: 690
    Oracle Count: 640 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}]

======================================================================
EXPERIMENT ROUND 11/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 690
  Performance plateaued, reducing LR to 0.000136

--- Round 11 Configuration ---
Learning rate: 0.000136
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TGGATACCGCCCGGCATCGG
  GCCAAGGCCCTGCGGTCTAG
  CGGTTACCTGAAGGCACGCT
  TGAAGTCACTGCGGGCCCGC
  TGAGCGGGACCTATCTAACG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.021
  Max reward: 17.220
  With intrinsic bonuses: 14.020

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9885, entropy=0.9483, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4359

=== Surrogate Model Training ===
Total samples: 754

Training on 719 samples (removed 35 outliers)
Reward range: [9.98, 17.65], mean: 13.91
  Created 13 candidate models for data size 719
Current R2 threshold: -0.29
  rf-tuned-l: R2 = -0.037 (std: 0.089)
  rf-tuned-xl: R2 = -0.027 (std: 0.067)
  gb-tuned-l: R2 = -0.012 (std: 0.069)
  gb-tuned-xl: R2 = -0.012 (std: 0.069)
  xgb-xl: R2 = -0.268 (std: 0.059)
  xgb-l: R2 = -0.268 (std: 0.059)
  mlp-adaptive-xl: R2 = -0.320 (std: 0.145)
  mlp-l: R2 = -0.227 (std: 0.092)
  svr-rbf-xl: R2 = 0.032 (std: 0.043)
  svr-poly-l: R2 = 0.032 (std: 0.043)
  knn-tuned-sqrt: R2 = -0.087 (std: 0.033)
  knn-tuned-l: R2 = -0.087 (std: 0.033)
  ridge: R2 = -0.017 (std: 0.055)

Model-based training with 12 models
Best R2: 0.032, Mean R2: -0.100
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.089 gb-tuned-xl:0.089 xgb-xl:0.069 xgb-l:0.069 mlp-l:0.072 svr-rbf-xl:0.093 svr-poly-l:0.093 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9797, entropy=0.9316, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5130
  Round 1/3: Mean predicted reward = 13.974
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.089 gb-tuned-xl:0.089 xgb-xl:0.069 xgb-l:0.069 mlp-l:0.072 svr-rbf-xl:0.093 svr-poly-l:0.093 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9764, entropy=0.9138, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5105
  Round 2/3: Mean predicted reward = 14.037
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.089 gb-tuned-xl:0.089 xgb-xl:0.069 xgb-l:0.069 mlp-l:0.072 svr-rbf-xl:0.093 svr-poly-l:0.093 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9767, entropy=0.8975, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5404
  Round 3/3: Mean predicted reward = 14.121

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 11 Results ---
  Mean Oracle Reward: 14.011
  Min Oracle Reward: 0.088
  Max Oracle Reward: 17.234
  Std Oracle Reward: 2.359
  Sequence Diversity: 1.000
  Models Used: 12
  Model R2 - Mean: -0.100, Max: 0.032, Count: 13
  Total Sequences Evaluated: 754
    Oracle Count: 704 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}]

======================================================================
EXPERIMENT ROUND 12/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 754
  Performance plateaued, reducing LR to 0.000100

--- Round 12 Configuration ---
Learning rate: 0.000100
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GGAATCAGCATGCGCTGCGC
  CGTGGGGACCCGACCATGTC
  AGCCCGAGACGTGTACATGT
  TGCCAGGAAGTCTGCGGACC
  GCGCAGGGCCACTAATCGTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.760
  Max reward: 18.036
  With intrinsic bonuses: 14.750

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9814, entropy=0.8764, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4101

=== Surrogate Model Training ===
Total samples: 818

Training on 780 samples (removed 38 outliers)
Reward range: [9.98, 17.65], mean: 13.97
  Created 13 candidate models for data size 780
Current R2 threshold: -0.27999999999999997
  rf-tuned-l: R2 = 0.021 (std: 0.051)
  rf-tuned-xl: R2 = 0.017 (std: 0.079)
  gb-tuned-l: R2 = 0.028 (std: 0.059)
  gb-tuned-xl: R2 = 0.028 (std: 0.059)
  xgb-xl: R2 = -0.201 (std: 0.107)
  xgb-l: R2 = -0.201 (std: 0.107)
  mlp-adaptive-xl: R2 = -0.154 (std: 0.149)
  mlp-l: R2 = -0.137 (std: 0.139)
  svr-rbf-xl: R2 = 0.060 (std: 0.051)
  svr-poly-l: R2 = 0.060 (std: 0.051)
  knn-tuned-sqrt: R2 = -0.055 (std: 0.068)
  knn-tuned-l: R2 = -0.055 (std: 0.068)
  ridge: R2 = -0.024 (std: 0.061)

Model-based training with 13 models
Best R2: 0.060, Mean R2: -0.047
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.082 rf-tuned-xl:0.082 gb-tuned-l:0.083 gb-tuned-xl:0.083 xgb-xl:0.066 xgb-l:0.066 mlp-adaptive-xl:0.069 mlp-l:0.070 svr-rbf-xl:0.085 svr-poly-l:0.085 knn-tuned-sqrt:0.076 knn-tuned-l:0.076 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9777, entropy=0.8599, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4529
  Round 1/3: Mean predicted reward = 14.135
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.082 rf-tuned-xl:0.082 gb-tuned-l:0.083 gb-tuned-xl:0.083 xgb-xl:0.066 xgb-l:0.066 mlp-adaptive-xl:0.069 mlp-l:0.070 svr-rbf-xl:0.085 svr-poly-l:0.085 knn-tuned-sqrt:0.076 knn-tuned-l:0.076 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9788, entropy=0.8487, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4668
  Round 2/3: Mean predicted reward = 14.062
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.082 rf-tuned-xl:0.082 gb-tuned-l:0.083 gb-tuned-xl:0.083 xgb-xl:0.066 xgb-l:0.066 mlp-adaptive-xl:0.069 mlp-l:0.070 svr-rbf-xl:0.085 svr-poly-l:0.085 knn-tuned-sqrt:0.076 knn-tuned-l:0.076 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9765, entropy=0.8301, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5339
  Round 3/3: Mean predicted reward = 14.062

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 12 Results ---
  Mean Oracle Reward: 14.758
  Min Oracle Reward: 9.174
  Max Oracle Reward: 18.465
  Std Oracle Reward: 1.816
  Sequence Diversity: 1.000
  Models Used: 13
  Model R2 - Mean: -0.047, Max: 0.060, Count: 13
  New best mean reward!
  Total Sequences Evaluated: 818
    Oracle Count: 768 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}]

======================================================================
EXPERIMENT ROUND 13/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 818

--- Round 13 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CTTAGGTGACCGAGACGCGC
  ATCTCCATGGCACAGGTCGG
  CCTCCGGATTGCGAGCGCAG
  GCCTCAGCTAGGTGGCACGC
  GCCGGTCCTGATACCCGGGA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.153
  Max reward: 18.958
  With intrinsic bonuses: 14.136

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9778, entropy=0.8185, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6103

=== Surrogate Model Training ===
Total samples: 882

Training on 836 samples (removed 46 outliers)
Reward range: [9.98, 17.65], mean: 13.99
  Created 13 candidate models for data size 836
Current R2 threshold: -0.27
  rf-tuned-l: R2 = 0.045 (std: 0.084)
  rf-tuned-xl: R2 = 0.044 (std: 0.059)
  gb-tuned-l: R2 = 0.070 (std: 0.041)
  gb-tuned-xl: R2 = 0.070 (std: 0.041)
  xgb-xl: R2 = -0.193 (std: 0.142)
  xgb-l: R2 = -0.193 (std: 0.142)
  mlp-adaptive-xl: R2 = -0.139 (std: 0.124)
  mlp-l: R2 = -0.114 (std: 0.117)
  svr-rbf-xl: R2 = 0.083 (std: 0.027)
  svr-poly-l: R2 = 0.083 (std: 0.027)
  knn-tuned-sqrt: R2 = -0.033 (std: 0.086)
  knn-tuned-l: R2 = -0.033 (std: 0.086)
  ridge: R2 = 0.001 (std: 0.054)

Model-based training with 13 models
Best R2: 0.083, Mean R2: -0.024
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.082 rf-tuned-xl:0.082 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.065 xgb-l:0.065 mlp-adaptive-xl:0.068 mlp-l:0.070 svr-rbf-xl:0.085 svr-poly-l:0.085 knn-tuned-sqrt:0.076 knn-tuned-l:0.076 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9777, entropy=0.8063, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6033
  Round 1/3: Mean predicted reward = 14.081
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.082 rf-tuned-xl:0.082 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.065 xgb-l:0.065 mlp-adaptive-xl:0.068 mlp-l:0.070 svr-rbf-xl:0.085 svr-poly-l:0.085 knn-tuned-sqrt:0.076 knn-tuned-l:0.076 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9796, entropy=0.7871, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6655
  Round 2/3: Mean predicted reward = 14.047
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.082 rf-tuned-xl:0.082 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.065 xgb-l:0.065 mlp-adaptive-xl:0.068 mlp-l:0.070 svr-rbf-xl:0.085 svr-poly-l:0.085 knn-tuned-sqrt:0.076 knn-tuned-l:0.076 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9729, entropy=0.7745, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6511
  Round 3/3: Mean predicted reward = 14.183

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 13 Results ---
  Mean Oracle Reward: 14.111
  Min Oracle Reward: 5.192
  Max Oracle Reward: 18.993
  Std Oracle Reward: 2.494
  Sequence Diversity: 1.000
  Models Used: 13
  Model R2 - Mean: -0.024, Max: 0.083, Count: 13
  Total Sequences Evaluated: 882
    Oracle Count: 832 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}]

======================================================================
EXPERIMENT ROUND 14/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 882

--- Round 14 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TTGCACGCGCTTACAGGAGC
  GCATGCTGCCATCACGGGGA
  CGCCGGGGACAACGTCGTTC
  GTAGGCACCCCTTGGAGGCC
  CGAGAGGCGCATTCCGGTCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.164
  Max reward: 19.059
  With intrinsic bonuses: 14.187

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9830, entropy=0.7592, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2155

=== Surrogate Model Training ===
Total samples: 946

Training on 897 samples (removed 49 outliers)
Reward range: [9.98, 18.07], mean: 14.01
  Created 13 candidate models for data size 897
Current R2 threshold: -0.26
  rf-tuned-l: R2 = 0.027 (std: 0.091)
  rf-tuned-xl: R2 = 0.035 (std: 0.090)
  gb-tuned-l: R2 = 0.066 (std: 0.041)
  gb-tuned-xl: R2 = 0.066 (std: 0.041)
  xgb-xl: R2 = -0.179 (std: 0.137)
  xgb-l: R2 = -0.179 (std: 0.137)
  mlp-adaptive-xl: R2 = -0.127 (std: 0.087)
  mlp-l: R2 = -0.120 (std: 0.042)
  svr-rbf-xl: R2 = 0.080 (std: 0.042)
  svr-poly-l: R2 = 0.080 (std: 0.042)
  knn-tuned-sqrt: R2 = -0.072 (std: 0.072)
  knn-tuned-l: R2 = -0.072 (std: 0.072)
  ridge: R2 = -0.015 (std: 0.046)

Model-based training with 13 models
Best R2: 0.080, Mean R2: -0.031
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.081 rf-tuned-xl:0.082 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.066 xgb-l:0.066 mlp-adaptive-xl:0.070 mlp-l:0.070 svr-rbf-xl:0.086 svr-poly-l:0.086 knn-tuned-sqrt:0.074 knn-tuned-l:0.074 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9794, entropy=0.7503, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2485
  Round 1/3: Mean predicted reward = 14.187
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.081 rf-tuned-xl:0.082 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.066 xgb-l:0.066 mlp-adaptive-xl:0.070 mlp-l:0.070 svr-rbf-xl:0.086 svr-poly-l:0.086 knn-tuned-sqrt:0.074 knn-tuned-l:0.074 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9735, entropy=0.7464, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2453
  Round 2/3: Mean predicted reward = 14.102
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.081 rf-tuned-xl:0.082 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.066 xgb-l:0.066 mlp-adaptive-xl:0.070 mlp-l:0.070 svr-rbf-xl:0.086 svr-poly-l:0.086 knn-tuned-sqrt:0.074 knn-tuned-l:0.074 ridge:0.078 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9743, entropy=0.7440, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2435
  Round 3/3: Mean predicted reward = 14.153

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 14 Results ---
  Mean Oracle Reward: 14.175
  Min Oracle Reward: 8.496
  Max Oracle Reward: 19.068
  Std Oracle Reward: 2.064
  Sequence Diversity: 1.000
  Models Used: 13
  Model R2 - Mean: -0.031, Max: 0.080, Count: 13
  Total Sequences Evaluated: 946
    Oracle Count: 896 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}]

======================================================================
EXPERIMENT ROUND 15/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 946

--- Round 15 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TGACGCCACAGCACTGGGTG
  CCAGGCACGCCATGGTGGCT
  GCGCCTTCACGCAGTGGGCA
  CCCGCCCAAGGATTGGGGCT
  ACAACGGCGTGACGGCTGCT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.940
  Max reward: 18.860
  With intrinsic bonuses: 13.889

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9869, entropy=0.7351, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.9329

=== Surrogate Model Training ===
Total samples: 1010

Training on 960 samples (removed 50 outliers)
Reward range: [9.82, 18.14], mean: 14.02
  Created 13 candidate models for data size 960
Current R2 threshold: -0.25
  rf-tuned-l: R2 = 0.026 (std: 0.041)
  rf-tuned-xl: R2 = 0.024 (std: 0.066)
  gb-tuned-l: R2 = 0.043 (std: 0.027)
  gb-tuned-xl: R2 = 0.043 (std: 0.027)
  xgb-xl: R2 = -0.226 (std: 0.159)
  xgb-l: R2 = -0.226 (std: 0.159)
  mlp-adaptive-xl: R2 = -0.152 (std: 0.086)
  mlp-l: R2 = -0.176 (std: 0.084)
  svr-rbf-xl: R2 = 0.069 (std: 0.036)
  svr-poly-l: R2 = 0.069 (std: 0.036)
  knn-tuned-sqrt: R2 = -0.105 (std: 0.077)
  knn-tuned-l: R2 = -0.105 (std: 0.077)
  ridge: R2 = -0.009 (std: 0.036)

Model-based training with 13 models
Best R2: 0.069, Mean R2: -0.056
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.083 rf-tuned-xl:0.083 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.065 xgb-l:0.065 mlp-adaptive-xl:0.069 mlp-l:0.068 svr-rbf-xl:0.087 svr-poly-l:0.087 knn-tuned-sqrt:0.073 knn-tuned-l:0.073 ridge:0.080 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9778, entropy=0.7048, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.0988
  Round 1/3: Mean predicted reward = 14.128
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.083 rf-tuned-xl:0.083 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.065 xgb-l:0.065 mlp-adaptive-xl:0.069 mlp-l:0.068 svr-rbf-xl:0.087 svr-poly-l:0.087 knn-tuned-sqrt:0.073 knn-tuned-l:0.073 ridge:0.080 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9776, entropy=0.6715, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.3454
  Round 2/3: Mean predicted reward = 14.269
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.083 rf-tuned-xl:0.083 gb-tuned-l:0.084 gb-tuned-xl:0.084 xgb-xl:0.065 xgb-l:0.065 mlp-adaptive-xl:0.069 mlp-l:0.068 svr-rbf-xl:0.087 svr-poly-l:0.087 knn-tuned-sqrt:0.073 knn-tuned-l:0.073 ridge:0.080 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9700, entropy=0.6427, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.4581
  Round 3/3: Mean predicted reward = 14.250

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 15 Results ---
  Mean Oracle Reward: 13.947
  Min Oracle Reward: 8.321
  Max Oracle Reward: 18.665
  Std Oracle Reward: 2.143
  Sequence Diversity: 1.000
  Models Used: 13
  Model R2 - Mean: -0.056, Max: 0.069, Count: 13
  Total Sequences Evaluated: 1010
    Oracle Count: 960 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}]

======================================================================
EXPERIMENT ROUND 16/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 1010

--- Round 16 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CTCGAAGGTGCCGTCGGACC
  GACTCGCAGGTTCGGGCACA
  ATACTTGCGGCCGACGCGGA
  GGTCAGAAGCCATGTGCGCC
  AGGCCCCTGGCGCGGTACAT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.191
  Max reward: 17.841
  With intrinsic bonuses: 13.175

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=6.0068, entropy=0.6160, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.9540

=== Surrogate Model Training ===
Total samples: 1074

Training on 1018 samples (removed 56 outliers)
Reward range: [9.82, 18.14], mean: 14.02
  Created 13 candidate models for data size 1018
Current R2 threshold: -0.24
  rf-tuned-l: R2 = 0.006 (std: 0.046)
  rf-tuned-xl: R2 = 0.020 (std: 0.035)
  gb-tuned-l: R2 = 0.029 (std: 0.030)
  gb-tuned-xl: R2 = 0.029 (std: 0.030)
  xgb-xl: R2 = -0.243 (std: 0.083)
  xgb-l: R2 = -0.243 (std: 0.083)
  mlp-adaptive-xl: R2 = -0.095 (std: 0.087)
  mlp-l: R2 = -0.120 (std: 0.056)
  svr-rbf-xl: R2 = 0.065 (std: 0.038)
  svr-poly-l: R2 = 0.065 (std: 0.038)
  knn-tuned-sqrt: R2 = -0.086 (std: 0.038)
  knn-tuned-l: R2 = -0.086 (std: 0.038)
  ridge: R2 = -0.014 (std: 0.035)

Model-based training with 11 models
Best R2: 0.065, Mean R2: -0.052
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.094 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.084 mlp-l:0.082 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.085 knn-tuned-l:0.085 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9753, entropy=0.5969, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.1048
  Round 1/3: Mean predicted reward = 14.184
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.094 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.084 mlp-l:0.082 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.085 knn-tuned-l:0.085 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9732, entropy=0.5826, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.3381
  Round 2/3: Mean predicted reward = 14.136
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.094 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.084 mlp-l:0.082 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.085 knn-tuned-l:0.085 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9781, entropy=0.5655, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.4856
  Round 3/3: Mean predicted reward = 14.050

  === Progress Analysis ===
  Status: NORMAL

--- Round 16 Results ---
  Mean Oracle Reward: 13.218
  Min Oracle Reward: 0.000
  Max Oracle Reward: 17.807
  Std Oracle Reward: 3.535
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.052, Max: 0.065, Count: 13
  Total Sequences Evaluated: 1074
    Oracle Count: 1024 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}]

======================================================================
EXPERIMENT ROUND 17/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 1074

--- Round 17 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CTCGTACGGAGGTCATCAGC
  CCGCAGCTCATCTGGGGCAG
  GCCACGGTGCTAGGACGATC
  CGCAGGCTGCCTGGACTGCA
  GGGTCTCCAGGGCACGCATC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.752
  Max reward: 20.436
  With intrinsic bonuses: 13.766

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9901, entropy=0.5449, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.4665

=== Surrogate Model Training ===
Total samples: 1138

Training on 1078 samples (removed 60 outliers)
Reward range: [9.82, 18.14], mean: 14.02
  Created 13 candidate models for data size 1078
Current R2 threshold: -0.22999999999999998
  rf-tuned-l: R2 = 0.014 (std: 0.033)
  rf-tuned-xl: R2 = 0.013 (std: 0.040)
  gb-tuned-l: R2 = 0.044 (std: 0.015)
  gb-tuned-xl: R2 = 0.044 (std: 0.015)
  xgb-xl: R2 = -0.242 (std: 0.050)
  xgb-l: R2 = -0.242 (std: 0.050)
  mlp-adaptive-xl: R2 = -0.051 (std: 0.056)
  mlp-l: R2 = -0.108 (std: 0.088)
  svr-rbf-xl: R2 = 0.063 (std: 0.042)
  svr-poly-l: R2 = 0.063 (std: 0.042)
  knn-tuned-sqrt: R2 = -0.105 (std: 0.042)
  knn-tuned-l: R2 = -0.105 (std: 0.042)
  ridge: R2 = -0.010 (std: 0.032)

Model-based training with 11 models
Best R2: 0.063, Mean R2: -0.048
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.093 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.082 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9748, entropy=0.5328, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.7167
  Round 1/3: Mean predicted reward = 14.149
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.093 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.082 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9713, entropy=0.5247, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.8637
  Round 2/3: Mean predicted reward = 14.086
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.093 rf-tuned-xl:0.093 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.082 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9752, entropy=0.5161, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.0374
  Round 3/3: Mean predicted reward = 14.211

  === Progress Analysis ===
  Status: NORMAL

--- Round 17 Results ---
  Mean Oracle Reward: 13.729
  Min Oracle Reward: 5.617
  Max Oracle Reward: 20.368
  Std Oracle Reward: 2.273
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.048, Max: 0.063, Count: 13
  Total Sequences Evaluated: 1138
    Oracle Count: 1088 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 18/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 1138

--- Round 18 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CGAGGCGCGTTTCCAAGCGA
  TTCGATCGGCGAGCCCGGAC
  GTTGAACCGCACCTGCGGAG
  AGCTCTGGCCGCGGCTCAGA
  TAACGTCCGGCCGGACTGCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.746
  Max reward: 17.651
  With intrinsic bonuses: 13.778

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9897, entropy=0.4990, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8907

=== Surrogate Model Training ===
Total samples: 1202

Training on 1140 samples (removed 62 outliers)
Reward range: [9.70, 18.26], mean: 14.05
  Created 13 candidate models for data size 1140
Current R2 threshold: -0.21999999999999997
  rf-tuned-l: R2 = 0.027 (std: 0.028)
  rf-tuned-xl: R2 = 0.033 (std: 0.031)
  gb-tuned-l: R2 = 0.071 (std: 0.045)
  gb-tuned-xl: R2 = 0.071 (std: 0.045)
  xgb-xl: R2 = -0.223 (std: 0.085)
  xgb-l: R2 = -0.223 (std: 0.085)
  mlp-adaptive-xl: R2 = -0.039 (std: 0.096)
  mlp-l: R2 = -0.062 (std: 0.056)
  svr-rbf-xl: R2 = 0.094 (std: 0.031)
  svr-poly-l: R2 = 0.094 (std: 0.031)
  knn-tuned-sqrt: R2 = -0.082 (std: 0.074)
  knn-tuned-l: R2 = -0.082 (std: 0.074)
  ridge: R2 = 0.011 (std: 0.044)

Model-based training with 11 models
Best R2: 0.094, Mean R2: -0.024
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.092 rf-tuned-xl:0.093 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.086 mlp-l:0.084 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9749, entropy=0.4933, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.0312
  Round 1/3: Mean predicted reward = 14.180
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.092 rf-tuned-xl:0.093 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.086 mlp-l:0.084 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9744, entropy=0.4899, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.1805
  Round 2/3: Mean predicted reward = 14.113
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.092 rf-tuned-xl:0.093 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.086 mlp-l:0.084 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9717, entropy=0.4867, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.1802
  Round 3/3: Mean predicted reward = 14.239

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 18 Results ---
  Mean Oracle Reward: 13.751
  Min Oracle Reward: 4.573
  Max Oracle Reward: 17.447
  Std Oracle Reward: 2.803
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.024, Max: 0.094, Count: 13
  Total Sequences Evaluated: 1202
    Oracle Count: 1152 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 19/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 1202

--- Round 19 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TGACCGCCCGCTCGGAGTGA
  GAAGGCACCCCGCGCTTGTG
  AGCCGCAGTCGTCGTGCCAG
  GCCGTGAGACGCCTGCCGTA
  GTCCGCAGCTGCGAGAACGT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.639
  Max reward: 18.299
  With intrinsic bonuses: 13.628

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9876, entropy=0.4756, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3707

=== Surrogate Model Training ===
Total samples: 1266

Training on 1201 samples (removed 65 outliers)
Reward range: [9.70, 18.26], mean: 14.04
  Created 13 candidate models for data size 1201
Current R2 threshold: -0.21
  rf-tuned-l: R2 = 0.037 (std: 0.013)
  rf-tuned-xl: R2 = 0.036 (std: 0.022)
  gb-tuned-l: R2 = 0.065 (std: 0.046)
  gb-tuned-xl: R2 = 0.065 (std: 0.046)
  xgb-xl: R2 = -0.208 (std: 0.084)
  xgb-l: R2 = -0.208 (std: 0.084)
  mlp-adaptive-xl: R2 = -0.019 (std: 0.033)
  mlp-l: R2 = -0.033 (std: 0.099)
  svr-rbf-xl: R2 = 0.096 (std: 0.011)
  svr-poly-l: R2 = 0.096 (std: 0.011)
  knn-tuned-sqrt: R2 = -0.084 (std: 0.050)
  knn-tuned-l: R2 = -0.084 (std: 0.050)
  ridge: R2 = 0.016 (std: 0.043)

Model-based training with 13 models
Best R2: 0.096, Mean R2: -0.017
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.081 rf-tuned-xl:0.081 gb-tuned-l:0.083 gb-tuned-xl:0.083 xgb-xl:0.063 xgb-l:0.063 mlp-adaptive-xl:0.076 mlp-l:0.075 svr-rbf-xl:0.086 svr-poly-l:0.086 knn-tuned-sqrt:0.072 knn-tuned-l:0.072 ridge:0.079 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9741, entropy=0.4758, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3909
  Round 1/3: Mean predicted reward = 14.111
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.081 rf-tuned-xl:0.081 gb-tuned-l:0.083 gb-tuned-xl:0.083 xgb-xl:0.063 xgb-l:0.063 mlp-adaptive-xl:0.076 mlp-l:0.075 svr-rbf-xl:0.086 svr-poly-l:0.086 knn-tuned-sqrt:0.072 knn-tuned-l:0.072 ridge:0.079 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9740, entropy=0.4833, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3818
  Round 2/3: Mean predicted reward = 14.127
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.081 rf-tuned-xl:0.081 gb-tuned-l:0.083 gb-tuned-xl:0.083 xgb-xl:0.063 xgb-l:0.063 mlp-adaptive-xl:0.076 mlp-l:0.075 svr-rbf-xl:0.086 svr-poly-l:0.086 knn-tuned-sqrt:0.072 knn-tuned-l:0.072 ridge:0.079 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9792, entropy=0.4777, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4362
  Round 3/3: Mean predicted reward = 14.130

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 19 Results ---
  Mean Oracle Reward: 13.585
  Min Oracle Reward: 0.000
  Max Oracle Reward: 18.120
  Std Oracle Reward: 2.637
  Sequence Diversity: 1.000
  Models Used: 13
  Model R2 - Mean: -0.017, Max: 0.096, Count: 13
  Total Sequences Evaluated: 1266
    Oracle Count: 1216 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 20/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 1266
  Performance plateaued, reducing LR to 0.000150

--- Round 20 Configuration ---
Learning rate: 0.000150
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TGCATACTCCCGGGGACCGG
  ATCAAGGTGTCCCCCGGGCG
  GCCGGAATCCTGCCGCGGAT
  GAGGAGCGGAGACTCCTCTC
  TGCTGCCACAGCGCGTAGCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.582
  Max reward: 17.698
  With intrinsic bonuses: 13.581

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9929, entropy=0.4774, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.2810

=== Surrogate Model Training ===
Total samples: 1330

Training on 1261 samples (removed 69 outliers)
Reward range: [9.70, 18.26], mean: 14.04
  Created 13 candidate models for data size 1261
Current R2 threshold: -0.19999999999999998
  rf-tuned-l: R2 = 0.022 (std: 0.046)
  rf-tuned-xl: R2 = 0.025 (std: 0.047)
  gb-tuned-l: R2 = 0.084 (std: 0.044)
  gb-tuned-xl: R2 = 0.084 (std: 0.044)
  xgb-xl: R2 = -0.220 (std: 0.089)
  xgb-l: R2 = -0.220 (std: 0.089)
  mlp-adaptive-xl: R2 = -0.009 (std: 0.019)
  mlp-l: R2 = -0.008 (std: 0.053)
  svr-rbf-xl: R2 = 0.107 (std: 0.038)
  svr-poly-l: R2 = 0.107 (std: 0.038)
  knn-tuned-sqrt: R2 = -0.101 (std: 0.069)
  knn-tuned-l: R2 = -0.101 (std: 0.069)
  ridge: R2 = 0.018 (std: 0.039)

Model-based training with 11 models
Best R2: 0.107, Mean R2: -0.016
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.091 rf-tuned-xl:0.091 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.088 mlp-l:0.088 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.080 knn-tuned-l:0.080 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9789, entropy=0.4699, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.4149
  Round 1/3: Mean predicted reward = 14.085
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.091 rf-tuned-xl:0.091 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.088 mlp-l:0.088 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.080 knn-tuned-l:0.080 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9786, entropy=0.4639, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.5490
  Round 2/3: Mean predicted reward = 14.078
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.091 rf-tuned-xl:0.091 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.088 mlp-l:0.088 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.080 knn-tuned-l:0.080 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9758, entropy=0.4556, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.6329
  Round 3/3: Mean predicted reward = 14.208

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 20 Results ---
  Mean Oracle Reward: 13.599
  Min Oracle Reward: 3.490
  Max Oracle Reward: 18.124
  Std Oracle Reward: 2.368
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.016, Max: 0.107, Count: 13
  Total Sequences Evaluated: 1330
    Oracle Count: 1280 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 21/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 1330
  Performance plateaued, reducing LR to 0.000136

--- Round 21 Configuration ---
Learning rate: 0.000136
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GAGTCCCAGCCGATCTGGCG
  GGGCCACGTGCATATGCCAG
  CTGCAGCGGCCTGGGTCCAA
  CGCATGAGCACCTGCGCGTG
  TTGGGACCCGGAAGCGCCCT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.519
  Max reward: 18.993
  With intrinsic bonuses: 13.536

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9926, entropy=0.4396, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.2248

=== Surrogate Model Training ===
Total samples: 1394

Training on 1321 samples (removed 73 outliers)
Reward range: [9.69, 18.26], mean: 14.03
  Created 13 candidate models for data size 1321
Current R2 threshold: -0.19
  rf-tuned-l: R2 = 0.036 (std: 0.030)
  rf-tuned-xl: R2 = 0.021 (std: 0.036)
  gb-tuned-l: R2 = 0.077 (std: 0.029)
  gb-tuned-xl: R2 = 0.077 (std: 0.029)
  xgb-xl: R2 = -0.207 (std: 0.056)
  xgb-l: R2 = -0.207 (std: 0.056)
  mlp-adaptive-xl: R2 = -0.000 (std: 0.059)
  mlp-l: R2 = -0.012 (std: 0.039)
  svr-rbf-xl: R2 = 0.102 (std: 0.026)
  svr-poly-l: R2 = 0.102 (std: 0.026)
  knn-tuned-sqrt: R2 = -0.066 (std: 0.063)
  knn-tuned-l: R2 = -0.066 (std: 0.063)
  ridge: R2 = 0.007 (std: 0.027)

Model-based training with 11 models
Best R2: 0.102, Mean R2: -0.010
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.092 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.088 mlp-l:0.087 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9769, entropy=0.4431, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.3146
  Round 1/3: Mean predicted reward = 14.033
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.092 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.088 mlp-l:0.087 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9790, entropy=0.4366, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.5061
  Round 2/3: Mean predicted reward = 14.113
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.092 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.088 mlp-l:0.087 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9808, entropy=0.4242, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.5776
  Round 3/3: Mean predicted reward = 14.112

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 21 Results ---
  Mean Oracle Reward: 13.485
  Min Oracle Reward: 0.000
  Max Oracle Reward: 18.899
  Std Oracle Reward: 2.443
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.010, Max: 0.102, Count: 13
  Total Sequences Evaluated: 1394
    Oracle Count: 1344 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 22/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 1394
  Performance plateaued, reducing LR to 0.000100

--- Round 22 Configuration ---
Learning rate: 0.000100
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TGCACGGCGTCAGCGCATGC
  TGGCTGGAACGCGACCTGCC
  AGCCGTCCCCGTTGGGGACA
  TGCGCGCTCACAAGGCGCTG
  AGTGCGCGCTGGCGACCACT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.526
  Max reward: 18.487
  With intrinsic bonuses: 13.506

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9889, entropy=0.4212, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.9873

=== Surrogate Model Training ===
Total samples: 1458

Training on 1379 samples (removed 79 outliers)
Reward range: [9.67, 18.26], mean: 14.03
  Created 13 candidate models for data size 1379
Current R2 threshold: -0.18
  rf-tuned-l: R2 = 0.005 (std: 0.041)
  rf-tuned-xl: R2 = 0.013 (std: 0.048)
  gb-tuned-l: R2 = 0.066 (std: 0.030)
  gb-tuned-xl: R2 = 0.066 (std: 0.030)
  xgb-xl: R2 = -0.210 (std: 0.052)
  xgb-l: R2 = -0.210 (std: 0.052)
  mlp-adaptive-xl: R2 = -0.029 (std: 0.049)
  mlp-l: R2 = -0.009 (std: 0.033)
  svr-rbf-xl: R2 = 0.086 (std: 0.020)
  svr-poly-l: R2 = 0.086 (std: 0.020)
  knn-tuned-sqrt: R2 = -0.092 (std: 0.045)
  knn-tuned-l: R2 = -0.092 (std: 0.045)
  ridge: R2 = -0.000 (std: 0.039)

Model-based training with 11 models
Best R2: 0.086, Mean R2: -0.025
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.091 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.089 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9822, entropy=0.4211, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.9930
  Round 1/3: Mean predicted reward = 14.059
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.091 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.089 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9758, entropy=0.4123, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.1310
  Round 2/3: Mean predicted reward = 14.084
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.091 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.089 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9744, entropy=0.4141, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.0957
  Round 3/3: Mean predicted reward = 14.070

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 22 Results ---
  Mean Oracle Reward: 13.535
  Min Oracle Reward: 0.000
  Max Oracle Reward: 18.436
  Std Oracle Reward: 2.857
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.025, Max: 0.086, Count: 13
  Total Sequences Evaluated: 1458
    Oracle Count: 1408 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 23/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 1458
  Performance plateaued, reducing LR to 0.000055

--- Round 23 Configuration ---
Learning rate: 0.000055
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CCGGCGATACCGCTGGCTAG
  AGCACTCAGCGGTCACGGTG
  GACGGGCTCCCCAGGCATGT
  CTGCGCCTTCGCGACAGGGA
  CCATGCGGCCTACGCGGTAG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 12.934
  Max reward: 17.753
  With intrinsic bonuses: 12.915

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=9.8020, entropy=0.4080, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4352

=== Surrogate Model Training ===
Total samples: 1522

Training on 1436 samples (removed 86 outliers)
Reward range: [9.67, 18.26], mean: 14.03
  Created 13 candidate models for data size 1436
Current R2 threshold: -0.16999999999999998
  rf-tuned-l: R2 = -0.009 (std: 0.053)
  rf-tuned-xl: R2 = -0.008 (std: 0.050)
  gb-tuned-l: R2 = 0.059 (std: 0.039)
  gb-tuned-xl: R2 = 0.059 (std: 0.039)
  xgb-xl: R2 = -0.222 (std: 0.099)
  xgb-l: R2 = -0.222 (std: 0.099)
  mlp-adaptive-xl: R2 = -0.013 (std: 0.065)
  mlp-l: R2 = -0.045 (std: 0.042)
  svr-rbf-xl: R2 = 0.069 (std: 0.049)
  svr-poly-l: R2 = 0.069 (std: 0.049)
  knn-tuned-sqrt: R2 = -0.099 (std: 0.059)
  knn-tuned-l: R2 = -0.099 (std: 0.059)
  ridge: R2 = -0.003 (std: 0.037)

Model-based training with 11 models
Best R2: 0.069, Mean R2: -0.036
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.090 mlp-l:0.087 svr-rbf-xl:0.097 svr-poly-l:0.097 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9783, entropy=0.4094, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4439
  Round 1/3: Mean predicted reward = 14.164
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.090 mlp-l:0.087 svr-rbf-xl:0.097 svr-poly-l:0.097 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9774, entropy=0.4071, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5192
  Round 2/3: Mean predicted reward = 14.131
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.090 mlp-l:0.087 svr-rbf-xl:0.097 svr-poly-l:0.097 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9753, entropy=0.3949, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5812
  Round 3/3: Mean predicted reward = 13.974

  === Progress Analysis ===
  Status: NORMAL

--- Round 23 Results ---
  Mean Oracle Reward: 12.955
  Min Oracle Reward: 0.000
  Max Oracle Reward: 17.793
  Std Oracle Reward: 3.780
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.036, Max: 0.069, Count: 13
  Total Sequences Evaluated: 1522
    Oracle Count: 1472 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 24/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 1522

--- Round 24 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  ACGGGATGGGCCCATGCCTC
  GACGTCGGCTACGCCGGTCA
  CCCCGCACACTGGGTTAGGG
  GCGTGTGCCCGGTCAAAGCC
  CCAGCAGCGGGCTGGCTATC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.147
  Max reward: 16.892
  With intrinsic bonuses: 13.108

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9947, entropy=0.4018, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2574

=== Surrogate Model Training ===
Total samples: 1586

Training on 1496 samples (removed 90 outliers)
Reward range: [9.67, 18.26], mean: 14.02
  Created 13 candidate models for data size 1496
Current R2 threshold: -0.15999999999999998
  rf-tuned-l: R2 = -0.032 (std: 0.057)
  rf-tuned-xl: R2 = -0.034 (std: 0.054)
  gb-tuned-l: R2 = 0.050 (std: 0.045)
  gb-tuned-xl: R2 = 0.050 (std: 0.045)
  xgb-xl: R2 = -0.256 (std: 0.074)
  xgb-l: R2 = -0.256 (std: 0.074)
  mlp-adaptive-xl: R2 = -0.045 (std: 0.062)
  mlp-l: R2 = -0.009 (std: 0.072)
  svr-rbf-xl: R2 = 0.068 (std: 0.054)
  svr-poly-l: R2 = 0.068 (std: 0.054)
  knn-tuned-sqrt: R2 = -0.097 (std: 0.039)
  knn-tuned-l: R2 = -0.097 (std: 0.039)
  ridge: R2 = -0.006 (std: 0.039)

Model-based training with 11 models
Best R2: 0.068, Mean R2: -0.046
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.088 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.091 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9757, entropy=0.3966, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3140
  Round 1/3: Mean predicted reward = 13.971
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.088 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.091 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9792, entropy=0.3970, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3234
  Round 2/3: Mean predicted reward = 14.129
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.088 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.087 mlp-l:0.091 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9780, entropy=0.3936, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3479
  Round 3/3: Mean predicted reward = 14.045

  === Progress Analysis ===
  Status: NORMAL

--- Round 24 Results ---
  Mean Oracle Reward: 13.136
  Min Oracle Reward: 4.055
  Max Oracle Reward: 16.926
  Std Oracle Reward: 2.498
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.046, Max: 0.068, Count: 13
  Total Sequences Evaluated: 1586
    Oracle Count: 1536 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 25/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 1586

--- Round 25 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TGCAACTTCTAGAGGCGCAG
  CCAATTCCAGGGGCTGGTCA
  GACAGCCCCCTTCGGGAGTG
  GCCTGGCCGCCGGTACAATG
  TGGCGCCAACTGCGCAGCTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.334
  Max reward: 19.446
  With intrinsic bonuses: 13.348

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=4.0455, entropy=0.3897, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.2645

=== Surrogate Model Training ===
Total samples: 1650

Training on 1563 samples (removed 87 outliers)
Reward range: [9.44, 18.26], mean: 13.99
  Created 13 candidate models for data size 1563
Current R2 threshold: -0.15
  rf-tuned-l: R2 = -0.027 (std: 0.047)
  rf-tuned-xl: R2 = -0.030 (std: 0.048)
  gb-tuned-l: R2 = 0.071 (std: 0.036)
  gb-tuned-xl: R2 = 0.071 (std: 0.036)
  xgb-xl: R2 = -0.238 (std: 0.058)
  xgb-l: R2 = -0.238 (std: 0.058)
  mlp-adaptive-xl: R2 = -0.002 (std: 0.035)
  mlp-l: R2 = -0.038 (std: 0.038)
  svr-rbf-xl: R2 = 0.098 (std: 0.047)
  svr-poly-l: R2 = 0.098 (std: 0.047)
  knn-tuned-sqrt: R2 = -0.091 (std: 0.024)
  knn-tuned-l: R2 = -0.091 (std: 0.024)
  ridge: R2 = 0.012 (std: 0.034)

Model-based training with 11 models
Best R2: 0.098, Mean R2: -0.031
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.087 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.090 mlp-l:0.087 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9828, entropy=0.4040, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.0642
  Round 1/3: Mean predicted reward = 13.986
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.087 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.090 mlp-l:0.087 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9784, entropy=0.3928, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.2308
  Round 2/3: Mean predicted reward = 14.197
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.088 rf-tuned-xl:0.087 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.090 mlp-l:0.087 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9818, entropy=0.3831, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.3117
  Round 3/3: Mean predicted reward = 14.160

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 25 Results ---
  Mean Oracle Reward: 13.344
  Min Oracle Reward: 0.000
  Max Oracle Reward: 19.170
  Std Oracle Reward: 3.290
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.031, Max: 0.098, Count: 13
  Total Sequences Evaluated: 1650
    Oracle Count: 1600 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 26/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 1650
  Consistent improvement, increasing LR to 0.000327

--- Round 26 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CGGCAGTCACCGGTACGGCT
  CGCTGCACGGAAGCCTTGGC
  CCGCACATGGATTGGGGCCC
  CCTGCGGCGAGACTAGGCCT
  CGGGAACTTCCGGATCCGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.713
  Max reward: 19.252
  With intrinsic bonuses: 13.760

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9903, entropy=0.3656, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.5605

=== Surrogate Model Training ===
Total samples: 1714

Training on 1623 samples (removed 91 outliers)
Reward range: [9.44, 18.26], mean: 13.99
  Created 13 candidate models for data size 1623
Current R2 threshold: -0.13999999999999999
  rf-tuned-l: R2 = -0.028 (std: 0.062)
  rf-tuned-xl: R2 = -0.030 (std: 0.056)
  gb-tuned-l: R2 = 0.084 (std: 0.032)
  gb-tuned-xl: R2 = 0.084 (std: 0.032)
  xgb-xl: R2 = -0.217 (std: 0.046)
  xgb-l: R2 = -0.217 (std: 0.046)
  mlp-adaptive-xl: R2 = -0.016 (std: 0.047)
  mlp-l: R2 = 0.003 (std: 0.040)
  svr-rbf-xl: R2 = 0.107 (std: 0.037)
  svr-poly-l: R2 = 0.107 (std: 0.037)
  knn-tuned-sqrt: R2 = -0.073 (std: 0.029)
  knn-tuned-l: R2 = -0.073 (std: 0.029)
  ridge: R2 = 0.018 (std: 0.026)

Model-based training with 11 models
Best R2: 0.107, Mean R2: -0.019
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.088 mlp-l:0.090 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9813, entropy=0.3639, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.4701
  Round 1/3: Mean predicted reward = 13.904
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.088 mlp-l:0.090 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9753, entropy=0.3627, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.6420
  Round 2/3: Mean predicted reward = 13.982
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.097 gb-tuned-xl:0.097 mlp-adaptive-xl:0.088 mlp-l:0.090 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.091 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9824, entropy=0.3526, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.7270
  Round 3/3: Mean predicted reward = 14.058

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 26 Results ---
  Mean Oracle Reward: 13.727
  Min Oracle Reward: 1.117
  Max Oracle Reward: 19.547
  Std Oracle Reward: 2.638
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.019, Max: 0.107, Count: 13
  Total Sequences Evaluated: 1714
    Oracle Count: 1664 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 27/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 1714
  Consistent improvement, increasing LR to 0.000240

--- Round 27 Configuration ---
Learning rate: 0.000240
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  TGCCCATGTGACGGGAGACC
  GCACGTGCCTAGCTGCGACG
  GAGCGTATCTGTCCGAAAGC
  TGGACGATTCCGCGCGGCAC
  GCCGGATGGGCAGCCTAACT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.918
  Max reward: 18.656
  With intrinsic bonuses: 13.914

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9854, entropy=0.3338, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8102

=== Surrogate Model Training ===
Total samples: 1778

Training on 1683 samples (removed 95 outliers)
Reward range: [9.44, 18.41], mean: 14.00
  Created 13 candidate models for data size 1683
Current R2 threshold: -0.12999999999999998
  rf-tuned-l: R2 = -0.014 (std: 0.063)
  rf-tuned-xl: R2 = -0.020 (std: 0.073)
  gb-tuned-l: R2 = 0.076 (std: 0.038)
  gb-tuned-xl: R2 = 0.076 (std: 0.038)
  xgb-xl: R2 = -0.250 (std: 0.075)
  xgb-l: R2 = -0.250 (std: 0.075)
  mlp-adaptive-xl: R2 = 0.019 (std: 0.050)
  mlp-l: R2 = 0.009 (std: 0.061)
  svr-rbf-xl: R2 = 0.107 (std: 0.034)
  svr-poly-l: R2 = 0.107 (std: 0.034)
  knn-tuned-sqrt: R2 = -0.059 (std: 0.028)
  knn-tuned-l: R2 = -0.059 (std: 0.028)
  ridge: R2 = 0.015 (std: 0.023)

Model-based training with 11 models
Best R2: 0.107, Mean R2: -0.019
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.090 mlp-l:0.089 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.084 knn-tuned-l:0.084 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9861, entropy=0.3425, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4901
  Round 1/3: Mean predicted reward = 13.971
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.090 mlp-l:0.089 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.084 knn-tuned-l:0.084 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9752, entropy=0.3433, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6238
  Round 2/3: Mean predicted reward = 14.078
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.087 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.090 mlp-l:0.089 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.084 knn-tuned-l:0.084 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9786, entropy=0.3356, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6436
  Round 3/3: Mean predicted reward = 14.140

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 27 Results ---
  Mean Oracle Reward: 13.919
  Min Oracle Reward: 7.874
  Max Oracle Reward: 18.819
  Std Oracle Reward: 2.202
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.019, Max: 0.107, Count: 13
  Total Sequences Evaluated: 1778
    Oracle Count: 1728 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 28/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 1778
  Consistent improvement, increasing LR to 0.000132

--- Round 28 Configuration ---
Learning rate: 0.000132
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CTCGTCCGAGAGGGCGCACT
  CATAGCGGGACGTGCCCTGA
  CCCGTGATCGCGGCACTAGG
  CAGCACCGTTGCCGTGCAGG
  AGGAGGCCGCGCTACTTGCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.978
  Max reward: 18.403
  With intrinsic bonuses: 13.992

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9852, entropy=0.3461, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1227

=== Surrogate Model Training ===
Total samples: 1842

Training on 1744 samples (removed 98 outliers)
Reward range: [9.44, 18.42], mean: 14.00
  Created 13 candidate models for data size 1744
Current R2 threshold: -0.12
  rf-tuned-l: R2 = -0.011 (std: 0.061)
  rf-tuned-xl: R2 = 0.005 (std: 0.060)
  gb-tuned-l: R2 = 0.086 (std: 0.027)
  gb-tuned-xl: R2 = 0.086 (std: 0.027)
  xgb-xl: R2 = -0.159 (std: 0.067)
  xgb-l: R2 = -0.159 (std: 0.067)
  mlp-adaptive-xl: R2 = 0.013 (std: 0.052)
  mlp-l: R2 = 0.021 (std: 0.043)
  svr-rbf-xl: R2 = 0.120 (std: 0.016)
  svr-poly-l: R2 = 0.120 (std: 0.016)
  knn-tuned-sqrt: R2 = -0.028 (std: 0.015)
  knn-tuned-l: R2 = -0.028 (std: 0.015)
  ridge: R2 = 0.011 (std: 0.026)

Model-based training with 11 models
Best R2: 0.120, Mean R2: 0.006
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.088 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.089 mlp-l:0.089 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.085 knn-tuned-l:0.085 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9779, entropy=0.3392, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2703
  Round 1/3: Mean predicted reward = 14.062
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.088 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.089 mlp-l:0.089 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.085 knn-tuned-l:0.085 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9776, entropy=0.3389, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3999
  Round 2/3: Mean predicted reward = 14.139
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.087 rf-tuned-xl:0.088 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.089 mlp-l:0.089 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.085 knn-tuned-l:0.085 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9738, entropy=0.3265, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5540
  Round 3/3: Mean predicted reward = 14.109

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 28 Results ---
  Mean Oracle Reward: 13.981
  Min Oracle Reward: 7.245
  Max Oracle Reward: 18.425
  Std Oracle Reward: 1.982
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: 0.006, Max: 0.120, Count: 13
  Total Sequences Evaluated: 1842
    Oracle Count: 1792 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 29/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 1842
  Consistent improvement, increasing LR to 0.000045

--- Round 29 Configuration ---
Learning rate: 0.000045
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  AGCGCGGGTCGCCTATCGAA
  GTCATGCGCCAGTAGCCCGG
  AAATCCGCTGGCCGGCGTCG
  AGAGTGAGCCGCGTGTCACC
  GATCCCGGGTCGTAGGACCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.501
  Max reward: 18.419
  With intrinsic bonuses: 14.457

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9761, entropy=0.3233, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2029

=== Surrogate Model Training ===
Total samples: 1906

Training on 1806 samples (removed 100 outliers)
Reward range: [9.44, 18.43], mean: 14.02
  Created 13 candidate models for data size 1806
Current R2 threshold: -0.10999999999999999
  rf-tuned-l: R2 = 0.027 (std: 0.039)
  rf-tuned-xl: R2 = 0.032 (std: 0.041)
  gb-tuned-l: R2 = 0.098 (std: 0.029)
  gb-tuned-xl: R2 = 0.098 (std: 0.029)
  xgb-xl: R2 = -0.152 (std: 0.062)
  xgb-l: R2 = -0.152 (std: 0.062)
  mlp-adaptive-xl: R2 = 0.036 (std: 0.062)
  mlp-l: R2 = 0.045 (std: 0.029)
  svr-rbf-xl: R2 = 0.123 (std: 0.024)
  svr-poly-l: R2 = 0.123 (std: 0.024)
  knn-tuned-sqrt: R2 = -0.033 (std: 0.033)
  knn-tuned-l: R2 = -0.033 (std: 0.033)
  ridge: R2 = 0.016 (std: 0.030)

Model-based training with 11 models
Best R2: 0.123, Mean R2: 0.018
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.090 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.084 knn-tuned-l:0.084 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9750, entropy=0.3152, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2092
  Round 1/3: Mean predicted reward = 14.096
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.090 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.084 knn-tuned-l:0.084 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9752, entropy=0.3155, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2588
  Round 2/3: Mean predicted reward = 14.185
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.095 gb-tuned-xl:0.095 mlp-adaptive-xl:0.090 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.084 knn-tuned-l:0.084 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9786, entropy=0.3119, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2810
  Round 3/3: Mean predicted reward = 14.237

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 29 Results ---
  Mean Oracle Reward: 14.468
  Min Oracle Reward: 7.091
  Max Oracle Reward: 18.420
  Std Oracle Reward: 1.953
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: 0.018, Max: 0.123, Count: 13
  Total Sequences Evaluated: 1906
    Oracle Count: 1856 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 30/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 1906
  Consistent improvement, increasing LR to 0.000360

--- Round 30 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GGGATCTGGCGCCCACAGCT
  AGGCGACCTCGCGGGATCCT
  TCCGACCACGATGGGTAGCG
  TTCGATCAACGCTAGCAGGG
  GCCGGTTCGAATCGCGGCAC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.595
  Max reward: 18.638
  With intrinsic bonuses: 13.611

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9852, entropy=0.3104, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.3232

=== Surrogate Model Training ===
Total samples: 1970

Training on 1869 samples (removed 101 outliers)
Reward range: [9.40, 18.53], mean: 14.02
  Created 13 candidate models for data size 1869
Current R2 threshold: -0.09999999999999998
  rf-tuned-l: R2 = 0.029 (std: 0.049)
  rf-tuned-xl: R2 = 0.035 (std: 0.051)
  gb-tuned-l: R2 = 0.093 (std: 0.028)
  gb-tuned-xl: R2 = 0.093 (std: 0.028)
  xgb-xl: R2 = -0.147 (std: 0.060)
  xgb-l: R2 = -0.147 (std: 0.060)
  mlp-adaptive-xl: R2 = 0.023 (std: 0.052)
  mlp-l: R2 = 0.031 (std: 0.049)
  svr-rbf-xl: R2 = 0.117 (std: 0.043)
  svr-poly-l: R2 = 0.117 (std: 0.043)
  knn-tuned-sqrt: R2 = -0.049 (std: 0.027)
  knn-tuned-l: R2 = -0.049 (std: 0.027)
  ridge: R2 = 0.011 (std: 0.028)

Model-based training with 11 models
Best R2: 0.117, Mean R2: 0.012
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.089 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9825, entropy=0.2790, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8410
  Round 1/3: Mean predicted reward = 14.057
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.089 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9739, entropy=0.2780, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.1811
  Round 2/3: Mean predicted reward = 14.136
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.090 rf-tuned-xl:0.090 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.089 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.083 knn-tuned-l:0.083 ridge:0.088 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9804, entropy=0.2656, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.2769
  Round 3/3: Mean predicted reward = 14.201

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 30 Results ---
  Mean Oracle Reward: 13.629
  Min Oracle Reward: 7.104
  Max Oracle Reward: 18.484
  Std Oracle Reward: 2.234
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: 0.012, Max: 0.117, Count: 13
  Total Sequences Evaluated: 1970
    Oracle Count: 1920 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 31/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 1970

--- Round 31 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  ACTTCGGTACGGGCCGCGCA
  CCAAGCTCTTGGGCCGGAGA
  TTGAACCGTGCCCCGGGCGA
  CGGCGAGACCAGCCTTGCGT
  GGAGTGTCCCTCGACAGCGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.407
  Max reward: 16.935
  With intrinsic bonuses: 13.406

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9883, entropy=0.2432, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.7343

=== Surrogate Model Training ===
Total samples: 2034

Training on 1932 samples (removed 102 outliers)
Reward range: [9.39, 18.53], mean: 14.00
  Created 13 candidate models for data size 1932
Current R2 threshold: -0.09
  rf-tuned-l: R2 = 0.013 (std: 0.059)
  rf-tuned-xl: R2 = 0.011 (std: 0.052)
  gb-tuned-l: R2 = 0.088 (std: 0.034)
  gb-tuned-xl: R2 = 0.088 (std: 0.034)
  xgb-xl: R2 = -0.159 (std: 0.044)
  xgb-l: R2 = -0.159 (std: 0.044)
  mlp-adaptive-xl: R2 = 0.034 (std: 0.049)
  mlp-l: R2 = 0.028 (std: 0.037)
  svr-rbf-xl: R2 = 0.112 (std: 0.037)
  svr-poly-l: R2 = 0.112 (std: 0.037)
  knn-tuned-sqrt: R2 = -0.071 (std: 0.013)
  knn-tuned-l: R2 = -0.071 (std: 0.013)
  ridge: R2 = 0.014 (std: 0.022)

Model-based training with 11 models
Best R2: 0.112, Mean R2: 0.003
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.091 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9895, entropy=0.2410, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3062
  Round 1/3: Mean predicted reward = 13.917
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.091 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9752, entropy=0.2506, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5314
  Round 2/3: Mean predicted reward = 13.982
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.091 mlp-l:0.090 svr-rbf-xl:0.098 svr-poly-l:0.098 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.089 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9754, entropy=0.2426, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8031
  Round 3/3: Mean predicted reward = 14.114

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 31 Results ---
  Mean Oracle Reward: 13.377
  Min Oracle Reward: 8.072
  Max Oracle Reward: 17.075
  Std Oracle Reward: 2.175
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: 0.003, Max: 0.112, Count: 13
  Total Sequences Evaluated: 2034
    Oracle Count: 1984 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 32/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 2034

--- Round 32 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CAGTCAGGGCACGCTTGGCC
  CCGTAGCTGGGTGACCACCG
  GGCAGGCCAACTGTCGTGCC
  GCCCAGTCGAGGCCCTAGGT
  GCAGCTCACGGACTTGGCGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.695
  Max reward: 17.921
  With intrinsic bonuses: 13.705

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9818, entropy=0.2286, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2283

=== Surrogate Model Training ===
Total samples: 2098

Training on 1991 samples (removed 107 outliers)
Reward range: [9.39, 18.53], mean: 14.00
  Created 13 candidate models for data size 1991
Current R2 threshold: -0.07999999999999999
  rf-tuned-l: R2 = 0.001 (std: 0.057)
  rf-tuned-xl: R2 = 0.005 (std: 0.053)
  gb-tuned-l: R2 = 0.084 (std: 0.036)
  gb-tuned-xl: R2 = 0.084 (std: 0.036)
  xgb-xl: R2 = -0.165 (std: 0.043)
  xgb-l: R2 = -0.165 (std: 0.043)
  mlp-adaptive-xl: R2 = 0.002 (std: 0.063)
  mlp-l: R2 = 0.020 (std: 0.040)
  svr-rbf-xl: R2 = 0.113 (std: 0.033)
  svr-poly-l: R2 = 0.113 (std: 0.033)
  knn-tuned-sqrt: R2 = -0.079 (std: 0.017)
  knn-tuned-l: R2 = -0.079 (std: 0.017)
  ridge: R2 = 0.020 (std: 0.021)

Model-based training with 11 models
Best R2: 0.113, Mean R2: -0.004
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.089 mlp-l:0.090 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9805, entropy=0.2357, kl_div=0.0000
    Epoch 1: policy_loss=-0.0153, value_loss=0.9805, entropy=0.2381, kl_div=-0.0872
  Round 1/3: Mean predicted reward = 13.910
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.089 mlp-l:0.090 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9754, entropy=0.2433, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4464
  Round 2/3: Mean predicted reward = 14.105
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.089 rf-tuned-xl:0.089 gb-tuned-l:0.096 gb-tuned-xl:0.096 mlp-adaptive-xl:0.089 mlp-l:0.090 svr-rbf-xl:0.099 svr-poly-l:0.099 knn-tuned-sqrt:0.082 knn-tuned-l:0.082 ridge:0.090 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9734, entropy=0.2275, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6335
  Round 3/3: Mean predicted reward = 14.146

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 32 Results ---
  Mean Oracle Reward: 13.683
  Min Oracle Reward: 5.291
  Max Oracle Reward: 18.311
  Std Oracle Reward: 2.496
  Sequence Diversity: 1.000
  Models Used: 11
  Model R2 - Mean: -0.004, Max: 0.113, Count: 13
  Total Sequences Evaluated: 2098
    Oracle Count: 2048 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 33/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 2098

--- Round 33 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GGGGTCATGCGCGCAAACCT
  TCGGGGCCTTAGCCGGCCAA
  ATGCCGTTCGCCCGGAAGGC
  TAACCGCGGCTCGGAGCAGT
  GGCTGGACCGGATCGCACCT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.882
  Max reward: 17.260
  With intrinsic bonuses: 13.880

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9870, entropy=0.2311, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1229

=== Surrogate Model Training ===
Total samples: 2162

Training on 2054 samples (removed 108 outliers)
Reward range: [9.39, 18.61], mean: 14.01
  Created 13 candidate models for data size 2054
Current R2 threshold: -0.06999999999999998
  rf-tuned-l: R2 = -0.017 (std: 0.055)
  rf-tuned-xl: R2 = -0.011 (std: 0.055)
  gb-tuned-l: R2 = 0.081 (std: 0.020)
  gb-tuned-xl: R2 = 0.081 (std: 0.020)
  xgb-xl: R2 = -0.177 (std: 0.049)
  xgb-l: R2 = -0.177 (std: 0.049)
  mlp-adaptive-xl: R2 = 0.037 (std: 0.021)
  mlp-l: R2 = 0.026 (std: 0.032)
  svr-rbf-xl: R2 = 0.102 (std: 0.027)
  svr-poly-l: R2 = 0.102 (std: 0.027)
  knn-tuned-sqrt: R2 = -0.086 (std: 0.024)
  knn-tuned-l: R2 = -0.086 (std: 0.024)
  ridge: R2 = 0.017 (std: 0.016)

Model-based training with 9 models
Best R2: 0.102, Mean R2: -0.008
Running 3 virtual training rounds
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.104 rf-tuned-xl:0.105 gb-tuned-l:0.115 gb-tuned-xl:0.115 mlp-adaptive-xl:0.110 mlp-l:0.109 svr-rbf-xl:0.117 svr-poly-l:0.117 ridge:0.108 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9809, entropy=0.2298, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1507
  Round 1/3: Mean predicted reward = 13.942
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.104 rf-tuned-xl:0.105 gb-tuned-l:0.115 gb-tuned-xl:0.115 mlp-adaptive-xl:0.110 mlp-l:0.109 svr-rbf-xl:0.117 svr-poly-l:0.117 ridge:0.108 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9752, entropy=0.2252, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2633
  Round 2/3: Mean predicted reward = 14.001
Current Method: dynamic
    Using performance-based weights
    Model weights: rf-tuned-l:0.104 rf-tuned-xl:0.105 gb-tuned-l:0.115 gb-tuned-xl:0.115 mlp-adaptive-xl:0.110 mlp-l:0.109 svr-rbf-xl:0.117 svr-poly-l:0.117 ridge:0.108 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9758, entropy=0.2325, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3966
  Round 3/3: Mean predicted reward = 14.095

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 33 Results ---
  Mean Oracle Reward: 13.877
  Min Oracle Reward: 8.824
  Max Oracle Reward: 17.268
  Std Oracle Reward: 1.775
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -0.008, Max: 0.102, Count: 13
  Total Sequences Evaluated: 2162
    Oracle Count: 2112 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 34/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 2162
  Consistent improvement, increasing LR to 0.000045

--- Round 34 Configuration ---
Learning rate: 0.000045
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GACCTGGCTGGCAATGCCCG
  TGAGGTAACCGCCCGTGGCC
  CCTAGCGGACCCCGGAGTGT
  CCGTGTTCCGCGAGACGCGA
  CGGATCGCGATCCACGCGTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.787
  Max reward: 18.012
  With intrinsic bonuses: 13.796

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9893, entropy=0.2266, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0758

=== Surrogate Model Training ===
Total samples: 2226

Training on 2116 samples (removed 110 outliers)
Reward range: [9.39, 18.61], mean: 14.01
  Created 13 candidate models for data size 2116
Current R2 threshold: -0.06
  rf-tuned-l: R2 = -0.010 (std: 0.039)
  rf-tuned-xl: R2 = -0.016 (std: 0.049)
  gb-tuned-l: R2 = 0.076 (std: 0.022)
  gb-tuned-xl: R2 = 0.076 (std: 0.022)
  xgb-xl: R2 = -0.164 (std: 0.048)
  xgb-l: R2 = -0.164 (std: 0.048)
  mlp-adaptive-xl: R2 = 0.036 (std: 0.029)
  mlp-l: R2 = 0.038 (std: 0.034)
  svr-rbf-xl: R2 = 0.099 (std: 0.024)
  svr-poly-l: R2 = 0.099 (std: 0.024)
  knn-tuned-sqrt: R2 = -0.083 (std: 0.037)
  knn-tuned-l: R2 = -0.083 (std: 0.037)
  ridge: R2 = 0.014 (std: 0.016)

Model-based training with 9 models
Best R2: 0.099, Mean R2: -0.006
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.014 rf-tuned-xl:0.881 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.031 svr-poly-l:0.000 ridge:0.074 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9884, entropy=0.2369, kl_div=0.0000
    Epoch 1: policy_loss=-0.0169, value_loss=0.9884, entropy=0.2371, kl_div=-0.0052
  Round 1/3: Mean predicted reward = 13.968
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.014 rf-tuned-xl:0.881 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.031 svr-poly-l:0.000 ridge:0.074 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9800, entropy=0.2242, kl_div=0.0000
    Epoch 1: policy_loss=-0.0158, value_loss=0.9800, entropy=0.2252, kl_div=-0.1257
  Round 2/3: Mean predicted reward = 14.028
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.014 rf-tuned-xl:0.881 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.031 svr-poly-l:0.000 ridge:0.074 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9854, entropy=0.2372, kl_div=0.0000
    Epoch 1: policy_loss=-0.0082, value_loss=0.9854, entropy=0.2380, kl_div=-0.1057
  Round 3/3: Mean predicted reward = 14.088

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 34 Results ---
  Mean Oracle Reward: 13.770
  Min Oracle Reward: 8.986
  Max Oracle Reward: 18.189
  Std Oracle Reward: 1.881
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -0.006, Max: 0.099, Count: 13
  Total Sequences Evaluated: 2226
    Oracle Count: 2176 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 35/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 2226
  Performance plateaued, reducing LR to 0.000150

--- Round 35 Configuration ---
Learning rate: 0.000150
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GTGGCTCCAATGCCGCGCGA
  CAGCGGACTCGGGTTCCCGA
  TATCCGCAGTCGACCGGGAG
  TGATTGGCGCGGCAGCACCC
  CTGTATACGGCGACACGGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.788
  Max reward: 18.654
  With intrinsic bonuses: 13.768

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9846, entropy=0.2319, kl_div=0.0000
    Epoch 1: policy_loss=0.0201, value_loss=0.9846, entropy=0.2336, kl_div=-0.3166

=== Surrogate Model Training ===
Total samples: 2290

Training on 2175 samples (removed 115 outliers)
Reward range: [9.39, 18.53], mean: 14.00
  Created 13 candidate models for data size 2175
Current R2 threshold: -0.04999999999999999
  rf-tuned-l: R2 = -0.008 (std: 0.049)
  rf-tuned-xl: R2 = -0.009 (std: 0.044)
  gb-tuned-l: R2 = 0.088 (std: 0.021)
  gb-tuned-xl: R2 = 0.088 (std: 0.021)
  xgb-xl: R2 = -0.152 (std: 0.043)
  xgb-l: R2 = -0.152 (std: 0.043)
  mlp-adaptive-xl: R2 = 0.041 (std: 0.021)
  mlp-l: R2 = 0.052 (std: 0.022)
  svr-rbf-xl: R2 = 0.099 (std: 0.027)
  svr-poly-l: R2 = 0.099 (std: 0.027)
  knn-tuned-sqrt: R2 = -0.089 (std: 0.028)
  knn-tuned-l: R2 = -0.089 (std: 0.028)
  ridge: R2 = 0.014 (std: 0.014)

Model-based training with 9 models
Best R2: 0.099, Mean R2: -0.001
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.311 gb-tuned-l:0.048 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.169 svr-rbf-xl:0.305 svr-poly-l:0.167 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9820, entropy=0.2341, kl_div=0.0000
    Epoch 1: policy_loss=0.0481, value_loss=0.9820, entropy=0.2347, kl_div=-0.3029
  Round 1/3: Mean predicted reward = 13.830
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.311 gb-tuned-l:0.048 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.169 svr-rbf-xl:0.305 svr-poly-l:0.167 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9810, entropy=0.2319, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0872
  Round 2/3: Mean predicted reward = 13.879
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.311 gb-tuned-l:0.048 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.169 svr-rbf-xl:0.305 svr-poly-l:0.167 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9792, entropy=0.2207, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3270
  Round 3/3: Mean predicted reward = 14.016

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 35 Results ---
  Mean Oracle Reward: 13.767
  Min Oracle Reward: 7.891
  Max Oracle Reward: 18.941
  Std Oracle Reward: 1.988
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -0.001, Max: 0.099, Count: 13
  Total Sequences Evaluated: 2290
    Oracle Count: 2240 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 36/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 2290
  Performance plateaued, reducing LR to 0.000136

--- Round 36 Configuration ---
Learning rate: 0.000136
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CCGCCGTGCTACTGAAGGGC
  GGGTCAGCGCCGCATTCCGA
  AAGGCCGCCATCTGGCGGTC
  GTACCCGTCGGGAGCAATCG
  CGCATATCGAGCTCGGCGTA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.942
  Max reward: 18.142
  With intrinsic bonuses: 13.927

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9905, entropy=0.2326, kl_div=0.0000
    Epoch 1: policy_loss=-0.0135, value_loss=0.9905, entropy=0.2321, kl_div=0.0045

=== Surrogate Model Training ===
Total samples: 2354

Training on 2239 samples (removed 115 outliers)
Reward range: [9.39, 18.61], mean: 14.01
  Created 13 candidate models for data size 2239
Current R2 threshold: -0.03999999999999998
  rf-tuned-l: R2 = -0.010 (std: 0.052)
  rf-tuned-xl: R2 = -0.002 (std: 0.063)
  gb-tuned-l: R2 = 0.080 (std: 0.030)
  gb-tuned-xl: R2 = 0.080 (std: 0.030)
  xgb-xl: R2 = -0.141 (std: 0.026)
  xgb-l: R2 = -0.141 (std: 0.026)
  mlp-adaptive-xl: R2 = 0.038 (std: 0.037)
  mlp-l: R2 = 0.052 (std: 0.032)
  svr-rbf-xl: R2 = 0.100 (std: 0.047)
  svr-poly-l: R2 = 0.100 (std: 0.047)
  knn-tuned-sqrt: R2 = -0.086 (std: 0.032)
  knn-tuned-l: R2 = -0.086 (std: 0.032)
  ridge: R2 = 0.013 (std: 0.016)

Model-based training with 9 models
Best R2: 0.100, Mean R2: -0.000
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.461 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.112 mlp-l:0.000 svr-rbf-xl:0.190 svr-poly-l:0.136 ridge:0.101 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9871, entropy=0.2083, kl_div=0.0000
    Epoch 1: policy_loss=0.0490, value_loss=0.9870, entropy=0.2094, kl_div=-0.3779
  Round 1/3: Mean predicted reward = 13.716
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.461 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.112 mlp-l:0.000 svr-rbf-xl:0.190 svr-poly-l:0.136 ridge:0.101 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9852, entropy=0.2254, kl_div=0.0000
    Epoch 1: policy_loss=0.1297, value_loss=0.9852, entropy=0.2269, kl_div=-0.3944
  Round 2/3: Mean predicted reward = 14.129
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.461 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.112 mlp-l:0.000 svr-rbf-xl:0.190 svr-poly-l:0.136 ridge:0.101 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9876, entropy=0.2302, kl_div=0.0000
    Epoch 1: policy_loss=0.0407, value_loss=0.9876, entropy=0.2303, kl_div=-0.2693
  Round 3/3: Mean predicted reward = 14.131

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 36 Results ---
  Mean Oracle Reward: 13.949
  Min Oracle Reward: 6.281
  Max Oracle Reward: 17.797
  Std Oracle Reward: 2.107
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: -0.000, Max: 0.100, Count: 13
  Total Sequences Evaluated: 2354
    Oracle Count: 2304 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 37/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 2354
  Performance plateaued, reducing LR to 0.000100

--- Round 37 Configuration ---
Learning rate: 0.000100
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  AGATCCGCGCGTGTCAGCGC
  CGGGCCGAGGCTTAGTCACC
  GCGCCCTCGGGCTAATGCGA
  GGCACTGCACCTACGCGGTG
  GGGCAGTTCCGCGTAACGCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.075
  Max reward: 17.339
  With intrinsic bonuses: 14.067

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9818, entropy=0.2225, kl_div=0.0000
    Epoch 1: policy_loss=-0.0399, value_loss=0.9818, entropy=0.2228, kl_div=-0.1838

=== Surrogate Model Training ===
Total samples: 2418

Training on 2303 samples (removed 115 outliers)
Reward range: [9.39, 18.63], mean: 14.01
  Created 13 candidate models for data size 2303
Current R2 threshold: -0.02999999999999997
  rf-tuned-l: R2 = 0.003 (std: 0.062)
  rf-tuned-xl: R2 = -0.002 (std: 0.050)
  gb-tuned-l: R2 = 0.090 (std: 0.026)
  gb-tuned-xl: R2 = 0.090 (std: 0.026)
  xgb-xl: R2 = -0.131 (std: 0.042)
  xgb-l: R2 = -0.131 (std: 0.042)
  mlp-adaptive-xl: R2 = 0.041 (std: 0.062)
  mlp-l: R2 = 0.050 (std: 0.031)
  svr-rbf-xl: R2 = 0.111 (std: 0.044)
  svr-poly-l: R2 = 0.111 (std: 0.044)
  knn-tuned-sqrt: R2 = -0.070 (std: 0.030)
  knn-tuned-l: R2 = -0.070 (std: 0.030)
  ridge: R2 = 0.017 (std: 0.014)

Model-based training with 9 models
Best R2: 0.111, Mean R2: 0.008
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.321 gb-tuned-l:0.030 gb-tuned-xl:0.175 mlp-adaptive-xl:0.020 mlp-l:0.079 svr-rbf-xl:0.052 svr-poly-l:0.323 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9933, entropy=0.2411, kl_div=0.0000
    Epoch 1: policy_loss=0.0052, value_loss=0.9933, entropy=0.2416, kl_div=-0.2266
  Round 1/3: Mean predicted reward = 13.925
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.321 gb-tuned-l:0.030 gb-tuned-xl:0.175 mlp-adaptive-xl:0.020 mlp-l:0.079 svr-rbf-xl:0.052 svr-poly-l:0.323 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9782, entropy=0.2400, kl_div=0.0000
    Epoch 1: policy_loss=-0.0016, value_loss=0.9782, entropy=0.2404, kl_div=-0.2051
  Round 2/3: Mean predicted reward = 13.882
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.321 gb-tuned-l:0.030 gb-tuned-xl:0.175 mlp-adaptive-xl:0.020 mlp-l:0.079 svr-rbf-xl:0.052 svr-poly-l:0.323 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9844, entropy=0.2321, kl_div=0.0000
    Epoch 1: policy_loss=0.0026, value_loss=0.9844, entropy=0.2323, kl_div=-0.1102
  Round 3/3: Mean predicted reward = 14.034

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 37 Results ---
  Mean Oracle Reward: 14.066
  Min Oracle Reward: 5.647
  Max Oracle Reward: 17.240
  Std Oracle Reward: 1.946
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: 0.008, Max: 0.111, Count: 13
  Total Sequences Evaluated: 2418
    Oracle Count: 2368 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 38/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 2418
  Consistent improvement, increasing LR to 0.000132

--- Round 38 Configuration ---
Learning rate: 0.000132
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CCGGTCGTCCTCAGCGGGAA
  GTCGCGCCGCCATGCAGTAG
  GCGAGCGTCCGTAGACGTCC
  GCGCTATGCCCACGAGGGTC
  GCAGGCCCACCGTCGTTAGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.095
  Max reward: 19.612
  With intrinsic bonuses: 14.070

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9863, entropy=0.2527, kl_div=0.0000
    Epoch 1: policy_loss=-0.0041, value_loss=0.9863, entropy=0.2534, kl_div=-0.2227

=== Surrogate Model Training ===
Total samples: 2482

Training on 2366 samples (removed 116 outliers)
Reward range: [9.36, 18.63], mean: 14.01
  Created 13 candidate models for data size 2366
Current R2 threshold: -0.019999999999999962
  rf-tuned-l: R2 = 0.007 (std: 0.059)
  rf-tuned-xl: R2 = -0.006 (std: 0.055)
  gb-tuned-l: R2 = 0.084 (std: 0.035)
  gb-tuned-xl: R2 = 0.084 (std: 0.035)
  xgb-xl: R2 = -0.107 (std: 0.046)
  xgb-l: R2 = -0.107 (std: 0.046)
  mlp-adaptive-xl: R2 = 0.036 (std: 0.062)
  mlp-l: R2 = 0.027 (std: 0.064)
  svr-rbf-xl: R2 = 0.106 (std: 0.049)
  svr-poly-l: R2 = 0.106 (std: 0.049)
  knn-tuned-sqrt: R2 = -0.084 (std: 0.056)
  knn-tuned-l: R2 = -0.084 (std: 0.056)
  ridge: R2 = 0.007 (std: 0.023)

Model-based training with 9 models
Best R2: 0.106, Mean R2: 0.005
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.789 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.011 mlp-l:0.000 svr-rbf-xl:0.049 svr-poly-l:0.079 ridge:0.073 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9904, entropy=0.2336, kl_div=0.0000
    Epoch 1: policy_loss=-0.0300, value_loss=0.9904, entropy=0.2343, kl_div=-0.1722
  Round 1/3: Mean predicted reward = 13.920
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.789 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.011 mlp-l:0.000 svr-rbf-xl:0.049 svr-poly-l:0.079 ridge:0.073 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9817, entropy=0.2353, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2647
  Round 2/3: Mean predicted reward = 13.987
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.789 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.011 mlp-l:0.000 svr-rbf-xl:0.049 svr-poly-l:0.079 ridge:0.073 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9808, entropy=0.2319, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3542
  Round 3/3: Mean predicted reward = 14.075

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 38 Results ---
  Mean Oracle Reward: 14.036
  Min Oracle Reward: 9.439
  Max Oracle Reward: 19.655
  Std Oracle Reward: 1.739
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: 0.005, Max: 0.106, Count: 13
  Total Sequences Evaluated: 2482
    Oracle Count: 2432 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 39/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 2482
  Performance plateaued, reducing LR to 0.000019

--- Round 39 Configuration ---
Learning rate: 0.000019
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  AATCGGTGGCCCCCGTAGCG
  TGCCTGACTGGGCAGCCAAG
  TGCCGCAAAGTCGGCGCCGT
  GTCAGTACAATCTGGAGCCG
  GCGTACGGTAATGGCCCGCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.673
  Max reward: 17.251
  With intrinsic bonuses: 13.618

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9803, entropy=0.2361, kl_div=0.0000
    Epoch 1: policy_loss=-0.0056, value_loss=0.9804, entropy=0.2361, kl_div=0.0049

=== Surrogate Model Training ===
Total samples: 2546

Training on 2426 samples (removed 120 outliers)
Reward range: [9.36, 18.63], mean: 14.01
  Created 13 candidate models for data size 2426
Current R2 threshold: -0.010000000000000009
  rf-tuned-l: R2 = 0.018 (std: 0.028)
  rf-tuned-xl: R2 = 0.016 (std: 0.036)
  gb-tuned-l: R2 = 0.087 (std: 0.029)
  gb-tuned-xl: R2 = 0.087 (std: 0.029)
  xgb-xl: R2 = -0.101 (std: 0.076)
  xgb-l: R2 = -0.101 (std: 0.076)
  mlp-adaptive-xl: R2 = 0.053 (std: 0.040)
  mlp-l: R2 = 0.043 (std: 0.040)
  svr-rbf-xl: R2 = 0.103 (std: 0.033)
  svr-poly-l: R2 = 0.103 (std: 0.033)
  knn-tuned-sqrt: R2 = -0.085 (std: 0.055)
  knn-tuned-l: R2 = -0.085 (std: 0.055)
  ridge: R2 = 0.010 (std: 0.015)

Model-based training with 9 models
Best R2: 0.103, Mean R2: 0.012
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.421 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.203 mlp-l:0.190 svr-rbf-xl:0.000 svr-poly-l:0.185 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9891, entropy=0.2360, kl_div=0.0000
    Epoch 1: policy_loss=-0.0321, value_loss=0.9891, entropy=0.2362, kl_div=-0.0645
  Round 1/3: Mean predicted reward = 13.691
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.421 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.203 mlp-l:0.190 svr-rbf-xl:0.000 svr-poly-l:0.185 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9866, entropy=0.2376, kl_div=0.0000
    Epoch 1: policy_loss=-0.0076, value_loss=0.9866, entropy=0.2381, kl_div=-0.1102
  Round 2/3: Mean predicted reward = 14.031
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.421 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.203 mlp-l:0.190 svr-rbf-xl:0.000 svr-poly-l:0.185 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9844, entropy=0.2373, kl_div=0.0000
    Epoch 1: policy_loss=-0.0202, value_loss=0.9844, entropy=0.2377, kl_div=-0.0937
  Round 3/3: Mean predicted reward = 13.945

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 39 Results ---
  Mean Oracle Reward: 13.662
  Min Oracle Reward: 7.345
  Max Oracle Reward: 17.058
  Std Oracle Reward: 2.077
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: 0.012, Max: 0.103, Count: 13
  Total Sequences Evaluated: 2546
    Oracle Count: 2496 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 40/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 2546

--- Round 40 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CATAGGCTGGGCGCCCTGAC
  GCACAGCGTCTGAGCATGGC
  CGCCGCAGTCACCTGGAGGT
  GCGCTAGAGCGCTCCAGATG
  TACGGGCGGCCGGTCCTCAA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.345
  Max reward: 18.998
  With intrinsic bonuses: 14.370

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9790, entropy=0.2389, kl_div=0.0000
    Epoch 1: policy_loss=0.6414, value_loss=0.9791, entropy=0.2442, kl_div=-1.3600

=== Surrogate Model Training ===
Total samples: 2610

Training on 2489 samples (removed 121 outliers)
Reward range: [9.36, 18.63], mean: 14.02
  Created 13 candidate models for data size 2489
Current R2 threshold: 0.0
  rf-tuned-l: R2 = 0.025 (std: 0.017)
  rf-tuned-xl: R2 = 0.027 (std: 0.020)
  gb-tuned-l: R2 = 0.081 (std: 0.026)
  gb-tuned-xl: R2 = 0.081 (std: 0.026)
  xgb-xl: R2 = -0.120 (std: 0.064)
  xgb-l: R2 = -0.120 (std: 0.064)
  mlp-adaptive-xl: R2 = 0.038 (std: 0.052)
  mlp-l: R2 = 0.055 (std: 0.041)
  svr-rbf-xl: R2 = 0.102 (std: 0.033)
  svr-poly-l: R2 = 0.102 (std: 0.033)
  knn-tuned-sqrt: R2 = -0.080 (std: 0.043)
  knn-tuned-l: R2 = -0.080 (std: 0.043)
  ridge: R2 = 0.009 (std: 0.022)

Model-based training with 9 models
Best R2: 0.102, Mean R2: 0.009
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.683 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.122 svr-poly-l:0.000 ridge:0.195 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9896, entropy=0.2561, kl_div=0.0000
    Epoch 1: policy_loss=0.2983, value_loss=0.9896, entropy=0.2592, kl_div=-1.2579
  Round 1/3: Mean predicted reward = 13.840
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.683 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.122 svr-poly-l:0.000 ridge:0.195 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.2643, kl_div=0.0000
    Epoch 1: policy_loss=0.0111, value_loss=0.9842, entropy=0.2640, kl_div=-0.1283
  Round 2/3: Mean predicted reward = 13.863
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.683 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.122 svr-poly-l:0.000 ridge:0.195 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9795, entropy=0.2432, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8020
  Round 3/3: Mean predicted reward = 13.984

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 40 Results ---
  Mean Oracle Reward: 14.388
  Min Oracle Reward: 9.218
  Max Oracle Reward: 18.810
  Std Oracle Reward: 1.746
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: 0.009, Max: 0.102, Count: 13
  Total Sequences Evaluated: 2610
    Oracle Count: 2560 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 41/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 2610

--- Round 41 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GCACGATTTAGGCGCCGTAC
  CTCCGCGGCGATCAAGTCGG
  GCGCGGGGTACCCGACATCT
  TGACGTGCCCCCCAGGGTGA
  GAGCCACGCCGCTTGCTGAG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.955
  Max reward: 18.485
  With intrinsic bonuses: 13.960

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=0.2491, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1400

=== Surrogate Model Training ===
Total samples: 2674

Training on 2546 samples (removed 128 outliers)
Reward range: [9.39, 18.53], mean: 14.03
  Created 13 candidate models for data size 2546
Current R2 threshold: 0.010000000000000009
  rf-tuned-l: R2 = 0.027 (std: 0.012)
  rf-tuned-xl: R2 = 0.033 (std: 0.014)
  gb-tuned-l: R2 = 0.102 (std: 0.013)
  gb-tuned-xl: R2 = 0.102 (std: 0.013)
  xgb-xl: R2 = -0.118 (std: 0.072)
  xgb-l: R2 = -0.118 (std: 0.072)
  mlp-adaptive-xl: R2 = 0.041 (std: 0.031)
  mlp-l: R2 = 0.037 (std: 0.041)
  svr-rbf-xl: R2 = 0.111 (std: 0.019)
  svr-poly-l: R2 = 0.111 (std: 0.019)
  knn-tuned-sqrt: R2 = -0.080 (std: 0.045)
  knn-tuned-l: R2 = -0.080 (std: 0.045)
  ridge: R2 = 0.018 (std: 0.008)

Model-based training with 9 models
Best R2: 0.111, Mean R2: 0.014
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.258 rf-tuned-xl:0.385 gb-tuned-l:0.027 gb-tuned-xl:0.303 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.026 svr-poly-l:0.000 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9832, entropy=0.2367, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3588
  Round 1/3: Mean predicted reward = 14.054
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.258 rf-tuned-xl:0.385 gb-tuned-l:0.027 gb-tuned-xl:0.303 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.026 svr-poly-l:0.000 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9821, entropy=0.2404, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5214
  Round 2/3: Mean predicted reward = 13.992
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.258 rf-tuned-xl:0.385 gb-tuned-l:0.027 gb-tuned-xl:0.303 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.026 svr-poly-l:0.000 ridge:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9799, entropy=0.2569, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6047
  Round 3/3: Mean predicted reward = 14.125

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 41 Results ---
  Mean Oracle Reward: 13.955
  Min Oracle Reward: 4.730
  Max Oracle Reward: 18.181
  Std Oracle Reward: 2.173
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: 0.014, Max: 0.111, Count: 13
  Total Sequences Evaluated: 2674
    Oracle Count: 2624 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 42/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 2674

--- Round 42 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GGCGAGTTCCCCTGAGCCAG
  GGTTGCACGGGCGCCAACCT
  TCCCGGGGGGAGTCCAAACT
  CCGGCTGTGGCCAGACATGC
  GCTTCGAGGTGACGACCCGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.483
  Max reward: 19.187
  With intrinsic bonuses: 14.489

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9767, entropy=0.2332, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6986

=== Surrogate Model Training ===
Total samples: 2738

Training on 2609 samples (removed 129 outliers)
Reward range: [9.39, 18.61], mean: 14.04
  Created 13 candidate models for data size 2609
Current R2 threshold: 0.020000000000000018
  rf-tuned-l: R2 = 0.023 (std: 0.040)
  rf-tuned-xl: R2 = 0.027 (std: 0.028)
  gb-tuned-l: R2 = 0.098 (std: 0.021)
  gb-tuned-xl: R2 = 0.098 (std: 0.021)
  xgb-xl: R2 = -0.119 (std: 0.047)
  xgb-l: R2 = -0.119 (std: 0.047)
  mlp-adaptive-xl: R2 = 0.039 (std: 0.022)
  mlp-l: R2 = 0.061 (std: 0.015)
  svr-rbf-xl: R2 = 0.106 (std: 0.031)
  svr-poly-l: R2 = 0.106 (std: 0.031)
  knn-tuned-sqrt: R2 = -0.086 (std: 0.044)
  knn-tuned-l: R2 = -0.086 (std: 0.044)
  ridge: R2 = 0.023 (std: 0.008)

Model-based training with 9 models
Best R2: 0.106, Mean R2: 0.013
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.008 rf-tuned-xl:0.428 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.159 mlp-l:0.000 svr-rbf-xl:0.303 svr-poly-l:0.000 ridge:0.101 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9863, entropy=0.2243, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1925
  Round 1/3: Mean predicted reward = 14.016
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.008 rf-tuned-xl:0.428 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.159 mlp-l:0.000 svr-rbf-xl:0.303 svr-poly-l:0.000 ridge:0.101 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9807, entropy=0.2376, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5841
  Round 2/3: Mean predicted reward = 14.245
Current Method: dynamic
    Using ridge regression weights
    Model weights: rf-tuned-l:0.008 rf-tuned-xl:0.428 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.159 mlp-l:0.000 svr-rbf-xl:0.303 svr-poly-l:0.000 ridge:0.101 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9755, entropy=0.2289, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.9519
  Round 3/3: Mean predicted reward = 14.057

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 42 Results ---
  Mean Oracle Reward: 14.497
  Min Oracle Reward: 8.717
  Max Oracle Reward: 18.915
  Std Oracle Reward: 1.920
  Sequence Diversity: 1.000
  Models Used: 9
  Model R2 - Mean: 0.013, Max: 0.106, Count: 13
  Total Sequences Evaluated: 2738
    Oracle Count: 2688 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 43/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 2738

--- Round 43 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  GAGCGGTTCGGACGTCCCCA
  TCCGGGGGAGTCGCACCTAC
  ACATGGCTCGGGCCCCATGG
  GCACGCGGGTTCGAGCATCC
  GGCCACGCATGGCTGCTGCA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.699
  Max reward: 19.198
  With intrinsic bonuses: 14.689

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9725, entropy=0.2127, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6138

=== Surrogate Model Training ===
Total samples: 2802

Training on 2668 samples (removed 134 outliers)
Reward range: [9.37, 18.63], mean: 14.05
  Created 13 candidate models for data size 2668
Current R2 threshold: 0.030000000000000027
  rf-tuned-l: R2 = 0.026 (std: 0.031)
  rf-tuned-xl: R2 = 0.024 (std: 0.029)
  gb-tuned-l: R2 = 0.101 (std: 0.017)
  gb-tuned-xl: R2 = 0.101 (std: 0.017)
  xgb-xl: R2 = -0.097 (std: 0.057)
  xgb-l: R2 = -0.097 (std: 0.057)
  mlp-adaptive-xl: R2 = 0.063 (std: 0.013)
  mlp-l: R2 = 0.050 (std: 0.027)
  svr-rbf-xl: R2 = 0.111 (std: 0.028)
  svr-poly-l: R2 = 0.111 (std: 0.028)
  knn-tuned-sqrt: R2 = -0.063 (std: 0.035)
  knn-tuned-l: R2 = -0.063 (std: 0.035)
  ridge: R2 = 0.027 (std: 0.010)

Model-based training with 6 models
Best R2: 0.111, Mean R2: 0.022
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.424 mlp-adaptive-xl:0.488 mlp-l:0.000 svr-rbf-xl:0.088 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9784, entropy=0.2103, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4674
  Round 1/3: Mean predicted reward = 14.049
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.424 mlp-adaptive-xl:0.488 mlp-l:0.000 svr-rbf-xl:0.088 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9762, entropy=0.2091, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6067
  Round 2/3: Mean predicted reward = 14.080
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.424 mlp-adaptive-xl:0.488 mlp-l:0.000 svr-rbf-xl:0.088 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9780, entropy=0.2163, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.8367
  Round 3/3: Mean predicted reward = 14.110

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 43 Results ---
  Mean Oracle Reward: 14.686
  Min Oracle Reward: 6.936
  Max Oracle Reward: 19.103
  Std Oracle Reward: 2.554
  Sequence Diversity: 1.000
  Models Used: 6
  Model R2 - Mean: 0.022, Max: 0.111, Count: 13
  Total Sequences Evaluated: 2802
    Oracle Count: 2752 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}]

======================================================================
EXPERIMENT ROUND 44/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 2802
  Consistent improvement, increasing LR to 0.000045

--- Round 44 Configuration ---
Learning rate: 0.000045
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  ATGGCCCCTGAGGCTGACCG
  CAGCGCTGCGAGGACTGCCT
  CGACGGGGCGGCTCTCATAC
  TGAGTCGCCGTGAACACTCG
  CCCTCACGGACGGCGTGGTA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.306
  Max reward: 21.275
  With intrinsic bonuses: 15.266

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9689, entropy=0.2080, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3543

=== Surrogate Model Training ===
Total samples: 2866

Training on 2721 samples (removed 145 outliers)
Reward range: [9.41, 18.65], mean: 14.08
  Created 13 candidate models for data size 2721
Current R2 threshold: 0.040000000000000036
  rf-tuned-l: R2 = 0.015 (std: 0.040)
  rf-tuned-xl: R2 = 0.017 (std: 0.038)
  gb-tuned-l: R2 = 0.099 (std: 0.022)
  gb-tuned-xl: R2 = 0.099 (std: 0.022)
  xgb-xl: R2 = -0.135 (std: 0.053)
  xgb-l: R2 = -0.135 (std: 0.053)
  mlp-adaptive-xl: R2 = 0.047 (std: 0.026)
  mlp-l: R2 = 0.034 (std: 0.024)
  svr-rbf-xl: R2 = 0.101 (std: 0.033)
  svr-poly-l: R2 = 0.101 (std: 0.033)
  knn-tuned-sqrt: R2 = -0.060 (std: 0.050)
  knn-tuned-l: R2 = -0.060 (std: 0.050)
  ridge: R2 = 0.023 (std: 0.019)

Model-based training with 5 models
Best R2: 0.101, Mean R2: 0.011
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.715 mlp-adaptive-xl:0.000 svr-rbf-xl:0.211 svr-poly-l:0.074 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9864, entropy=0.2051, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2244
  Round 1/3: Mean predicted reward = 14.117
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.715 mlp-adaptive-xl:0.000 svr-rbf-xl:0.211 svr-poly-l:0.074 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9798, entropy=0.2060, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3129
  Round 2/3: Mean predicted reward = 14.221
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.715 mlp-adaptive-xl:0.000 svr-rbf-xl:0.211 svr-poly-l:0.074 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9715, entropy=0.1906, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3441
  Round 3/3: Mean predicted reward = 14.186

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 44 Results ---
  Mean Oracle Reward: 15.273
  Min Oracle Reward: 11.629
  Max Oracle Reward: 21.049
  Std Oracle Reward: 2.358
  Sequence Diversity: 1.000
  Models Used: 5
  Model R2 - Mean: 0.011, Max: 0.101, Count: 13
  New best mean reward!
  Total Sequences Evaluated: 2866
    Oracle Count: 2816 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}]

======================================================================
EXPERIMENT ROUND 45/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 2866
  Consistent improvement, increasing LR to 0.000360

--- Round 45 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CGCTAGACGGATCCTGGCCG
  CGGCGGTCAAGCTGCCGACT
  CTCCGCAAGCTGTGGGAGCC
  CTGTGGCCGCACAAGGGTCC
  GCTCCACGTCCGGGTGAACG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.469
  Max reward: 20.501
  With intrinsic bonuses: 14.458

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9717, entropy=0.2044, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.3264

=== Surrogate Model Training ===
Total samples: 2930

Training on 2776 samples (removed 154 outliers)
Reward range: [9.41, 18.65], mean: 14.08
  Created 13 candidate models for data size 2776
Current R2 threshold: 0.050000000000000044
  rf-tuned-l: R2 = -0.005 (std: 0.056)
  rf-tuned-xl: R2 = -0.001 (std: 0.056)
  gb-tuned-l: R2 = 0.095 (std: 0.032)
  gb-tuned-xl: R2 = 0.095 (std: 0.032)
  xgb-xl: R2 = -0.140 (std: 0.046)
  xgb-l: R2 = -0.140 (std: 0.046)
  mlp-adaptive-xl: R2 = 0.038 (std: 0.029)
  mlp-l: R2 = 0.043 (std: 0.035)
  svr-rbf-xl: R2 = 0.094 (std: 0.041)
  svr-poly-l: R2 = 0.094 (std: 0.041)
  knn-tuned-sqrt: R2 = -0.075 (std: 0.054)
  knn-tuned-l: R2 = -0.075 (std: 0.054)
  ridge: R2 = 0.022 (std: 0.030)

Model-based training with 4 models
Best R2: 0.095, Mean R2: 0.003
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:1.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9827, entropy=0.1990, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.4038
  Round 1/3: Mean predicted reward = 13.960
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:1.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9750, entropy=0.1886, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.8044
  Round 2/3: Mean predicted reward = 14.306
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:1.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9767, entropy=0.1896, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.4378
  Round 3/3: Mean predicted reward = 14.424

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 45 Results ---
  Mean Oracle Reward: 14.470
  Min Oracle Reward: 3.743
  Max Oracle Reward: 20.279
  Std Oracle Reward: 2.943
  Sequence Diversity: 1.000
  Models Used: 4
  Model R2 - Mean: 0.003, Max: 0.095, Count: 13
  Total Sequences Evaluated: 2930
    Oracle Count: 2880 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}]

======================================================================
EXPERIMENT ROUND 46/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 2930

--- Round 46 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 1.000) ---
  CACGGCCATCGCTACGTGGG
  GCGGCTGCGATGCATCCCGA
  GCGGAGTCCCGTAGGTCCAC
  GTCGAACGTGTACTCACGCG
  TCGGCGGACGGCCTTCACGA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.826
  Max reward: 21.190
  With intrinsic bonuses: 14.831

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9735, entropy=0.1730, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.2597

=== Surrogate Model Training ===
Total samples: 2994

Training on 2835 samples (removed 159 outliers)
Reward range: [9.40, 18.70], mean: 14.09
  Created 13 candidate models for data size 2835
Current R2 threshold: 0.06
  rf-tuned-l: R2 = -0.009 (std: 0.055)
  rf-tuned-xl: R2 = -0.008 (std: 0.060)
  gb-tuned-l: R2 = 0.091 (std: 0.041)
  gb-tuned-xl: R2 = 0.091 (std: 0.041)
  xgb-xl: R2 = -0.139 (std: 0.046)
  xgb-l: R2 = -0.139 (std: 0.046)
  mlp-adaptive-xl: R2 = 0.049 (std: 0.034)
  mlp-l: R2 = 0.030 (std: 0.036)
  svr-rbf-xl: R2 = 0.089 (std: 0.049)
  svr-poly-l: R2 = 0.089 (std: 0.049)
  knn-tuned-sqrt: R2 = -0.084 (std: 0.060)
  knn-tuned-l: R2 = -0.084 (std: 0.060)
  ridge: R2 = 0.023 (std: 0.037)

Model-based training with 4 models
Best R2: 0.091, Mean R2: -0.000
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.401 svr-rbf-xl:0.599 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9781, entropy=0.1713, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.1157
  Round 1/3: Mean predicted reward = 14.032
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.401 svr-rbf-xl:0.599 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9733, entropy=0.1630, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.3429
  Round 2/3: Mean predicted reward = 14.396
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.401 svr-rbf-xl:0.599 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9741, entropy=0.1438, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 2.4979
  Round 3/3: Mean predicted reward = 14.473

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 46 Results ---
  Mean Oracle Reward: 14.856
  Min Oracle Reward: 3.672
  Max Oracle Reward: 21.282
  Std Oracle Reward: 2.856
  Sequence Diversity: 1.000
  Models Used: 4
  Model R2 - Mean: -0.000, Max: 0.091, Count: 13
  Total Sequences Evaluated: 2994
    Oracle Count: 2944 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}]

======================================================================
EXPERIMENT ROUND 47/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 2994

--- Round 47 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.891) ---
  TCCCGTGCAGTGCGGAGCAC
  TCGGTACCGTGCGCAAGCCG
  GCGCTCGTAGATCCGGCCGA
  CCATGCTGGATCCCGAGGGC
  GCCGAGGCGCCTCATTCAGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.922
  Max reward: 21.311
  With intrinsic bonuses: 15.913

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9663, entropy=0.1198, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.8123

=== Surrogate Model Training ===
Total samples: 3058

Training on 2890 samples (removed 168 outliers)
Reward range: [9.39, 18.73], mean: 14.10
  Created 13 candidate models for data size 2890
Current R2 threshold: 0.07
  rf-tuned-l: R2 = -0.023 (std: 0.069)
  rf-tuned-xl: R2 = -0.021 (std: 0.065)
  gb-tuned-l: R2 = 0.090 (std: 0.042)
  gb-tuned-xl: R2 = 0.090 (std: 0.042)
  xgb-xl: R2 = -0.133 (std: 0.056)
  xgb-l: R2 = -0.133 (std: 0.056)
  mlp-adaptive-xl: R2 = 0.039 (std: 0.036)
  mlp-l: R2 = 0.035 (std: 0.044)
  svr-rbf-xl: R2 = 0.088 (std: 0.051)
  svr-poly-l: R2 = 0.088 (std: 0.051)
  knn-tuned-sqrt: R2 = -0.092 (std: 0.064)
  knn-tuned-l: R2 = -0.092 (std: 0.064)
  ridge: R2 = 0.025 (std: 0.035)

Model-based training with 4 models
Best R2: 0.090, Mean R2: -0.003
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.833 svr-rbf-xl:0.167 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9843, entropy=0.1131, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.1887
  Round 1/3: Mean predicted reward = 13.979
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.833 svr-rbf-xl:0.167 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9695, entropy=0.1232, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.4163
  Round 2/3: Mean predicted reward = 14.320
Current Method: dynamic
    Using ridge regression weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.833 svr-rbf-xl:0.167 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9726, entropy=0.1181, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.6773
  Round 3/3: Mean predicted reward = 14.478

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 47 Results ---
  Mean Oracle Reward: 15.944
  Min Oracle Reward: 10.927
  Max Oracle Reward: 21.299
  Std Oracle Reward: 2.880
  Sequence Diversity: 0.891
  Models Used: 4
  Model R2 - Mean: -0.003, Max: 0.090, Count: 13
  New best mean reward!
  Total Sequences Evaluated: 3058
    Oracle Count: 3008 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 48/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 3058
  Consistent improvement, increasing LR to 0.000132

--- Round 48 Configuration ---
Learning rate: 0.000132
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.891) ---
  GAGCTGAGACCGGCCCTCGT
  AGTGCCGCAGCGGCAGTCTC
  CCCTGCAACGGTACGGTGCG
  TTGCGCGACAGGGTACCTAC
  GCATCGCCTCCGCAGTGGGA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.155
  Max reward: 20.163
  With intrinsic bonuses: 15.159

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9731, entropy=0.1126, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 1.0868

=== Surrogate Model Training ===
Total samples: 3122

Training on 2948 samples (removed 174 outliers)
Reward range: [9.39, 18.76], mean: 14.12
  Created 13 candidate models for data size 2948
Current R2 threshold: 0.08000000000000002
  rf-tuned-l: R2 = -0.024 (std: 0.087)
  rf-tuned-xl: R2 = -0.025 (std: 0.083)
  gb-tuned-l: R2 = 0.079 (std: 0.060)
  gb-tuned-xl: R2 = 0.079 (std: 0.060)
  xgb-xl: R2 = -0.150 (std: 0.063)
  xgb-l: R2 = -0.150 (std: 0.063)
  mlp-adaptive-xl: R2 = 0.032 (std: 0.056)
  mlp-l: R2 = 0.043 (std: 0.065)
  svr-rbf-xl: R2 = 0.082 (std: 0.068)
  svr-poly-l: R2 = 0.082 (std: 0.068)
  knn-tuned-sqrt: R2 = -0.108 (std: 0.067)
  knn-tuned-l: R2 = -0.108 (std: 0.067)
  ridge: R2 = 0.016 (std: 0.041)

Model-based training with 2 models
Best R2: 0.082, Mean R2: -0.012
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9889, entropy=0.1158, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6075
  Round 1/3: Mean predicted reward = 13.726
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9741, entropy=0.0978, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5627
  Round 2/3: Mean predicted reward = 14.458
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9741, entropy=0.1029, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6515
  Round 3/3: Mean predicted reward = 14.359

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 48 Results ---
  Mean Oracle Reward: 15.145
  Min Oracle Reward: 8.719
  Max Oracle Reward: 20.125
  Std Oracle Reward: 2.243
  Sequence Diversity: 0.891
  Models Used: 2
  Model R2 - Mean: -0.012, Max: 0.082, Count: 13
  Total Sequences Evaluated: 3122
    Oracle Count: 3072 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 49/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 3122

--- Round 49 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.969) ---
  CAAGCTTCCGGTGCGCGAGC
  CACTAGCTGCGGCGCGTGAC
  TGCGTAGCACACGCGTCCGG
  TCCAGCAGGGCCGCAGGTTC
  ACCCTTGCTGGGCCGCGGAA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.880
  Max reward: 19.127
  With intrinsic bonuses: 14.868

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9716, entropy=0.1081, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1537

=== Surrogate Model Training ===
Total samples: 3186

Training on 3016 samples (removed 170 outliers)
Reward range: [9.37, 18.82], mean: 14.14
  Created 13 candidate models for data size 3016
Current R2 threshold: 0.09000000000000002
  rf-tuned-l: R2 = -0.011 (std: 0.118)
  rf-tuned-xl: R2 = -0.010 (std: 0.108)
  gb-tuned-l: R2 = 0.080 (std: 0.084)
  gb-tuned-xl: R2 = 0.080 (std: 0.084)
  xgb-xl: R2 = -0.128 (std: 0.119)
  xgb-l: R2 = -0.128 (std: 0.119)
  mlp-adaptive-xl: R2 = 0.036 (std: 0.086)
  mlp-l: R2 = 0.047 (std: 0.078)
  svr-rbf-xl: R2 = 0.089 (std: 0.092)
  svr-poly-l: R2 = 0.089 (std: 0.092)
  knn-tuned-sqrt: R2 = -0.074 (std: 0.095)
  knn-tuned-l: R2 = -0.074 (std: 0.095)
  ridge: R2 = 0.013 (std: 0.057)
  Fallback: Using svr-rbf-xl with R2 = 0.089

Model-based training with 1 models
Best R2: 0.089, Mean R2: 0.001
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9923, entropy=0.1003, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1269
  Round 1/3: Mean predicted reward = 13.718
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9722, entropy=0.1025, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1465
  Round 2/3: Mean predicted reward = 14.642
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9717, entropy=0.0941, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1929
  Round 3/3: Mean predicted reward = 14.765

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 49 Results ---
  Mean Oracle Reward: 14.871
  Min Oracle Reward: 9.949
  Max Oracle Reward: 19.072
  Std Oracle Reward: 2.458
  Sequence Diversity: 0.969
  Models Used: 1
  Model R2 - Mean: 0.001, Max: 0.089, Count: 13
  Total Sequences Evaluated: 3186
    Oracle Count: 3136 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 50/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 3186

--- Round 50 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.953) ---
  GTGAACGTCGGCCGCAGCCT
  CCTTGCGGCGCCCTGAAAGG
  CGGCCCCCTAGGGACGTAGT
  GGCGTGGGCCGCCTTACCAA
  GCCGCCATATGGCTGGAGAC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.186
  Max reward: 19.854
  With intrinsic bonuses: 15.181

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9739, entropy=0.1010, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.9764

=== Surrogate Model Training ===
Total samples: 3250

Training on 3078 samples (removed 172 outliers)
Reward range: [9.36, 18.86], mean: 14.15
  Created 13 candidate models for data size 3078
Current R2 threshold: 0.10000000000000003
  rf-tuned-l: R2 = -0.004 (std: 0.120)
  rf-tuned-xl: R2 = -0.005 (std: 0.117)
  gb-tuned-l: R2 = 0.078 (std: 0.087)
  gb-tuned-xl: R2 = 0.078 (std: 0.087)
  xgb-xl: R2 = -0.118 (std: 0.127)
  xgb-l: R2 = -0.118 (std: 0.127)
  mlp-adaptive-xl: R2 = 0.048 (std: 0.079)
  mlp-l: R2 = 0.029 (std: 0.092)
  svr-rbf-xl: R2 = 0.086 (std: 0.097)
  svr-poly-l: R2 = 0.086 (std: 0.097)
  knn-tuned-sqrt: R2 = -0.073 (std: 0.101)
  knn-tuned-l: R2 = -0.073 (std: 0.101)
  ridge: R2 = 0.010 (std: 0.059)
  Fallback: Using svr-rbf-xl with R2 = 0.086

Model-based training with 1 models
Best R2: 0.086, Mean R2: 0.002
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9979, entropy=0.0935, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4458
  Round 1/3: Mean predicted reward = 12.941
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9728, entropy=0.0753, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.7813
  Round 2/3: Mean predicted reward = 14.643
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9703, entropy=0.0714, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.7625
  Round 3/3: Mean predicted reward = 14.842

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 50 Results ---
  Mean Oracle Reward: 15.179
  Min Oracle Reward: 9.457
  Max Oracle Reward: 19.859
  Std Oracle Reward: 2.195
  Sequence Diversity: 0.953
  Models Used: 1
  Model R2 - Mean: 0.002, Max: 0.086, Count: 13
  Total Sequences Evaluated: 3250
    Oracle Count: 3200 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 51/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 3250

--- Round 51 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.844) ---
  CCTGAACTACGGCGCGGCGT
  TGAATCAGCCTGGGCCCGCG
  AGTGGGCCCTACCGAGCCGT
  ATTGGCCCGCCCAAGCTGGG
  AGGTCGCTTGCGCACACGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.126
  Max reward: 19.085
  With intrinsic bonuses: 15.121

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9690, entropy=0.0709, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5196

=== Surrogate Model Training ===
Total samples: 3314

Training on 3140 samples (removed 174 outliers)
Reward range: [9.36, 18.90], mean: 14.17
  Created 13 candidate models for data size 3140
Current R2 threshold: 0.11000000000000004
  rf-tuned-l: R2 = 0.001 (std: 0.125)
  rf-tuned-xl: R2 = 0.003 (std: 0.130)
  gb-tuned-l: R2 = 0.077 (std: 0.084)
  gb-tuned-xl: R2 = 0.077 (std: 0.084)
  xgb-xl: R2 = -0.072 (std: 0.129)
  xgb-l: R2 = -0.072 (std: 0.129)
  mlp-adaptive-xl: R2 = 0.042 (std: 0.097)
  mlp-l: R2 = 0.043 (std: 0.085)
  svr-rbf-xl: R2 = 0.089 (std: 0.099)
  svr-poly-l: R2 = 0.089 (std: 0.099)
  knn-tuned-sqrt: R2 = -0.061 (std: 0.101)
  knn-tuned-l: R2 = -0.061 (std: 0.101)
  ridge: R2 = 0.005 (std: 0.056)
  Fallback: Using svr-rbf-xl with R2 = 0.089

Model-based training with 1 models
Best R2: 0.089, Mean R2: 0.012
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9990, entropy=0.0705, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1207
  Round 1/3: Mean predicted reward = 12.811
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9706, entropy=0.0580, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3774
  Round 2/3: Mean predicted reward = 14.870
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9699, entropy=0.0554, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6302
  Round 3/3: Mean predicted reward = 14.885

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 51 Results ---
  Mean Oracle Reward: 15.076
  Min Oracle Reward: 7.279
  Max Oracle Reward: 19.145
  Std Oracle Reward: 2.578
  Sequence Diversity: 0.844
  Models Used: 1
  Model R2 - Mean: 0.012, Max: 0.089, Count: 13
  Total Sequences Evaluated: 3314
    Oracle Count: 3264 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 52/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 3314

--- Round 52 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.828) ---
  CTCGCACGGGCCCGTGGAAT
  GCGGAACCCTCCTGGAGCTG
  GAGCTCCCCAGGTAGCGGTC
  CTAGGCGCATGCCGCGCGAT
  AGGCGTGTGCCGCCTCCAGA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.169
  Max reward: 19.184
  With intrinsic bonuses: 15.160

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9724, entropy=0.0510, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.6989

=== Surrogate Model Training ===
Total samples: 3378

Training on 3206 samples (removed 172 outliers)
Reward range: [9.36, 18.95], mean: 14.20
  Created 13 candidate models for data size 3206
Current R2 threshold: 0.12
  rf-tuned-l: R2 = 0.032 (std: 0.117)
  rf-tuned-xl: R2 = 0.030 (std: 0.123)
  gb-tuned-l: R2 = 0.079 (std: 0.069)
  gb-tuned-xl: R2 = 0.079 (std: 0.069)
  xgb-xl: R2 = -0.066 (std: 0.125)
  xgb-l: R2 = -0.066 (std: 0.125)
  mlp-adaptive-xl: R2 = 0.048 (std: 0.096)
  mlp-l: R2 = 0.053 (std: 0.085)
  svr-rbf-xl: R2 = 0.100 (std: 0.092)
  svr-poly-l: R2 = 0.100 (std: 0.092)
  knn-tuned-sqrt: R2 = -0.043 (std: 0.118)
  knn-tuned-l: R2 = -0.043 (std: 0.118)
  ridge: R2 = -0.003 (std: 0.054)
  Fallback: Using svr-rbf-xl with R2 = 0.100

Model-based training with 1 models
Best R2: 0.100, Mean R2: 0.023
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=11.9987, entropy=0.0522, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2933
  Round 1/3: Mean predicted reward = 11.635
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9707, entropy=0.0485, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3970
  Round 2/3: Mean predicted reward = 14.906
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9699, entropy=0.0504, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5351
  Round 3/3: Mean predicted reward = 15.085

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 52 Results ---
  Mean Oracle Reward: 15.164
  Min Oracle Reward: 7.774
  Max Oracle Reward: 19.045
  Std Oracle Reward: 2.373
  Sequence Diversity: 0.828
  Models Used: 1
  Model R2 - Mean: 0.023, Max: 0.100, Count: 13
  Total Sequences Evaluated: 3378
    Oracle Count: 3328 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 53/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 3378
  Performance plateaued, reducing LR to 0.000055

--- Round 53 Configuration ---
Learning rate: 0.000055
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.812) ---
  GGAGGACCCCGCACGTCTTG
  TGTCCCCGAATGGAGCCGCG
  AGGTGCTACCCCGGTCGACG
  GCCGCTTCCGGGAACCAGTG
  AAGGTCGACGCGTGCCCGTC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.622
  Max reward: 18.997
  With intrinsic bonuses: 14.692

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9725, entropy=0.0530, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1107

=== Surrogate Model Training ===
Total samples: 3442

Training on 3269 samples (removed 173 outliers)
Reward range: [9.36, 18.95], mean: 14.21
  Created 13 candidate models for data size 3269
Current R2 threshold: 0.13
  rf-tuned-l: R2 = 0.029 (std: 0.138)
  rf-tuned-xl: R2 = 0.032 (std: 0.136)
  gb-tuned-l: R2 = 0.079 (std: 0.073)
  gb-tuned-xl: R2 = 0.079 (std: 0.073)
  xgb-xl: R2 = -0.059 (std: 0.158)
  xgb-l: R2 = -0.059 (std: 0.158)
  mlp-adaptive-xl: R2 = 0.062 (std: 0.096)
  mlp-l: R2 = 0.071 (std: 0.104)
  svr-rbf-xl: R2 = 0.112 (std: 0.096)
  svr-poly-l: R2 = 0.112 (std: 0.096)
  knn-tuned-sqrt: R2 = -0.042 (std: 0.150)
  knn-tuned-l: R2 = -0.042 (std: 0.150)
  ridge: R2 = -0.002 (std: 0.051)
  Fallback: Using svr-rbf-xl with R2 = 0.112

Model-based training with 1 models
Best R2: 0.112, Mean R2: 0.029
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=30.4507, entropy=0.0554, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0645
  Round 1/3: Mean predicted reward = 10.941
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9724, entropy=0.0526, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0829
  Round 2/3: Mean predicted reward = 14.931
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9725, entropy=0.0543, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1513
  Round 3/3: Mean predicted reward = 15.192

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 53 Results ---
  Mean Oracle Reward: 14.655
  Min Oracle Reward: 7.528
  Max Oracle Reward: 18.940
  Std Oracle Reward: 2.194
  Sequence Diversity: 0.812
  Models Used: 1
  Model R2 - Mean: 0.029, Max: 0.112, Count: 13
  Total Sequences Evaluated: 3442
    Oracle Count: 3392 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 54/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 3442

--- Round 54 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.844) ---
  TGCTGCCCGTGGAAAGCGCC
  TGGCGGGATCACTAGCGCCC
  CCTGTGGGCGCCCAAGTGCA
  GGCTTACACGCTAGGCCGGC
  AAGGTCTCGGCCTCAGCGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.000
  Max reward: 19.001
  With intrinsic bonuses: 14.990

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9726, entropy=0.0543, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0729

=== Surrogate Model Training ===
Total samples: 3506

Training on 3338 samples (removed 168 outliers)
Reward range: [9.36, 18.99], mean: 14.24
  Created 13 candidate models for data size 3338
Current R2 threshold: 0.14
  rf-tuned-l: R2 = 0.061 (std: 0.133)
  rf-tuned-xl: R2 = 0.061 (std: 0.132)
  gb-tuned-l: R2 = 0.102 (std: 0.057)
  gb-tuned-xl: R2 = 0.102 (std: 0.057)
  xgb-xl: R2 = -0.030 (std: 0.138)
  xgb-l: R2 = -0.030 (std: 0.138)
  mlp-adaptive-xl: R2 = 0.085 (std: 0.100)
  mlp-l: R2 = 0.104 (std: 0.069)
  svr-rbf-xl: R2 = 0.131 (std: 0.081)
  svr-poly-l: R2 = 0.131 (std: 0.081)
  knn-tuned-sqrt: R2 = -0.003 (std: 0.124)
  knn-tuned-l: R2 = -0.003 (std: 0.124)
  ridge: R2 = 0.006 (std: 0.037)
  Fallback: Using svr-rbf-xl with R2 = 0.131

Model-based training with 1 models
Best R2: 0.131, Mean R2: 0.055
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=28.8194, entropy=0.0535, kl_div=0.0000
    Epoch 1: policy_loss=0.0110, value_loss=28.8194, entropy=0.0534, kl_div=0.0183
  Round 1/3: Mean predicted reward = 10.629
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9704, entropy=0.0611, kl_div=0.0000
    Epoch 1: policy_loss=-0.0076, value_loss=0.9705, entropy=0.0610, kl_div=0.0248
  Round 2/3: Mean predicted reward = 14.786
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9706, entropy=0.0565, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0928
  Round 3/3: Mean predicted reward = 14.980

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 54 Results ---
  Mean Oracle Reward: 14.987
  Min Oracle Reward: 10.682
  Max Oracle Reward: 18.989
  Std Oracle Reward: 1.856
  Sequence Diversity: 0.844
  Models Used: 1
  Model R2 - Mean: 0.055, Max: 0.131, Count: 13
  Total Sequences Evaluated: 3506
    Oracle Count: 3456 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 55/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 3506

--- Round 55 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.891) ---
  GACCCTCTTGCAGCGACGGG
  ATCTGCCAGCTCGCGCAGGG
  GAACCGGCAGCTCCTTCGGG
  CGTCCACGATCCGGTGAGGC
  TATGCGCGGAGCGCCACGTC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.667
  Max reward: 19.145
  With intrinsic bonuses: 14.658

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9751, entropy=0.0578, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2965

=== Surrogate Model Training ===
Total samples: 3570

Training on 3404 samples (removed 166 outliers)
Reward range: [9.36, 19.01], mean: 14.25
  Created 13 candidate models for data size 3404
Current R2 threshold: 0.15000000000000002
  rf-tuned-l: R2 = 0.095 (std: 0.134)
  rf-tuned-xl: R2 = 0.099 (std: 0.143)
  gb-tuned-l: R2 = 0.132 (std: 0.066)
  gb-tuned-xl: R2 = 0.132 (std: 0.066)
  xgb-xl: R2 = 0.012 (std: 0.143)
  xgb-l: R2 = 0.012 (std: 0.143)
  mlp-adaptive-xl: R2 = 0.127 (std: 0.104)
  mlp-l: R2 = 0.123 (std: 0.110)
  svr-rbf-xl: R2 = 0.163 (std: 0.091)
  svr-poly-l: R2 = 0.163 (std: 0.091)
  knn-tuned-sqrt: R2 = 0.029 (std: 0.140)
  knn-tuned-l: R2 = 0.029 (std: 0.140)
  ridge: R2 = 0.022 (std: 0.047)

Model-based training with 2 models
Best R2: 0.163, Mean R2: 0.088
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=50.7265, entropy=0.0563, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0602
  Round 1/3: Mean predicted reward = 9.943
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9733, entropy=0.0611, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1227
  Round 2/3: Mean predicted reward = 14.806
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9715, entropy=0.0562, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3027
  Round 3/3: Mean predicted reward = 14.972

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 55 Results ---
  Mean Oracle Reward: 14.656
  Min Oracle Reward: 10.051
  Max Oracle Reward: 19.004
  Std Oracle Reward: 2.204
  Sequence Diversity: 0.891
  Models Used: 2
  Model R2 - Mean: 0.088, Max: 0.163, Count: 13
  Total Sequences Evaluated: 3570
    Oracle Count: 3520 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 56/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 3570

--- Round 56 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.859) ---
  GTTCAGGCCCGAGGGCACCT
  AACCAGCGCTTTCGCGGGGC
  CACGCGCGGGGTGATACCTC
  GTCCGGAGCCCTACGTACGG
  CTCGAACGAGGGTTCCCGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.755
  Max reward: 19.282
  With intrinsic bonuses: 14.797

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9765, entropy=0.0581, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0784

=== Surrogate Model Training ===
Total samples: 3634

Training on 3463 samples (removed 171 outliers)
Reward range: [9.39, 19.01], mean: 14.26
  Created 13 candidate models for data size 3463
Current R2 threshold: 0.16000000000000003
  rf-tuned-l: R2 = 0.094 (std: 0.138)
  rf-tuned-xl: R2 = 0.093 (std: 0.135)
  gb-tuned-l: R2 = 0.134 (std: 0.068)
  gb-tuned-xl: R2 = 0.134 (std: 0.068)
  xgb-xl: R2 = 0.011 (std: 0.145)
  xgb-l: R2 = 0.011 (std: 0.145)
  mlp-adaptive-xl: R2 = 0.126 (std: 0.109)
  mlp-l: R2 = 0.127 (std: 0.115)
  svr-rbf-xl: R2 = 0.163 (std: 0.090)
  svr-poly-l: R2 = 0.163 (std: 0.090)
  knn-tuned-sqrt: R2 = 0.031 (std: 0.147)
  knn-tuned-l: R2 = 0.031 (std: 0.147)
  ridge: R2 = 0.021 (std: 0.048)

Model-based training with 2 models
Best R2: 0.163, Mean R2: 0.088
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:0.283 svr-poly-l:0.717 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=67.5289, entropy=0.0592, kl_div=0.0000
    Epoch 1: policy_loss=0.0733, value_loss=67.5291, entropy=0.0555, kl_div=-0.0732
  Round 1/3: Mean predicted reward = 10.239
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:0.283 svr-poly-l:0.717 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9732, entropy=0.0593, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2839
  Round 2/3: Mean predicted reward = 14.994
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:0.283 svr-poly-l:0.717 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9723, entropy=0.0536, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.5720
  Round 3/3: Mean predicted reward = 14.854

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 56 Results ---
  Mean Oracle Reward: 14.783
  Min Oracle Reward: 8.806
  Max Oracle Reward: 19.131
  Std Oracle Reward: 2.130
  Sequence Diversity: 0.859
  Models Used: 2
  Model R2 - Mean: 0.088, Max: 0.163, Count: 13
  Total Sequences Evaluated: 3634
    Oracle Count: 3584 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 57/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 3634

--- Round 57 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.859) ---
  ATCAGCGCGGCCCTCAGGTG
  CTGGGAACCCTCGAGCGGCT
  AGGTCGGACCTTGGCGACCC
  ATCGCGCAGCAGGTGTCGCC
  CATAGACTGTGGGCCCCCGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.900
  Max reward: 19.250
  With intrinsic bonuses: 14.899

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9750, entropy=0.0596, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0811

=== Surrogate Model Training ===
Total samples: 3698

Training on 3525 samples (removed 173 outliers)
Reward range: [9.39, 19.01], mean: 14.27
  Created 13 candidate models for data size 3525
Current R2 threshold: 0.17000000000000004
  rf-tuned-l: R2 = 0.100 (std: 0.162)
  rf-tuned-xl: R2 = 0.098 (std: 0.165)
  gb-tuned-l: R2 = 0.127 (std: 0.081)
  gb-tuned-xl: R2 = 0.127 (std: 0.081)
  xgb-xl: R2 = 0.009 (std: 0.168)
  xgb-l: R2 = 0.009 (std: 0.168)
  mlp-adaptive-xl: R2 = 0.124 (std: 0.133)
  mlp-l: R2 = 0.123 (std: 0.116)
  svr-rbf-xl: R2 = 0.162 (std: 0.108)
  svr-poly-l: R2 = 0.162 (std: 0.108)
  knn-tuned-sqrt: R2 = 0.028 (std: 0.167)
  knn-tuned-l: R2 = 0.028 (std: 0.167)
  ridge: R2 = 0.018 (std: 0.066)
  Fallback: Using svr-rbf-xl with R2 = 0.162

Model-based training with 1 models
Best R2: 0.162, Mean R2: 0.086
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=22.9649, entropy=0.0575, kl_div=0.0000
    Epoch 1: policy_loss=-0.0112, value_loss=22.9650, entropy=0.0569, kl_div=-0.0320
  Round 1/3: Mean predicted reward = 9.548
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9743, entropy=0.0574, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1254
  Round 2/3: Mean predicted reward = 15.003
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9762, entropy=0.0605, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1554
  Round 3/3: Mean predicted reward = 15.012

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 57 Results ---
  Mean Oracle Reward: 14.925
  Min Oracle Reward: 8.180
  Max Oracle Reward: 19.140
  Std Oracle Reward: 2.058
  Sequence Diversity: 0.859
  Models Used: 1
  Model R2 - Mean: 0.086, Max: 0.162, Count: 13
  Total Sequences Evaluated: 3698
    Oracle Count: 3648 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 58/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 3698
  Performance plateaued, reducing LR to 0.000055

--- Round 58 Configuration ---
Learning rate: 0.000055
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.891) ---
  GACCTCGGTACGGGTACCGC
  GCGAGCTCGCCAGAGTTCCG
  CAGGTGACGGCCGCGCACTT
  ACCGGCGTGCATCATGGCCG
  CCCGCCTCGGGGATGATAGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.292
  Max reward: 18.072
  With intrinsic bonuses: 14.319

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9777, entropy=0.0655, kl_div=0.0000
    Epoch 1: policy_loss=0.0029, value_loss=0.9777, entropy=0.0654, kl_div=0.0139

=== Surrogate Model Training ===
Total samples: 3762

Training on 3587 samples (removed 175 outliers)
Reward range: [9.39, 19.01], mean: 14.28
  Created 13 candidate models for data size 3587
Current R2 threshold: 0.18
  rf-tuned-l: R2 = 0.114 (std: 0.159)
  rf-tuned-xl: R2 = 0.120 (std: 0.159)
  gb-tuned-l: R2 = 0.138 (std: 0.089)
  gb-tuned-xl: R2 = 0.138 (std: 0.089)
  xgb-xl: R2 = 0.034 (std: 0.170)
  xgb-l: R2 = 0.034 (std: 0.170)
  mlp-adaptive-xl: R2 = 0.131 (std: 0.124)
  mlp-l: R2 = 0.124 (std: 0.106)
  svr-rbf-xl: R2 = 0.173 (std: 0.113)
  svr-poly-l: R2 = 0.173 (std: 0.113)
  knn-tuned-sqrt: R2 = 0.028 (std: 0.165)
  knn-tuned-l: R2 = 0.028 (std: 0.165)
  ridge: R2 = 0.025 (std: 0.070)
  Fallback: Using svr-rbf-xl with R2 = 0.173

Model-based training with 1 models
Best R2: 0.173, Mean R2: 0.097
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=45.0873, entropy=0.0594, kl_div=0.0000
    Epoch 1: policy_loss=-0.0179, value_loss=45.0873, entropy=0.0594, kl_div=0.0057
  Round 1/3: Mean predicted reward = 9.610
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9757, entropy=0.0652, kl_div=0.0000
    Epoch 1: policy_loss=0.0002, value_loss=0.9757, entropy=0.0654, kl_div=0.0434
  Round 2/3: Mean predicted reward = 14.881
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9767, entropy=0.0708, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0553
  Round 3/3: Mean predicted reward = 14.981

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 58 Results ---
  Mean Oracle Reward: 14.279
  Min Oracle Reward: 6.215
  Max Oracle Reward: 18.211
  Std Oracle Reward: 2.134
  Sequence Diversity: 0.891
  Models Used: 1
  Model R2 - Mean: 0.097, Max: 0.173, Count: 13
  Total Sequences Evaluated: 3762
    Oracle Count: 3712 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 59/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 3762

--- Round 59 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.891) ---
  GCAAACGCCGTCGCTGGTCG
  GCCCATCGCGAGCGGAGTTC
  CCCAGGACCCTATTGGGGGC
  GTCTCACCCAACGGGGTGCG
  GTGCTGACACAGCCGGTCCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.588
  Max reward: 18.538
  With intrinsic bonuses: 14.528

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9787, entropy=0.0623, kl_div=0.0000
    Epoch 1: policy_loss=0.0039, value_loss=0.9787, entropy=0.0623, kl_div=0.0183

=== Surrogate Model Training ===
Total samples: 3826

Training on 3646 samples (removed 180 outliers)
Reward range: [9.41, 19.01], mean: 14.29
  Created 13 candidate models for data size 3646
Current R2 threshold: 0.19
  rf-tuned-l: R2 = 0.117 (std: 0.172)
  rf-tuned-xl: R2 = 0.123 (std: 0.173)
  gb-tuned-l: R2 = 0.135 (std: 0.094)
  gb-tuned-xl: R2 = 0.135 (std: 0.094)
  xgb-xl: R2 = 0.030 (std: 0.182)
  xgb-l: R2 = 0.030 (std: 0.182)
  mlp-adaptive-xl: R2 = 0.124 (std: 0.110)
  mlp-l: R2 = 0.137 (std: 0.133)
  svr-rbf-xl: R2 = 0.175 (std: 0.124)
  svr-poly-l: R2 = 0.175 (std: 0.124)
  knn-tuned-sqrt: R2 = 0.027 (std: 0.173)
  knn-tuned-l: R2 = 0.027 (std: 0.173)
  ridge: R2 = 0.027 (std: 0.086)
  Fallback: Using svr-rbf-xl with R2 = 0.175

Model-based training with 1 models
Best R2: 0.175, Mean R2: 0.097
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=41.3324, entropy=0.0637, kl_div=0.0000
    Epoch 1: policy_loss=-0.0037, value_loss=41.3324, entropy=0.0638, kl_div=-0.0139
  Round 1/3: Mean predicted reward = 10.252
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9756, entropy=0.0656, kl_div=0.0000
    Epoch 1: policy_loss=-0.0025, value_loss=0.9756, entropy=0.0657, kl_div=0.0030
  Round 2/3: Mean predicted reward = 14.814
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9751, entropy=0.0637, kl_div=0.0000
    Epoch 1: policy_loss=-0.0218, value_loss=0.9751, entropy=0.0638, kl_div=0.0451
  Round 3/3: Mean predicted reward = 14.941

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 59 Results ---
  Mean Oracle Reward: 14.494
  Min Oracle Reward: 8.800
  Max Oracle Reward: 18.185
  Std Oracle Reward: 1.794
  Sequence Diversity: 0.891
  Models Used: 1
  Model R2 - Mean: 0.097, Max: 0.175, Count: 13
  Total Sequences Evaluated: 3826
    Oracle Count: 3776 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 60/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 3826

--- Round 60 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.922) ---
  CCTCATGTGGGAAGCCGCGC
  GGCCGCTCAAGGTGGCTACC
  GCCGGAGCTGCTCGTGACAC
  GGGACCCATCCGCTTACGGG
  CACTGGGTCCATCGGACGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.744
  Max reward: 17.100
  With intrinsic bonuses: 13.790

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9841, entropy=0.0681, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0760

=== Surrogate Model Training ===
Total samples: 3890

Training on 3706 samples (removed 184 outliers)
Reward range: [9.43, 18.99], mean: 14.28
  Created 13 candidate models for data size 3706
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.120 (std: 0.168)
  rf-tuned-xl: R2 = 0.118 (std: 0.175)
  gb-tuned-l: R2 = 0.148 (std: 0.114)
  gb-tuned-xl: R2 = 0.148 (std: 0.114)
  xgb-xl: R2 = 0.031 (std: 0.181)
  xgb-l: R2 = 0.031 (std: 0.181)
  mlp-adaptive-xl: R2 = 0.143 (std: 0.153)
  mlp-l: R2 = 0.146 (std: 0.140)
  svr-rbf-xl: R2 = 0.186 (std: 0.138)
  svr-poly-l: R2 = 0.186 (std: 0.138)
  knn-tuned-sqrt: R2 = 0.033 (std: 0.174)
  knn-tuned-l: R2 = 0.033 (std: 0.174)
  ridge: R2 = 0.035 (std: 0.099)
  Fallback: Using svr-rbf-xl with R2 = 0.186

Model-based training with 1 models
Best R2: 0.186, Mean R2: 0.104
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=9.3181, entropy=0.0663, kl_div=0.0000
    Epoch 1: policy_loss=0.0277, value_loss=9.3182, entropy=0.0644, kl_div=-0.0125
  Round 1/3: Mean predicted reward = 11.750
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9770, entropy=0.0647, kl_div=0.0000
    Epoch 1: policy_loss=0.1756, value_loss=0.9771, entropy=0.0640, kl_div=-0.3027
  Round 2/3: Mean predicted reward = 14.847
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9762, entropy=0.0593, kl_div=0.0000
    Epoch 1: policy_loss=-0.0325, value_loss=0.9764, entropy=0.0579, kl_div=-0.0003
  Round 3/3: Mean predicted reward = 14.768

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 60 Results ---
  Mean Oracle Reward: 13.783
  Min Oracle Reward: 9.369
  Max Oracle Reward: 16.997
  Std Oracle Reward: 1.725
  Sequence Diversity: 0.922
  Models Used: 1
  Model R2 - Mean: 0.104, Max: 0.186, Count: 13
  Total Sequences Evaluated: 3890
    Oracle Count: 3840 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 61/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 3890

--- Round 61 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.844) ---
  TCTGGAGCGCGACACCCTGG
  CACTGGGTGCCCAGATCGGC
  TTACACCTGCGAGGCCGGCG
  CCCCCCGAGAGGGCGTGATT
  GGCGATACGCCTCCGTGAGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.388
  Max reward: 17.350
  With intrinsic bonuses: 14.374

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9804, entropy=0.0639, kl_div=0.0000
    Epoch 1: policy_loss=-0.0216, value_loss=0.9805, entropy=0.0623, kl_div=-0.0503

=== Surrogate Model Training ===
Total samples: 3954

Training on 3765 samples (removed 189 outliers)
Reward range: [9.44, 18.96], mean: 14.28
  Created 13 candidate models for data size 3765
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.102 (std: 0.123)
  rf-tuned-xl: R2 = 0.100 (std: 0.126)
  gb-tuned-l: R2 = 0.159 (std: 0.117)
  gb-tuned-xl: R2 = 0.159 (std: 0.117)
  xgb-xl: R2 = 0.032 (std: 0.133)
  xgb-l: R2 = 0.032 (std: 0.133)
  mlp-adaptive-xl: R2 = 0.150 (std: 0.136)
  mlp-l: R2 = 0.145 (std: 0.124)
  svr-rbf-xl: R2 = 0.190 (std: 0.129)
  svr-poly-l: R2 = 0.190 (std: 0.129)
  knn-tuned-sqrt: R2 = 0.027 (std: 0.136)
  knn-tuned-l: R2 = 0.027 (std: 0.136)
  ridge: R2 = 0.041 (std: 0.097)
  Fallback: Using svr-rbf-xl with R2 = 0.190

Model-based training with 1 models
Best R2: 0.190, Mean R2: 0.104
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=51.2649, entropy=0.0530, kl_div=0.0000
    Epoch 1: policy_loss=0.0311, value_loss=51.2657, entropy=0.0510, kl_div=-0.1711
  Round 1/3: Mean predicted reward = 8.670
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9762, entropy=0.0507, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1218
  Round 2/3: Mean predicted reward = 14.856
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9762, entropy=0.0492, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2823
  Round 3/3: Mean predicted reward = 14.888

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 61 Results ---
  Mean Oracle Reward: 14.390
  Min Oracle Reward: 8.014
  Max Oracle Reward: 17.092
  Std Oracle Reward: 1.713
  Sequence Diversity: 0.844
  Models Used: 1
  Model R2 - Mean: 0.104, Max: 0.190, Count: 13
  Total Sequences Evaluated: 3954
    Oracle Count: 3904 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 62/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 3954

--- Round 62 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.828) ---
  CTCAGGTGTGGCGACCCCGA
  AGCTCGCTATGGGCGCACCG
  CCCCGGCAGGGAATGTGTCC
  CTGGAGCCCACGCACGTTGG
  TGCACGCGAGCCACTGGCGT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.497
  Max reward: 18.492
  With intrinsic bonuses: 14.480

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9795, entropy=0.0513, kl_div=0.0000
    Epoch 1: policy_loss=0.0003, value_loss=0.9795, entropy=0.0510, kl_div=0.0469

=== Surrogate Model Training ===
Total samples: 4018

Training on 3827 samples (removed 191 outliers)
Reward range: [9.47, 18.96], mean: 14.29
  Created 13 candidate models for data size 3827
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.091 (std: 0.123)
  rf-tuned-xl: R2 = 0.093 (std: 0.121)
  gb-tuned-l: R2 = 0.165 (std: 0.123)
  gb-tuned-xl: R2 = 0.165 (std: 0.123)
  xgb-xl: R2 = 0.026 (std: 0.129)
  xgb-l: R2 = 0.026 (std: 0.129)
  mlp-adaptive-xl: R2 = 0.144 (std: 0.126)
  mlp-l: R2 = 0.144 (std: 0.127)
  svr-rbf-xl: R2 = 0.188 (std: 0.133)
  svr-poly-l: R2 = 0.188 (std: 0.133)
  knn-tuned-sqrt: R2 = 0.008 (std: 0.136)
  knn-tuned-l: R2 = 0.008 (std: 0.136)
  ridge: R2 = 0.041 (std: 0.108)
  Fallback: Using svr-rbf-xl with R2 = 0.188

Model-based training with 1 models
Best R2: 0.188, Mean R2: 0.099
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=57.2828, entropy=0.0496, kl_div=0.0000
    Epoch 1: policy_loss=0.0081, value_loss=57.2832, entropy=0.0464, kl_div=-0.1820
  Round 1/3: Mean predicted reward = 8.077
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9763, entropy=0.0425, kl_div=0.0000
    Epoch 1: policy_loss=-0.0180, value_loss=0.9764, entropy=0.0416, kl_div=-0.0007
  Round 2/3: Mean predicted reward = 14.642
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9773, entropy=0.0474, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1806
  Round 3/3: Mean predicted reward = 14.647

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 62 Results ---
  Mean Oracle Reward: 14.521
  Min Oracle Reward: 8.453
  Max Oracle Reward: 18.657
  Std Oracle Reward: 1.884
  Sequence Diversity: 0.828
  Models Used: 1
  Model R2 - Mean: 0.099, Max: 0.188, Count: 13
  Total Sequences Evaluated: 4018
    Oracle Count: 3968 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 63/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 4018
  Consistent improvement, increasing LR to 0.000132

--- Round 63 Configuration ---
Learning rate: 0.000132
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.812) ---
  AGCCTGGGTCGCGCGCATCA
  AGGTCCGGAGGTCCACCGTC
  CAGGACCGCACCGGCTTGTG
  GCGGCCCTAAGCGGAGCCTT
  GTAGCAAGTCCTCGGCGGCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.752
  Max reward: 18.758
  With intrinsic bonuses: 14.794

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9795, entropy=0.0480, kl_div=0.0000
    Epoch 1: policy_loss=0.0160, value_loss=0.9795, entropy=0.0481, kl_div=0.0460

=== Surrogate Model Training ===
Total samples: 4082

Training on 3889 samples (removed 193 outliers)
Reward range: [9.47, 18.99], mean: 14.30
  Created 13 candidate models for data size 3889
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.094 (std: 0.131)
  rf-tuned-xl: R2 = 0.095 (std: 0.124)
  gb-tuned-l: R2 = 0.169 (std: 0.135)
  gb-tuned-xl: R2 = 0.169 (std: 0.135)
  xgb-xl: R2 = 0.039 (std: 0.134)
  xgb-l: R2 = 0.039 (std: 0.134)
  mlp-adaptive-xl: R2 = 0.154 (std: 0.131)
  mlp-l: R2 = 0.154 (std: 0.128)
  svr-rbf-xl: R2 = 0.188 (std: 0.143)
  svr-poly-l: R2 = 0.188 (std: 0.143)
  knn-tuned-sqrt: R2 = 0.027 (std: 0.150)
  knn-tuned-l: R2 = 0.027 (std: 0.150)
  ridge: R2 = 0.038 (std: 0.117)
  Fallback: Using svr-rbf-xl with R2 = 0.188

Model-based training with 1 models
Best R2: 0.188, Mean R2: 0.106
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=88.3995, entropy=0.0443, kl_div=0.0000
    Epoch 1: policy_loss=-0.0068, value_loss=88.4000, entropy=0.0425, kl_div=-0.0909
  Round 1/3: Mean predicted reward = 8.455
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9786, entropy=0.0458, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0558
  Round 2/3: Mean predicted reward = 14.755
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9780, entropy=0.0484, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1072
  Round 3/3: Mean predicted reward = 14.664

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 63 Results ---
  Mean Oracle Reward: 14.737
  Min Oracle Reward: 5.402
  Max Oracle Reward: 18.766
  Std Oracle Reward: 2.414
  Sequence Diversity: 0.812
  Models Used: 1
  Model R2 - Mean: 0.106, Max: 0.188, Count: 13
  Total Sequences Evaluated: 4082
    Oracle Count: 4032 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 64/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 4082
  Consistent improvement, increasing LR to 0.000045

--- Round 64 Configuration ---
Learning rate: 0.000045
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.828) ---
  CGGTACGTCTACACGCGGCG
  CTCAGCCAGAGCGGTGCTGC
  GGCGAACTCCTGGTGCCCGA
  ATCGGGCACCCCATGGGTCG
  CGTGCCGCCCAATTGGAGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.470
  Max reward: 18.745
  With intrinsic bonuses: 14.509

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9795, entropy=0.0485, kl_div=0.0000
    Epoch 1: policy_loss=0.0075, value_loss=0.9795, entropy=0.0487, kl_div=0.0092

=== Surrogate Model Training ===
Total samples: 4146

Training on 3946 samples (removed 200 outliers)
Reward range: [9.52, 18.95], mean: 14.30
  Created 13 candidate models for data size 3946
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.083 (std: 0.143)
  rf-tuned-xl: R2 = 0.078 (std: 0.137)
  gb-tuned-l: R2 = 0.159 (std: 0.144)
  gb-tuned-xl: R2 = 0.159 (std: 0.144)
  xgb-xl: R2 = 0.035 (std: 0.143)
  xgb-l: R2 = 0.035 (std: 0.143)
  mlp-adaptive-xl: R2 = 0.141 (std: 0.144)
  mlp-l: R2 = 0.143 (std: 0.147)
  svr-rbf-xl: R2 = 0.187 (std: 0.150)
  svr-poly-l: R2 = 0.187 (std: 0.150)
  knn-tuned-sqrt: R2 = 0.037 (std: 0.163)
  knn-tuned-l: R2 = 0.037 (std: 0.163)
  ridge: R2 = 0.033 (std: 0.128)
  Fallback: Using svr-rbf-xl with R2 = 0.187

Model-based training with 1 models
Best R2: 0.187, Mean R2: 0.101
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=60.2166, entropy=0.0509, kl_div=0.0000
    Epoch 1: policy_loss=-0.0306, value_loss=60.2167, entropy=0.0503, kl_div=-0.0304
  Round 1/3: Mean predicted reward = 8.888
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9790, entropy=0.0479, kl_div=0.0000
    Epoch 1: policy_loss=-0.0001, value_loss=0.9790, entropy=0.0473, kl_div=-0.0408
  Round 2/3: Mean predicted reward = 14.764
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9793, entropy=0.0484, kl_div=0.0000
    Epoch 1: policy_loss=-0.0116, value_loss=0.9793, entropy=0.0479, kl_div=-0.0241
  Round 3/3: Mean predicted reward = 14.751

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 64 Results ---
  Mean Oracle Reward: 14.490
  Min Oracle Reward: 9.691
  Max Oracle Reward: 18.603
  Std Oracle Reward: 1.592
  Sequence Diversity: 0.828
  Models Used: 1
  Model R2 - Mean: 0.101, Max: 0.187, Count: 13
  Total Sequences Evaluated: 4146
    Oracle Count: 4096 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 65/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 4146

--- Round 65 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.797) ---
  GGGAGGCACACCTCTCCGGT
  ACGAGGCCTCTCGCGGTGCA
  GTTGCGCGCAACGACCGTGC
  GCAGGCCCGCTGCTGAAGTC
  GAGCGGCCTGGTCGACCCTA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.814
  Max reward: 18.742
  With intrinsic bonuses: 14.786

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9791, entropy=0.0448, kl_div=0.0000
    Epoch 1: policy_loss=0.0356, value_loss=0.9792, entropy=0.0385, kl_div=-0.1709

=== Surrogate Model Training ===
Total samples: 4210

Training on 4013 samples (removed 197 outliers)
Reward range: [9.52, 18.96], mean: 14.31
  Created 13 candidate models for data size 4013
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.090 (std: 0.140)
  rf-tuned-xl: R2 = 0.092 (std: 0.137)
  gb-tuned-l: R2 = 0.169 (std: 0.152)
  gb-tuned-xl: R2 = 0.169 (std: 0.152)
  xgb-xl: R2 = 0.031 (std: 0.137)
  xgb-l: R2 = 0.031 (std: 0.137)
  mlp-adaptive-xl: R2 = 0.143 (std: 0.137)
  mlp-l: R2 = 0.146 (std: 0.131)
  svr-rbf-xl: R2 = 0.191 (std: 0.146)
  svr-poly-l: R2 = 0.191 (std: 0.146)
  knn-tuned-sqrt: R2 = 0.037 (std: 0.150)
  knn-tuned-l: R2 = 0.037 (std: 0.150)
  ridge: R2 = 0.030 (std: 0.139)
  Fallback: Using svr-rbf-xl with R2 = 0.191

Model-based training with 1 models
Best R2: 0.191, Mean R2: 0.104
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=94.5081, entropy=0.0385, kl_div=0.0000
    Epoch 1: policy_loss=0.0013, value_loss=94.5094, entropy=0.0349, kl_div=-0.0710
  Round 1/3: Mean predicted reward = 7.759
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9776, entropy=0.0350, kl_div=0.0000
    Epoch 1: policy_loss=0.0433, value_loss=0.9778, entropy=0.0355, kl_div=-0.1091
  Round 2/3: Mean predicted reward = 14.603
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9783, entropy=0.0333, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1982
  Round 3/3: Mean predicted reward = 15.089

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 65 Results ---
  Mean Oracle Reward: 14.817
  Min Oracle Reward: 4.845
  Max Oracle Reward: 18.867
  Std Oracle Reward: 2.457
  Sequence Diversity: 0.797
  Models Used: 1
  Model R2 - Mean: 0.104, Max: 0.191, Count: 13
  Total Sequences Evaluated: 4210
    Oracle Count: 4160 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 66/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 4210

--- Round 66 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.766) ---
  GCTACGCGGTCCAGCGACTG
  CCCTGTCAGGCGTCGGGCAA
  GGCATCCCGCGAACGTGCTG
  GGGCCCTCCAGGTTAAGGCC
  GCTGATGGACGCACCGTCGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.095
  Max reward: 19.210
  With intrinsic bonuses: 15.046

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9793, entropy=0.0330, kl_div=0.0000
    Epoch 1: policy_loss=0.0000, value_loss=0.9794, entropy=0.0328, kl_div=-0.0052

=== Surrogate Model Training ===
Total samples: 4274

Training on 4080 samples (removed 194 outliers)
Reward range: [9.52, 19.01], mean: 14.33
  Created 13 candidate models for data size 4080
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.099 (std: 0.160)
  rf-tuned-xl: R2 = 0.099 (std: 0.161)
  gb-tuned-l: R2 = 0.168 (std: 0.155)
  gb-tuned-xl: R2 = 0.168 (std: 0.155)
  xgb-xl: R2 = 0.036 (std: 0.158)
  xgb-l: R2 = 0.036 (std: 0.158)
  mlp-adaptive-xl: R2 = 0.146 (std: 0.133)
  mlp-l: R2 = 0.152 (std: 0.147)
  svr-rbf-xl: R2 = 0.193 (std: 0.151)
  svr-poly-l: R2 = 0.193 (std: 0.151)
  knn-tuned-sqrt: R2 = 0.026 (std: 0.150)
  knn-tuned-l: R2 = 0.026 (std: 0.150)
  ridge: R2 = 0.024 (std: 0.139)
  Fallback: Using svr-rbf-xl with R2 = 0.193

Model-based training with 1 models
Best R2: 0.193, Mean R2: 0.105
Running 3 virtual training rounds
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=68.9728, entropy=0.0323, kl_div=0.0000
    Epoch 1: policy_loss=-0.0039, value_loss=68.9742, entropy=0.0349, kl_div=-0.1213
  Round 1/3: Mean predicted reward = 4.933
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9792, entropy=0.0377, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1438
  Round 2/3: Mean predicted reward = 14.865
Current Method: dynamic
    Using ridge regression weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9794, entropy=0.0361, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2498
  Round 3/3: Mean predicted reward = 15.049

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 66 Results ---
  Mean Oracle Reward: 15.108
  Min Oracle Reward: 7.326
  Max Oracle Reward: 18.967
  Std Oracle Reward: 2.276
  Sequence Diversity: 0.766
  Models Used: 1
  Model R2 - Mean: 0.105, Max: 0.193, Count: 13
  Total Sequences Evaluated: 4274
    Oracle Count: 4224 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 67/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 4274
  Consistent improvement, increasing LR to 0.000240

--- Round 67 Configuration ---
Learning rate: 0.000240
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.766) ---
  GGCTGCGCCACGATTGCGCA
  CTAAGCCGGTGCTACGCGCG
  GGGCGGGCTAATCAGCCCTC
  GTCGCCCCAACGGTACTGGG
  GGGGCGCACTTCGACCGATC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.078
  Max reward: 19.143
  With intrinsic bonuses: 15.062

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9797, entropy=0.0322, kl_div=0.0000
    Epoch 1: policy_loss=-0.0209, value_loss=0.9798, entropy=0.0330, kl_div=-0.0063

=== Surrogate Model Training ===
Total samples: 4338

Training on 4143 samples (removed 195 outliers)
Reward range: [9.52, 19.02], mean: 14.34
  Created 13 candidate models for data size 4143
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.109 (std: 0.184)
  rf-tuned-xl: R2 = 0.108 (std: 0.187)
  gb-tuned-l: R2 = 0.170 (std: 0.161)
  gb-tuned-xl: R2 = 0.170 (std: 0.161)
  xgb-xl: R2 = 0.060 (std: 0.178)
  xgb-l: R2 = 0.060 (std: 0.178)
  mlp-adaptive-xl: R2 = 0.149 (std: 0.151)
  mlp-l: R2 = 0.163 (std: 0.166)
  svr-rbf-xl: R2 = 0.196 (std: 0.160)
  svr-poly-l: R2 = 0.196 (std: 0.160)
  knn-tuned-sqrt: R2 = 0.034 (std: 0.162)
  knn-tuned-l: R2 = 0.034 (std: 0.162)
  ridge: R2 = 0.018 (std: 0.147)
  Fallback: Using svr-rbf-xl with R2 = 0.196

Model-based training with 1 models
Best R2: 0.196, Mean R2: 0.113
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=305.0621, entropy=0.0322, kl_div=0.0000
    Epoch 1: policy_loss=-0.0259, value_loss=305.0648, entropy=0.0340, kl_div=-0.0936
  Round 1/3: Mean predicted reward = 3.781
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9793, entropy=0.0357, kl_div=0.0000
    Epoch 1: policy_loss=0.0369, value_loss=0.9794, entropy=0.0372, kl_div=-0.0269
  Round 2/3: Mean predicted reward = 14.962
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9793, entropy=0.0377, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2438
  Round 3/3: Mean predicted reward = 14.858

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 67 Results ---
  Mean Oracle Reward: 15.043
  Min Oracle Reward: 11.424
  Max Oracle Reward: 19.138
  Std Oracle Reward: 2.260
  Sequence Diversity: 0.766
  Models Used: 1
  Model R2 - Mean: 0.113, Max: 0.196, Count: 13
  Total Sequences Evaluated: 4338
    Oracle Count: 4288 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 68/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 4338

--- Round 68 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.766) ---
  CGGCTAACGCTACGGCCGGT
  CGTACGCTCTGACGGGCACG
  TCAGCGGCCGAGCGTCCGTA
  GGCGCTACCGTGTCGCCGAA
  ACGGATGGCGGACCTCTCGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.360
  Max reward: 19.065
  With intrinsic bonuses: 15.369

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9799, entropy=0.0325, kl_div=0.0000
    Epoch 1: policy_loss=-0.0115, value_loss=0.9799, entropy=0.0321, kl_div=0.0432

=== Surrogate Model Training ===
Total samples: 4402

Training on 4206 samples (removed 196 outliers)
Reward range: [9.52, 19.05], mean: 14.36
  Created 13 candidate models for data size 4206
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.122 (std: 0.190)
  rf-tuned-xl: R2 = 0.127 (std: 0.184)
  gb-tuned-l: R2 = 0.178 (std: 0.168)
  gb-tuned-xl: R2 = 0.178 (std: 0.168)
  xgb-xl: R2 = 0.068 (std: 0.187)
  xgb-l: R2 = 0.068 (std: 0.187)
  mlp-adaptive-xl: R2 = 0.171 (std: 0.158)
  mlp-l: R2 = 0.169 (std: 0.164)
  svr-rbf-xl: R2 = 0.210 (std: 0.163)
  svr-poly-l: R2 = 0.210 (std: 0.163)
  knn-tuned-sqrt: R2 = 0.043 (std: 0.171)
  knn-tuned-l: R2 = 0.043 (std: 0.171)
  ridge: R2 = 0.019 (std: 0.148)

Model-based training with 2 models
Best R2: 0.210, Mean R2: 0.123
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=185.0735, entropy=0.0295, kl_div=0.0000
    Epoch 1: policy_loss=0.0004, value_loss=185.0743, entropy=0.0308, kl_div=-0.1337
  Round 1/3: Mean predicted reward = 0.799
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9800, entropy=0.0371, kl_div=0.0000
    Epoch 1: policy_loss=-0.0174, value_loss=0.9800, entropy=0.0361, kl_div=0.0288
  Round 2/3: Mean predicted reward = 14.897
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9796, entropy=0.0270, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1124
  Round 3/3: Mean predicted reward = 14.934

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 68 Results ---
  Mean Oracle Reward: 15.360
  Min Oracle Reward: 8.817
  Max Oracle Reward: 19.041
  Std Oracle Reward: 2.334
  Sequence Diversity: 0.766
  Models Used: 2
  Model R2 - Mean: 0.123, Max: 0.210, Count: 13
  Total Sequences Evaluated: 4402
    Oracle Count: 4352 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 69/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 4402

--- Round 69 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.766) ---
  TCCCTCCGGAGAATCGCGGG
  TAGAGTCCCCGCCGTGCGGA
  TATGCGGGGCCCTGGACCAC
  GCACCTCGGACTGGGCCAGT
  CCGATGCCCAGCGTCTAGGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.259
  Max reward: 18.997
  With intrinsic bonuses: 15.270

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9805, entropy=0.0377, kl_div=0.0000
    Epoch 1: policy_loss=-0.0045, value_loss=0.9805, entropy=0.0376, kl_div=0.0115

=== Surrogate Model Training ===
Total samples: 4466

Training on 4273 samples (removed 193 outliers)
Reward range: [9.52, 19.07], mean: 14.38
  Created 13 candidate models for data size 4273
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.127 (std: 0.209)
  rf-tuned-xl: R2 = 0.128 (std: 0.212)
  gb-tuned-l: R2 = 0.174 (std: 0.173)
  gb-tuned-xl: R2 = 0.174 (std: 0.173)
  xgb-xl: R2 = 0.076 (std: 0.200)
  xgb-l: R2 = 0.076 (std: 0.200)
  mlp-adaptive-xl: R2 = 0.157 (std: 0.180)
  mlp-l: R2 = 0.174 (std: 0.183)
  svr-rbf-xl: R2 = 0.208 (std: 0.173)
  svr-poly-l: R2 = 0.208 (std: 0.173)
  knn-tuned-sqrt: R2 = 0.038 (std: 0.182)
  knn-tuned-l: R2 = 0.038 (std: 0.182)
  ridge: R2 = 0.011 (std: 0.158)

Model-based training with 2 models
Best R2: 0.208, Mean R2: 0.122
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=255.1121, entropy=0.0317, kl_div=0.0000
    Epoch 1: policy_loss=-0.0080, value_loss=255.1125, entropy=0.0319, kl_div=-0.0244
  Round 1/3: Mean predicted reward = -0.746
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9799, entropy=0.0357, kl_div=0.0000
    Epoch 1: policy_loss=0.0054, value_loss=0.9799, entropy=0.0358, kl_div=-0.0120
  Round 2/3: Mean predicted reward = 15.082
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9799, entropy=0.0272, kl_div=0.0000
    Epoch 1: policy_loss=-0.0112, value_loss=0.9799, entropy=0.0269, kl_div=0.0274
  Round 3/3: Mean predicted reward = 14.971

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 69 Results ---
  Mean Oracle Reward: 15.282
  Min Oracle Reward: 10.094
  Max Oracle Reward: 19.346
  Std Oracle Reward: 2.246
  Sequence Diversity: 0.766
  Models Used: 2
  Model R2 - Mean: 0.122, Max: 0.208, Count: 13
  Total Sequences Evaluated: 4466
    Oracle Count: 4416 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 70/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 4466

--- Round 70 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  TCCGCTGGGCGCGCTACAAG
  AACGCCCATGCCTGGCTGGG
  CAGCTCTCGGGGACGCTGCA
  CCGGGGAGTCCGTGCTCACA
  CGTTCAGCCGCGCGCAGGTA
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.137
  Max reward: 19.060
  With intrinsic bonuses: 15.160

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9800, entropy=0.0318, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3819

=== Surrogate Model Training ===
Total samples: 4530

Training on 4337 samples (removed 193 outliers)
Reward range: [9.52, 19.08], mean: 14.39
  Created 13 candidate models for data size 4337
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.128 (std: 0.240)
  rf-tuned-xl: R2 = 0.127 (std: 0.240)
  gb-tuned-l: R2 = 0.181 (std: 0.175)
  gb-tuned-xl: R2 = 0.181 (std: 0.175)
  xgb-xl: R2 = 0.074 (std: 0.225)
  xgb-l: R2 = 0.074 (std: 0.225)
  mlp-adaptive-xl: R2 = 0.174 (std: 0.194)
  mlp-l: R2 = 0.173 (std: 0.192)
  svr-rbf-xl: R2 = 0.214 (std: 0.183)
  svr-poly-l: R2 = 0.214 (std: 0.183)
  knn-tuned-sqrt: R2 = 0.029 (std: 0.216)
  knn-tuned-l: R2 = 0.029 (std: 0.216)
  ridge: R2 = 0.006 (std: 0.155)

Model-based training with 2 models
Best R2: 0.214, Mean R2: 0.123
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=235.5656, entropy=0.0327, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1938
  Round 1/3: Mean predicted reward = -1.699
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9799, entropy=0.0316, kl_div=0.0000
    Epoch 1: policy_loss=-0.0237, value_loss=0.9800, entropy=0.0320, kl_div=0.0098
  Round 2/3: Mean predicted reward = 14.946
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9804, entropy=0.0286, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0977
  Round 3/3: Mean predicted reward = 14.834

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 70 Results ---
  Mean Oracle Reward: 15.138
  Min Oracle Reward: 8.998
  Max Oracle Reward: 18.990
  Std Oracle Reward: 2.279
  Sequence Diversity: 0.734
  Models Used: 2
  Model R2 - Mean: 0.123, Max: 0.214, Count: 13
  Total Sequences Evaluated: 4530
    Oracle Count: 4480 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 71/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 4530
  Performance plateaued, reducing LR to 0.000136

--- Round 71 Configuration ---
Learning rate: 0.000136
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  CCTCGTCGACTCGGAACGGG
  GTCTTAACCGAGGCGGCGCC
  AGGCGGTATCGTGCCCGCAC
  CGAGGCCTATTGCCCACGGG
  CTATGCGTAGCCGCCAGGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.454
  Max reward: 19.021
  With intrinsic bonuses: 15.459

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9805, entropy=0.0249, kl_div=0.0000
    Epoch 1: policy_loss=-0.0195, value_loss=0.9805, entropy=0.0230, kl_div=-0.0167

=== Surrogate Model Training ===
Total samples: 4594

Training on 4400 samples (removed 194 outliers)
Reward range: [9.52, 19.08], mean: 14.40
  Created 13 candidate models for data size 4400
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.132 (std: 0.235)
  rf-tuned-xl: R2 = 0.137 (std: 0.234)
  gb-tuned-l: R2 = 0.182 (std: 0.172)
  gb-tuned-xl: R2 = 0.182 (std: 0.172)
  xgb-xl: R2 = 0.078 (std: 0.239)
  xgb-l: R2 = 0.078 (std: 0.239)
  mlp-adaptive-xl: R2 = 0.178 (std: 0.187)
  mlp-l: R2 = 0.184 (std: 0.185)
  svr-rbf-xl: R2 = 0.217 (std: 0.183)
  svr-poly-l: R2 = 0.217 (std: 0.183)
  knn-tuned-sqrt: R2 = 0.032 (std: 0.214)
  knn-tuned-l: R2 = 0.032 (std: 0.214)
  ridge: R2 = 0.005 (std: 0.154)

Model-based training with 2 models
Best R2: 0.217, Mean R2: 0.127
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=410.6115, entropy=0.0243, kl_div=0.0000
    Epoch 1: policy_loss=0.0096, value_loss=410.6129, entropy=0.0217, kl_div=-0.0219
  Round 1/3: Mean predicted reward = -1.562
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9802, entropy=0.0224, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0762
  Round 2/3: Mean predicted reward = 15.131
Current Method: dynamic
    Using validation-optimized weights
    Model weights: svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9807, entropy=0.0227, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1059
  Round 3/3: Mean predicted reward = 15.132

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 71 Results ---
  Mean Oracle Reward: 15.467
  Min Oracle Reward: 11.640
  Max Oracle Reward: 19.058
  Std Oracle Reward: 2.052
  Sequence Diversity: 0.734
  Models Used: 2
  Model R2 - Mean: 0.127, Max: 0.217, Count: 13
  Total Sequences Evaluated: 4594
    Oracle Count: 4544 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 72/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 4594

--- Round 72 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  CCGTTAGCGAAGCCTCGGCG
  GCCGTCCTGAAGCGCGTAGC
  CGCCCTAGTAGGGCCAGTCG
  CGGCCAGGCTGAAGCGTCTC
  ACGGACCGCACTTGGCGCGT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.125
  Max reward: 18.884
  With intrinsic bonuses: 15.142

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9807, entropy=0.0226, kl_div=0.0000
    Epoch 1: policy_loss=-0.0110, value_loss=0.9808, entropy=0.0216, kl_div=0.0273

=== Surrogate Model Training ===
Total samples: 4658

Training on 4464 samples (removed 194 outliers)
Reward range: [9.52, 19.08], mean: 14.41
  Created 13 candidate models for data size 4464
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.164 (std: 0.208)
  rf-tuned-xl: R2 = 0.167 (std: 0.206)
  gb-tuned-l: R2 = 0.200 (std: 0.162)
  gb-tuned-xl: R2 = 0.200 (std: 0.162)
  xgb-xl: R2 = 0.116 (std: 0.206)
  xgb-l: R2 = 0.116 (std: 0.206)
  mlp-adaptive-xl: R2 = 0.205 (std: 0.178)
  mlp-l: R2 = 0.203 (std: 0.177)
  svr-rbf-xl: R2 = 0.235 (std: 0.169)
  svr-poly-l: R2 = 0.235 (std: 0.169)
  knn-tuned-sqrt: R2 = 0.074 (std: 0.185)
  knn-tuned-l: R2 = 0.074 (std: 0.185)
  ridge: R2 = 0.013 (std: 0.142)

Model-based training with 4 models
Best R2: 0.235, Mean R2: 0.154
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=603.7185, entropy=0.0211, kl_div=0.0000
    Epoch 1: policy_loss=0.0143, value_loss=603.7215, entropy=0.0185, kl_div=-0.1813
  Round 1/3: Mean predicted reward = -5.003
Current Method: dynamic
    Using validation-optimized weights
    Model weights: mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9803, entropy=0.0137, kl_div=0.0000
    Epoch 1: policy_loss=-0.0066, value_loss=0.9804, entropy=0.0138, kl_div=0.0473
  Round 2/3: Mean predicted reward = 15.094
Current Method: dynamic
    Using validation-optimized weights
    Model weights: mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9805, entropy=0.0152, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0729
  Round 3/3: Mean predicted reward = 15.115

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 72 Results ---
  Mean Oracle Reward: 15.133
  Min Oracle Reward: 11.153
  Max Oracle Reward: 18.848
  Std Oracle Reward: 2.338
  Sequence Diversity: 0.734
  Models Used: 4
  Model R2 - Mean: 0.154, Max: 0.235, Count: 13
  Total Sequences Evaluated: 4658
    Oracle Count: 4608 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 73/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 4658

--- Round 73 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  CCACCACACTTGGGGGGCTG
  GCGTCGTAACGGCTGCAGCC
  AGGACGGCCATGGCTGCTCC
  CCTGCGGTCGGTGCCCAAGA
  GCGCGCAGTCTGACCGGTAC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.422
  Max reward: 19.197
  With intrinsic bonuses: 15.438

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9810, entropy=0.0139, kl_div=0.0000
    Epoch 1: policy_loss=-0.0107, value_loss=0.9810, entropy=0.0136, kl_div=0.0013

=== Surrogate Model Training ===
Total samples: 4722

Training on 4527 samples (removed 195 outliers)
Reward range: [9.52, 19.14], mean: 14.43
  Created 13 candidate models for data size 4527
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.185 (std: 0.194)
  rf-tuned-xl: R2 = 0.189 (std: 0.192)
  gb-tuned-l: R2 = 0.212 (std: 0.161)
  gb-tuned-xl: R2 = 0.212 (std: 0.161)
  xgb-xl: R2 = 0.135 (std: 0.199)
  xgb-l: R2 = 0.135 (std: 0.199)
  mlp-adaptive-xl: R2 = 0.222 (std: 0.163)
  mlp-l: R2 = 0.223 (std: 0.170)
  svr-rbf-xl: R2 = 0.248 (std: 0.162)
  svr-poly-l: R2 = 0.248 (std: 0.162)
  knn-tuned-sqrt: R2 = 0.086 (std: 0.182)
  knn-tuned-l: R2 = 0.086 (std: 0.182)
  ridge: R2 = 0.023 (std: 0.136)

Model-based training with 6 models
Best R2: 0.248, Mean R2: 0.170
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.105 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.895 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=816.4074, entropy=0.0146, kl_div=0.0000
    Epoch 1: policy_loss=-0.0068, value_loss=816.4102, entropy=0.0144, kl_div=-0.0191
  Round 1/3: Mean predicted reward = -8.711
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.105 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.895 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9811, entropy=0.0165, kl_div=0.0000
    Epoch 1: policy_loss=-0.0078, value_loss=0.9811, entropy=0.0164, kl_div=-0.0032
  Round 2/3: Mean predicted reward = 15.425
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.105 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.895 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9812, entropy=0.0170, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1060
  Round 3/3: Mean predicted reward = 15.266

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 73 Results ---
  Mean Oracle Reward: 15.456
  Min Oracle Reward: 8.959
  Max Oracle Reward: 19.126
  Std Oracle Reward: 2.419
  Sequence Diversity: 0.734
  Models Used: 6
  Model R2 - Mean: 0.170, Max: 0.248, Count: 13
  Total Sequences Evaluated: 4722
    Oracle Count: 4672 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 74/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 4722

--- Round 74 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.703) ---
  GCGCCCACGTCGCAGATGTG
  GCGTTCGACCCAGGCGTGCA
  TCGAACGGCCCGTGTCCGGA
  GCCGCGGACCTCGAATCGGT
  TCTGCGCGTACACGCGAGGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.578
  Max reward: 18.937
  With intrinsic bonuses: 15.573

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9810, entropy=0.0157, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0594

=== Surrogate Model Training ===
Total samples: 4786

Training on 4593 samples (removed 193 outliers)
Reward range: [9.52, 19.16], mean: 14.45
  Created 13 candidate models for data size 4593
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.192 (std: 0.191)
  rf-tuned-xl: R2 = 0.193 (std: 0.192)
  gb-tuned-l: R2 = 0.212 (std: 0.160)
  gb-tuned-xl: R2 = 0.212 (std: 0.160)
  xgb-xl: R2 = 0.139 (std: 0.199)
  xgb-l: R2 = 0.139 (std: 0.199)
  mlp-adaptive-xl: R2 = 0.225 (std: 0.170)
  mlp-l: R2 = 0.209 (std: 0.183)
  svr-rbf-xl: R2 = 0.249 (std: 0.167)
  svr-poly-l: R2 = 0.249 (std: 0.167)
  knn-tuned-sqrt: R2 = 0.101 (std: 0.194)
  knn-tuned-l: R2 = 0.101 (std: 0.194)
  ridge: R2 = 0.011 (std: 0.137)

Model-based training with 6 models
Best R2: 0.249, Mean R2: 0.172
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=1282.2058, entropy=0.0137, kl_div=0.0000
    Epoch 1: policy_loss=0.0138, value_loss=1282.2065, entropy=0.0137, kl_div=0.0199
  Round 1/3: Mean predicted reward = -10.101
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9813, entropy=0.0146, kl_div=0.0000
    Epoch 1: policy_loss=-0.0061, value_loss=0.9813, entropy=0.0146, kl_div=0.0104
  Round 2/3: Mean predicted reward = 15.414
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9814, entropy=0.0134, kl_div=0.0000
    Epoch 1: policy_loss=-0.0067, value_loss=0.9814, entropy=0.0135, kl_div=0.0418
  Round 3/3: Mean predicted reward = 15.365

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 74 Results ---
  Mean Oracle Reward: 15.552
  Min Oracle Reward: 10.690
  Max Oracle Reward: 18.806
  Std Oracle Reward: 2.388
  Sequence Diversity: 0.703
  Models Used: 6
  Model R2 - Mean: 0.172, Max: 0.249, Count: 13
  Total Sequences Evaluated: 4786
    Oracle Count: 4736 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 75/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 4786
  Consistent improvement, increasing LR to 0.000360

--- Round 75 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.688) ---
  CTAGGGCCCCCACTAGGGTG
  GTCCAGTCGTAGGAGCCCGC
  CAGCTACGGCATCCGGTGGC
  CCGTTGGACGCAGGTCCGCA
  AGGCGAGATCCCCCCGGTTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.299
  Max reward: 18.728
  With intrinsic bonuses: 15.268

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9812, entropy=0.0127, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2359

=== Surrogate Model Training ===
Total samples: 4850

Training on 4665 samples (removed 185 outliers)
Reward range: [9.47, 19.21], mean: 14.47
  Created 13 candidate models for data size 4665
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.187 (std: 0.191)
  rf-tuned-xl: R2 = 0.187 (std: 0.194)
  gb-tuned-l: R2 = 0.217 (std: 0.153)
  gb-tuned-xl: R2 = 0.217 (std: 0.153)
  xgb-xl: R2 = 0.137 (std: 0.205)
  xgb-l: R2 = 0.137 (std: 0.205)
  mlp-adaptive-xl: R2 = 0.236 (std: 0.170)
  mlp-l: R2 = 0.231 (std: 0.177)
  svr-rbf-xl: R2 = 0.257 (std: 0.166)
  svr-poly-l: R2 = 0.257 (std: 0.166)
  knn-tuned-sqrt: R2 = 0.110 (std: 0.196)
  knn-tuned-l: R2 = 0.110 (std: 0.196)
  ridge: R2 = 0.011 (std: 0.134)

Model-based training with 6 models
Best R2: 0.257, Mean R2: 0.177
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=1136.1870, entropy=0.0156, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0840
  Round 1/3: Mean predicted reward = -11.863
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9818, entropy=0.0146, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0538
  Round 2/3: Mean predicted reward = 15.171
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9816, entropy=0.0136, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1325
  Round 3/3: Mean predicted reward = 15.749

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 75 Results ---
  Mean Oracle Reward: 15.285
  Min Oracle Reward: 8.863
  Max Oracle Reward: 18.837
  Std Oracle Reward: 2.802
  Sequence Diversity: 0.688
  Models Used: 6
  Model R2 - Mean: 0.177, Max: 0.257, Count: 13
  Total Sequences Evaluated: 4850
    Oracle Count: 4800 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 76/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 4850

--- Round 76 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.703) ---
  CTGCGCTCCCAGGGGAGCTA
  GCCCATACGCGCAGTTCGGG
  GGAATGCGTACCCGGCTCGC
  CCGCCTCAGGGGTTGCACGA
  CATCGGGGGTTCCAAGGCCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.199
  Max reward: 18.737
  With intrinsic bonuses: 15.228

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9818, entropy=0.0157, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1234

=== Surrogate Model Training ===
Total samples: 4914

Training on 4731 samples (removed 183 outliers)
Reward range: [9.45, 19.27], mean: 14.48
  Created 13 candidate models for data size 4731
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.195 (std: 0.174)
  rf-tuned-xl: R2 = 0.191 (std: 0.172)
  gb-tuned-l: R2 = 0.215 (std: 0.144)
  gb-tuned-xl: R2 = 0.215 (std: 0.144)
  xgb-xl: R2 = 0.150 (std: 0.184)
  xgb-l: R2 = 0.150 (std: 0.184)
  mlp-adaptive-xl: R2 = 0.222 (std: 0.157)
  mlp-l: R2 = 0.240 (std: 0.161)
  svr-rbf-xl: R2 = 0.255 (std: 0.154)
  svr-poly-l: R2 = 0.255 (std: 0.154)
  knn-tuned-sqrt: R2 = 0.128 (std: 0.215)
  knn-tuned-l: R2 = 0.128 (std: 0.215)
  ridge: R2 = 0.014 (std: 0.132)

Model-based training with 6 models
Best R2: 0.255, Mean R2: 0.181
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1423.4312, entropy=0.0145, kl_div=0.0000
    Epoch 1: policy_loss=0.0231, value_loss=1423.4376, entropy=0.0130, kl_div=-0.0099
  Round 1/3: Mean predicted reward = -13.887
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9820, entropy=0.0113, kl_div=0.0000
    Epoch 1: policy_loss=-0.0130, value_loss=0.9820, entropy=0.0110, kl_div=0.0424
  Round 2/3: Mean predicted reward = 15.624
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:1.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9819, entropy=0.0115, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0897
  Round 3/3: Mean predicted reward = 15.376

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 76 Results ---
  Mean Oracle Reward: 15.220
  Min Oracle Reward: 8.423
  Max Oracle Reward: 18.897
  Std Oracle Reward: 2.682
  Sequence Diversity: 0.703
  Models Used: 6
  Model R2 - Mean: 0.181, Max: 0.255, Count: 13
  Total Sequences Evaluated: 4914
    Oracle Count: 4864 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 77/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 4914

--- Round 77 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  CCCCATGGCGTCGGGAGCAT
  CACCCCCTGTGGTGGAGAGC
  GTGCCCCATAGCACGCGGTG
  GTTTGGGAGACGCCCGCACC
  CCCTGGAAGCTCGGCCGGAT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.280
  Max reward: 18.780
  With intrinsic bonuses: 15.269

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9822, entropy=0.0139, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1194

=== Surrogate Model Training ===
Total samples: 4978

Training on 4797 samples (removed 181 outliers)
Reward range: [9.43, 19.27], mean: 14.49
  Created 13 candidate models for data size 4797
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.185 (std: 0.171)
  rf-tuned-xl: R2 = 0.185 (std: 0.172)
  gb-tuned-l: R2 = 0.212 (std: 0.148)
  gb-tuned-xl: R2 = 0.212 (std: 0.148)
  xgb-xl: R2 = 0.139 (std: 0.176)
  xgb-l: R2 = 0.139 (std: 0.176)
  mlp-adaptive-xl: R2 = 0.215 (std: 0.156)
  mlp-l: R2 = 0.226 (std: 0.148)
  svr-rbf-xl: R2 = 0.231 (std: 0.125)
  svr-poly-l: R2 = 0.231 (std: 0.125)
  knn-tuned-sqrt: R2 = 0.129 (std: 0.216)
  knn-tuned-l: R2 = 0.129 (std: 0.216)
  ridge: R2 = 0.011 (std: 0.142)

Model-based training with 6 models
Best R2: 0.231, Mean R2: 0.173
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.336 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.664 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=1584.1412, entropy=0.0140, kl_div=0.0000
    Epoch 1: policy_loss=0.0065, value_loss=1584.1472, entropy=0.0133, kl_div=-0.0069
  Round 1/3: Mean predicted reward = -18.305
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.336 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.664 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9822, entropy=0.0126, kl_div=0.0000
    Epoch 1: policy_loss=0.0140, value_loss=0.9823, entropy=0.0113, kl_div=-0.0227
  Round 2/3: Mean predicted reward = 15.373
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.336 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.664 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9821, entropy=0.0089, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1223
  Round 3/3: Mean predicted reward = 15.318

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 77 Results ---
  Mean Oracle Reward: 15.246
  Min Oracle Reward: 9.934
  Max Oracle Reward: 18.832
  Std Oracle Reward: 2.552
  Sequence Diversity: 0.734
  Models Used: 6
  Model R2 - Mean: 0.173, Max: 0.231, Count: 13
  Total Sequences Evaluated: 4978
    Oracle Count: 4928 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 78/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 4978
  Performance plateaued, reducing LR to 0.000055

--- Round 78 Configuration ---
Learning rate: 0.000055
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.703) ---
  TCAACGTGGCGTACGCCGCG
  CCCTGTCGCAGGACGCAGTG
  CCTGGTCGCGGTCGAAACGC
  GGCGCGCGCTCCGACAGTAT
  CCGAGGCCTCCTGAGGTAGC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.398
  Max reward: 19.459
  With intrinsic bonuses: 15.423

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9824, entropy=0.0100, kl_div=0.0000
    Epoch 1: policy_loss=-0.0052, value_loss=0.9824, entropy=0.0101, kl_div=0.0299

=== Surrogate Model Training ===
Total samples: 5042

Training on 4862 samples (removed 180 outliers)
Reward range: [9.43, 19.31], mean: 14.50
  Created 13 candidate models for data size 4862
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.203 (std: 0.180)
  rf-tuned-xl: R2 = 0.202 (std: 0.184)
  gb-tuned-l: R2 = 0.222 (std: 0.154)
  gb-tuned-xl: R2 = 0.222 (std: 0.154)
  xgb-xl: R2 = 0.153 (std: 0.187)
  xgb-l: R2 = 0.153 (std: 0.187)
  mlp-adaptive-xl: R2 = 0.236 (std: 0.172)
  mlp-l: R2 = 0.230 (std: 0.172)
  svr-rbf-xl: R2 = 0.249 (std: 0.148)
  svr-poly-l: R2 = 0.249 (std: 0.148)
  knn-tuned-sqrt: R2 = 0.138 (std: 0.224)
  knn-tuned-l: R2 = 0.138 (std: 0.224)
  ridge: R2 = 0.017 (std: 0.148)

Model-based training with 8 models
Best R2: 0.249, Mean R2: 0.185
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1589.4961, entropy=0.0092, kl_div=0.0000
    Epoch 1: policy_loss=0.0022, value_loss=1589.4980, entropy=0.0091, kl_div=0.0033
  Round 1/3: Mean predicted reward = -19.391
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9825, entropy=0.0092, kl_div=0.0000
    Epoch 1: policy_loss=-0.0022, value_loss=0.9825, entropy=0.0092, kl_div=0.0033
  Round 2/3: Mean predicted reward = 15.051
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9824, entropy=0.0099, kl_div=0.0000
    Epoch 1: policy_loss=-0.0123, value_loss=0.9824, entropy=0.0103, kl_div=0.0334
  Round 3/3: Mean predicted reward = 15.076

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 78 Results ---
  Mean Oracle Reward: 15.436
  Min Oracle Reward: 9.455
  Max Oracle Reward: 19.262
  Std Oracle Reward: 2.525
  Sequence Diversity: 0.703
  Models Used: 8
  Model R2 - Mean: 0.185, Max: 0.249, Count: 13
  Total Sequences Evaluated: 5042
    Oracle Count: 4992 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 79/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 5042
  Performance plateaued, reducing LR to 0.000019

--- Round 79 Configuration ---
Learning rate: 0.000019
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.703) ---
  GCTCACGCGCAAGGGTCGTC
  GGACCCCGCGGTTCGAGTCA
  CCCTGCGTCGACTAAGGGGC
  CCCCCGGAGCGGACTTTGAG
  CGGTCGACGTAGACGCCGTC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.569
  Max reward: 18.870
  With intrinsic bonuses: 15.551

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9825, entropy=0.0095, kl_div=0.0000
    Epoch 1: policy_loss=-0.0104, value_loss=0.9825, entropy=0.0098, kl_div=0.0245

=== Surrogate Model Training ===
Total samples: 5106

Training on 4930 samples (removed 176 outliers)
Reward range: [9.40, 19.33], mean: 14.51
  Created 13 candidate models for data size 4930
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.207 (std: 0.182)
  rf-tuned-xl: R2 = 0.208 (std: 0.186)
  gb-tuned-l: R2 = 0.229 (std: 0.154)
  gb-tuned-xl: R2 = 0.229 (std: 0.154)
  xgb-xl: R2 = 0.167 (std: 0.183)
  xgb-l: R2 = 0.167 (std: 0.183)
  mlp-adaptive-xl: R2 = 0.237 (std: 0.164)
  mlp-l: R2 = 0.229 (std: 0.163)
  svr-rbf-xl: R2 = 0.254 (std: 0.147)
  svr-poly-l: R2 = 0.254 (std: 0.147)
  knn-tuned-sqrt: R2 = 0.143 (std: 0.222)
  knn-tuned-l: R2 = 0.143 (std: 0.222)
  ridge: R2 = 0.019 (std: 0.149)

Model-based training with 8 models
Best R2: 0.254, Mean R2: 0.191
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=3324.2939, entropy=0.0124, kl_div=0.0000
    Epoch 1: policy_loss=0.0081, value_loss=3324.2944, entropy=0.0126, kl_div=0.0127
  Round 1/3: Mean predicted reward = -21.695
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9822, entropy=0.0116, kl_div=0.0000
    Epoch 1: policy_loss=-0.0021, value_loss=0.9822, entropy=0.0116, kl_div=0.0058
  Round 2/3: Mean predicted reward = 15.282
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9826, entropy=0.0109, kl_div=0.0000
    Epoch 1: policy_loss=-0.0040, value_loss=0.9826, entropy=0.0110, kl_div=0.0052
  Round 3/3: Mean predicted reward = 15.302

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 79 Results ---
  Mean Oracle Reward: 15.560
  Min Oracle Reward: 11.326
  Max Oracle Reward: 18.989
  Std Oracle Reward: 2.299
  Sequence Diversity: 0.703
  Models Used: 8
  Model R2 - Mean: 0.191, Max: 0.254, Count: 13
  Total Sequences Evaluated: 5106
    Oracle Count: 5056 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 80/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 5106
  Consistent improvement, increasing LR to 0.000360

--- Round 80 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  GTGTCCAGCATGGCAGCCCG
  ATCGGGCCCACCGGTGCGAT
  CGGCGACTACGGCTGCATCG
  AGCTGACGTCCGCTCCGGGA
  CCGTCGTAGCGAGGCGCTAC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.483
  Max reward: 18.744
  With intrinsic bonuses: 15.517

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9826, entropy=0.0120, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0996

=== Surrogate Model Training ===
Total samples: 5170

Training on 5000 samples (removed 170 outliers)
Reward range: [9.39, 19.40], mean: 14.53
  Created 13 candidate models for data size 5000
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.205 (std: 0.185)
  rf-tuned-xl: R2 = 0.207 (std: 0.187)
  gb-tuned-l: R2 = 0.228 (std: 0.152)
  gb-tuned-xl: R2 = 0.228 (std: 0.152)
  xgb-xl: R2 = 0.166 (std: 0.188)
  xgb-l: R2 = 0.166 (std: 0.188)
  mlp-adaptive-xl: R2 = 0.232 (std: 0.174)
  mlp-l: R2 = 0.226 (std: 0.158)
  svr-rbf-xl: R2 = 0.252 (std: 0.140)
  svr-poly-l: R2 = 0.252 (std: 0.140)
  knn-tuned-sqrt: R2 = 0.149 (std: 0.216)
  knn-tuned-l: R2 = 0.149 (std: 0.216)
  ridge: R2 = 0.013 (std: 0.153)

Model-based training with 8 models
Best R2: 0.252, Mean R2: 0.190
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.277 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.296 svr-poly-l:0.427 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=6332.3149, entropy=0.0133, kl_div=0.0000
    Epoch 1: policy_loss=-0.0058, value_loss=6332.3340, entropy=0.0132, kl_div=-0.1108
  Round 1/3: Mean predicted reward = -23.979
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.277 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.296 svr-poly-l:0.427 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9828, entropy=0.0167, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1269
  Round 2/3: Mean predicted reward = 15.331
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.277 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.296 svr-poly-l:0.427 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9828, entropy=0.0277, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0858
  Round 3/3: Mean predicted reward = 15.288

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 80 Results ---
  Mean Oracle Reward: 15.501
  Min Oracle Reward: 8.193
  Max Oracle Reward: 18.858
  Std Oracle Reward: 2.473
  Sequence Diversity: 0.734
  Models Used: 8
  Model R2 - Mean: 0.190, Max: 0.252, Count: 13
  Total Sequences Evaluated: 5170
    Oracle Count: 5120 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 81/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 5170
  Performance plateaued, reducing LR to 0.000136

--- Round 81 Configuration ---
Learning rate: 0.000136
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  GCCGTCCTAGGGCGCGCTAA
  GGCGCGCGGCACACCTATTG
  GGGAGTTGGCCACCCTGCCA
  TGGAACCCAGTCGGCGGTCC
  GGACCGAGTTCGAGCTGCCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.156
  Max reward: 18.900
  With intrinsic bonuses: 15.191

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9831, entropy=0.0291, kl_div=0.0000
    Epoch 1: policy_loss=-0.0222, value_loss=0.9831, entropy=0.0274, kl_div=-0.0464

=== Surrogate Model Training ===
Total samples: 5234

Training on 5065 samples (removed 169 outliers)
Reward range: [9.37, 19.40], mean: 14.54
  Created 13 candidate models for data size 5065
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.221 (std: 0.185)
  rf-tuned-xl: R2 = 0.224 (std: 0.186)
  gb-tuned-l: R2 = 0.243 (std: 0.157)
  gb-tuned-xl: R2 = 0.243 (std: 0.157)
  xgb-xl: R2 = 0.175 (std: 0.186)
  xgb-l: R2 = 0.175 (std: 0.186)
  mlp-adaptive-xl: R2 = 0.260 (std: 0.181)
  mlp-l: R2 = 0.245 (std: 0.174)
  svr-rbf-xl: R2 = 0.276 (std: 0.160)
  svr-poly-l: R2 = 0.276 (std: 0.160)
  knn-tuned-sqrt: R2 = 0.150 (std: 0.209)
  knn-tuned-l: R2 = 0.150 (std: 0.209)
  ridge: R2 = 0.027 (std: 0.161)

Model-based training with 8 models
Best R2: 0.276, Mean R2: 0.205
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.965 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.035 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=2233.2170, entropy=0.0277, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0579
  Round 1/3: Mean predicted reward = -14.356
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.965 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.035 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9830, entropy=0.0281, kl_div=0.0000
    Epoch 1: policy_loss=-0.0037, value_loss=0.9830, entropy=0.0271, kl_div=0.0039
  Round 2/3: Mean predicted reward = 15.128
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.965 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.035 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9832, entropy=0.0271, kl_div=0.0000
    Epoch 1: policy_loss=0.0088, value_loss=0.9832, entropy=0.0228, kl_div=-0.1054
  Round 3/3: Mean predicted reward = 15.050

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 81 Results ---
  Mean Oracle Reward: 15.155
  Min Oracle Reward: 11.558
  Max Oracle Reward: 18.733
  Std Oracle Reward: 2.163
  Sequence Diversity: 0.734
  Models Used: 8
  Model R2 - Mean: 0.205, Max: 0.276, Count: 13
  Total Sequences Evaluated: 5234
    Oracle Count: 5184 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 82/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 5234

--- Round 82 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.719) ---
  CCTCATCGGTACCAGGGGCG
  TTGGGTACCCCAGGCCGGCA
  TGCGAGCCACTGCGGCATCG
  GTACCGTACAGGGCGCGCTC
  CTGGCCCAGCATCGTCGAGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.006
  Max reward: 19.713
  With intrinsic bonuses: 15.014

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9833, entropy=0.0244, kl_div=0.0000
    Epoch 1: policy_loss=-0.0231, value_loss=0.9834, entropy=0.0213, kl_div=0.0098

=== Surrogate Model Training ===
Total samples: 5298

Training on 5129 samples (removed 169 outliers)
Reward range: [9.36, 19.40], mean: 14.54
  Created 13 candidate models for data size 5129
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.222 (std: 0.197)
  rf-tuned-xl: R2 = 0.225 (std: 0.198)
  gb-tuned-l: R2 = 0.250 (std: 0.164)
  gb-tuned-xl: R2 = 0.250 (std: 0.164)
  xgb-xl: R2 = 0.182 (std: 0.202)
  xgb-l: R2 = 0.182 (std: 0.202)
  mlp-adaptive-xl: R2 = 0.246 (std: 0.166)
  mlp-l: R2 = 0.245 (std: 0.179)
  svr-rbf-xl: R2 = 0.283 (std: 0.171)
  svr-poly-l: R2 = 0.283 (std: 0.171)
  knn-tuned-sqrt: R2 = 0.153 (std: 0.205)
  knn-tuned-l: R2 = 0.153 (std: 0.205)
  ridge: R2 = 0.029 (std: 0.181)

Model-based training with 8 models
Best R2: 0.283, Mean R2: 0.208
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=3373.2070, entropy=0.0199, kl_div=0.0000
    Epoch 1: policy_loss=0.0362, value_loss=3373.2129, entropy=0.0200, kl_div=-0.0213
  Round 1/3: Mean predicted reward = -22.505
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9830, entropy=0.0207, kl_div=0.0000
    Epoch 1: policy_loss=0.0323, value_loss=0.9831, entropy=0.0224, kl_div=-0.0724
  Round 2/3: Mean predicted reward = 15.021
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9832, entropy=0.0200, kl_div=0.0000
    Epoch 1: policy_loss=-0.0020, value_loss=0.9832, entropy=0.0211, kl_div=0.0011
  Round 3/3: Mean predicted reward = 15.182

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 82 Results ---
  Mean Oracle Reward: 15.004
  Min Oracle Reward: 9.477
  Max Oracle Reward: 19.498
  Std Oracle Reward: 2.463
  Sequence Diversity: 0.719
  Models Used: 8
  Model R2 - Mean: 0.208, Max: 0.283, Count: 13
  Total Sequences Evaluated: 5298
    Oracle Count: 5248 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 83/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 5298

--- Round 83 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.719) ---
  TGGCACGACCCTTCGGACGG
  GTGGCGTCCAGGATCCCCGA
  GACCGTCTGCTAACCGGGGC
  CTAGCGGGGCGCTGACCACT
  GGCCGGTAGACCTCCGTGAC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.321
  Max reward: 19.136
  With intrinsic bonuses: 15.298

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9832, entropy=0.0236, kl_div=0.0000
    Epoch 1: policy_loss=-0.0283, value_loss=0.9832, entropy=0.0230, kl_div=-0.0122

=== Surrogate Model Training ===
Total samples: 5362

Training on 5198 samples (removed 164 outliers)
Reward range: [9.36, 19.52], mean: 14.56
  Created 13 candidate models for data size 5198
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.232 (std: 0.201)
  rf-tuned-xl: R2 = 0.236 (std: 0.200)
  gb-tuned-l: R2 = 0.258 (std: 0.174)
  gb-tuned-xl: R2 = 0.258 (std: 0.174)
  xgb-xl: R2 = 0.198 (std: 0.202)
  xgb-l: R2 = 0.198 (std: 0.202)
  mlp-adaptive-xl: R2 = 0.255 (std: 0.177)
  mlp-l: R2 = 0.267 (std: 0.177)
  svr-rbf-xl: R2 = 0.291 (std: 0.174)
  svr-poly-l: R2 = 0.291 (std: 0.174)
  knn-tuned-sqrt: R2 = 0.149 (std: 0.204)
  knn-tuned-l: R2 = 0.149 (std: 0.204)
  ridge: R2 = 0.035 (std: 0.185)

Model-based training with 8 models
Best R2: 0.291, Mean R2: 0.217
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.943 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.057 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=3216.8750, entropy=0.0237, kl_div=0.0000
    Epoch 1: policy_loss=-0.0099, value_loss=3216.8782, entropy=0.0245, kl_div=-0.0591
  Round 1/3: Mean predicted reward = -24.666
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.943 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.057 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9833, entropy=0.0273, kl_div=0.0000
    Epoch 1: policy_loss=-0.0013, value_loss=0.9833, entropy=0.0274, kl_div=-0.0270
  Round 2/3: Mean predicted reward = 15.324
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.943 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.057 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9834, entropy=0.0236, kl_div=0.0000
    Epoch 1: policy_loss=-0.0201, value_loss=0.9834, entropy=0.0237, kl_div=0.0486
  Round 3/3: Mean predicted reward = 15.238

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 83 Results ---
  Mean Oracle Reward: 15.304
  Min Oracle Reward: 9.400
  Max Oracle Reward: 18.912
  Std Oracle Reward: 2.508
  Sequence Diversity: 0.719
  Models Used: 8
  Model R2 - Mean: 0.217, Max: 0.291, Count: 13
  Total Sequences Evaluated: 5362
    Oracle Count: 5312 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 84/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 5362

--- Round 84 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.719) ---
  CACCCGAGGGTCCTTCGAGG
  TCGAAGGCACGTGTGCCCGC
  CCTGAGACCCGTCCAGGTGG
  CGGACCTCGTAGTGCCGCGA
  TCGCGTCGACGGGAACCGTC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.628
  Max reward: 19.356
  With intrinsic bonuses: 15.644

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9834, entropy=0.0215, kl_div=0.0000
    Epoch 1: policy_loss=-0.0039, value_loss=0.9834, entropy=0.0212, kl_div=0.0062

=== Surrogate Model Training ===
Total samples: 5426

Training on 5262 samples (removed 164 outliers)
Reward range: [9.33, 19.52], mean: 14.57
  Created 13 candidate models for data size 5262
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.229 (std: 0.209)
  rf-tuned-xl: R2 = 0.229 (std: 0.210)
  gb-tuned-l: R2 = 0.261 (std: 0.183)
  gb-tuned-xl: R2 = 0.261 (std: 0.183)
  xgb-xl: R2 = 0.198 (std: 0.211)
  xgb-l: R2 = 0.198 (std: 0.211)
  mlp-adaptive-xl: R2 = 0.252 (std: 0.183)
  mlp-l: R2 = 0.265 (std: 0.189)
  svr-rbf-xl: R2 = 0.296 (std: 0.184)
  svr-poly-l: R2 = 0.296 (std: 0.184)
  knn-tuned-sqrt: R2 = 0.152 (std: 0.209)
  knn-tuned-l: R2 = 0.152 (std: 0.209)
  ridge: R2 = 0.039 (std: 0.212)

Model-based training with 8 models
Best R2: 0.296, Mean R2: 0.217
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.819 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.181 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=4143.8350, entropy=0.0227, kl_div=0.0000
    Epoch 1: policy_loss=-0.0081, value_loss=4143.8354, entropy=0.0224, kl_div=-0.0178
  Round 1/3: Mean predicted reward = -27.065
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.819 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.181 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9834, entropy=0.0240, kl_div=0.0000
    Epoch 1: policy_loss=0.0105, value_loss=0.9834, entropy=0.0238, kl_div=-0.0073
  Round 2/3: Mean predicted reward = 15.301
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.819 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.181 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9833, entropy=0.0191, kl_div=0.0000
    Epoch 1: policy_loss=-0.0099, value_loss=0.9833, entropy=0.0190, kl_div=0.0228
  Round 3/3: Mean predicted reward = 15.184

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 84 Results ---
  Mean Oracle Reward: 15.624
  Min Oracle Reward: 6.754
  Max Oracle Reward: 19.141
  Std Oracle Reward: 2.640
  Sequence Diversity: 0.719
  Models Used: 8
  Model R2 - Mean: 0.217, Max: 0.296, Count: 13
  Total Sequences Evaluated: 5426
    Oracle Count: 5376 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 85/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 5426
  Consistent improvement, increasing LR to 0.000360

--- Round 85 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.719) ---
  CACTCCGCGTGCCGGAGTGA
  GACTTGAAGGGTCGCCCCCG
  ACCGGGCGACGATCCGCTGT
  TCGGCACCTGGAGATGCGCC
  GTCGCGTAGACCAGCTCCGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.328
  Max reward: 20.351
  With intrinsic bonuses: 15.351

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=1.1796, entropy=0.0200, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1011

=== Surrogate Model Training ===
Total samples: 5490

Training on 5325 samples (removed 165 outliers)
Reward range: [9.28, 19.61], mean: 14.58
  Created 13 candidate models for data size 5325
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.244 (std: 0.213)
  rf-tuned-xl: R2 = 0.241 (std: 0.212)
  gb-tuned-l: R2 = 0.269 (std: 0.196)
  gb-tuned-xl: R2 = 0.269 (std: 0.196)
  xgb-xl: R2 = 0.217 (std: 0.211)
  xgb-l: R2 = 0.217 (std: 0.211)
  mlp-adaptive-xl: R2 = 0.269 (std: 0.200)
  mlp-l: R2 = 0.278 (std: 0.195)
  svr-rbf-xl: R2 = 0.305 (std: 0.197)
  svr-poly-l: R2 = 0.305 (std: 0.197)
  knn-tuned-sqrt: R2 = 0.161 (std: 0.211)
  knn-tuned-l: R2 = 0.161 (std: 0.211)
  ridge: R2 = 0.043 (std: 0.222)

Model-based training with 10 models
Best R2: 0.305, Mean R2: 0.229
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:1.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1707.1598, entropy=0.0202, kl_div=0.0000
    Epoch 1: policy_loss=0.0118, value_loss=1707.1656, entropy=0.0204, kl_div=-0.0299
  Round 1/5: Mean predicted reward = -24.426
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:1.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9834, entropy=0.0236, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2414
  Round 2/5: Mean predicted reward = 15.087
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:1.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9834, entropy=0.0222, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2116
  Round 3/5: Mean predicted reward = 15.493
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:1.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9834, entropy=0.0130, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3535
  Round 4/5: Mean predicted reward = 15.363
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:1.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9836, entropy=0.0104, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3627
  Round 5/5: Mean predicted reward = 15.422

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 85 Results ---
  Mean Oracle Reward: 15.341
  Min Oracle Reward: 7.480
  Max Oracle Reward: 19.933
  Std Oracle Reward: 3.022
  Sequence Diversity: 0.719
  Models Used: 10
  Model R2 - Mean: 0.229, Max: 0.305, Count: 13
  Total Sequences Evaluated: 5490
    Oracle Count: 5440 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 86/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 5490

--- Round 86 Configuration ---
Learning rate: 0.000272
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.750) ---
  CGGCCGGCATGCCCGAGTTA
  TGCGATGTGGCCCGCGACAC
  GACCGCTGCCGTTGGCCGAA
  GGCCCCTCACGCTGAAGTGG
  CACACACGTCGGCGGTGGCT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 15.388
  Max reward: 18.891
  With intrinsic bonuses: 15.410

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9837, entropy=0.0149, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0738

=== Surrogate Model Training ===
Total samples: 5554

Training on 5389 samples (removed 165 outliers)
Reward range: [9.28, 19.61], mean: 14.59
  Created 13 candidate models for data size 5389
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.250 (std: 0.212)
  rf-tuned-xl: R2 = 0.249 (std: 0.211)
  gb-tuned-l: R2 = 0.280 (std: 0.197)
  gb-tuned-xl: R2 = 0.280 (std: 0.197)
  xgb-xl: R2 = 0.219 (std: 0.216)
  xgb-l: R2 = 0.219 (std: 0.216)
  mlp-adaptive-xl: R2 = 0.279 (std: 0.201)
  mlp-l: R2 = 0.283 (std: 0.201)
  svr-rbf-xl: R2 = 0.314 (std: 0.199)
  svr-poly-l: R2 = 0.314 (std: 0.199)
  knn-tuned-sqrt: R2 = 0.165 (std: 0.203)
  knn-tuned-l: R2 = 0.165 (std: 0.203)
  ridge: R2 = 0.055 (std: 0.224)

Model-based training with 10 models
Best R2: 0.314, Mean R2: 0.236
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=2783.9937, entropy=0.0223, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4092
  Round 1/5: Mean predicted reward = -25.005
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9837, entropy=0.0279, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.4278
  Round 2/5: Mean predicted reward = 15.079
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9839, entropy=0.0450, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3678
  Round 3/5: Mean predicted reward = 14.829
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9840, entropy=0.0475, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3028
  Round 4/5: Mean predicted reward = 14.554
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.0567, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.3882
  Round 5/5: Mean predicted reward = 14.203

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 86 Results ---
  Mean Oracle Reward: 15.399
  Min Oracle Reward: 9.458
  Max Oracle Reward: 18.864
  Std Oracle Reward: 2.311
  Sequence Diversity: 0.750
  Models Used: 10
  Model R2 - Mean: 0.236, Max: 0.314, Count: 13
  Total Sequences Evaluated: 5554
    Oracle Count: 5504 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 87/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 5554

--- Round 87 Configuration ---
Learning rate: 0.000200
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.875) ---
  CGCGATGGCCAGTAGCCCTG
  GGGTGCAGGCTGCCTCCCAA
  AACTGCCCCCGCGTGTGGGA
  CGGCCGCCGGAGTGTATCAC
  CAAAGCCCGTGGTGGCCGTC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 12.430
  Max reward: 16.767
  With intrinsic bonuses: 12.421

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=3.2248, entropy=0.0535, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0675

=== Surrogate Model Training ===
Total samples: 5618

Training on 5444 samples (removed 174 outliers)
Reward range: [9.25, 19.61], mean: 14.58
  Created 13 candidate models for data size 5444
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.247 (std: 0.220)
  rf-tuned-xl: R2 = 0.244 (std: 0.222)
  gb-tuned-l: R2 = 0.281 (std: 0.205)
  gb-tuned-xl: R2 = 0.281 (std: 0.205)
  xgb-xl: R2 = 0.211 (std: 0.226)
  xgb-l: R2 = 0.211 (std: 0.226)
  mlp-adaptive-xl: R2 = 0.288 (std: 0.209)
  mlp-l: R2 = 0.273 (std: 0.205)
  svr-rbf-xl: R2 = 0.319 (std: 0.202)
  svr-poly-l: R2 = 0.319 (std: 0.202)
  knn-tuned-sqrt: R2 = 0.169 (std: 0.216)
  knn-tuned-l: R2 = 0.169 (std: 0.216)
  ridge: R2 = 0.065 (std: 0.235)

Model-based training with 10 models
Best R2: 0.319, Mean R2: 0.237
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9849, entropy=0.0619, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1516
  Round 1/5: Mean predicted reward = 13.236
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9846, entropy=0.0610, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1205
  Round 2/5: Mean predicted reward = 14.014
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9844, entropy=0.0633, kl_div=0.0000
    Epoch 1: policy_loss=-0.0042, value_loss=0.9844, entropy=0.0583, kl_div=-0.0078
  Round 3/5: Mean predicted reward = 14.022
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9845, entropy=0.0586, kl_div=0.0000
    Epoch 1: policy_loss=0.0277, value_loss=0.9845, entropy=0.0638, kl_div=-0.0467
  Round 4/5: Mean predicted reward = 13.950
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9845, entropy=0.0637, kl_div=0.0000
    Epoch 1: policy_loss=-0.0091, value_loss=0.9845, entropy=0.0676, kl_div=0.0086
  Round 5/5: Mean predicted reward = 13.883

  === Progress Analysis ===
  Status: NORMAL

--- Round 87 Results ---
  Mean Oracle Reward: 12.430
  Min Oracle Reward: 0.000
  Max Oracle Reward: 16.814
  Std Oracle Reward: 3.189
  Sequence Diversity: 0.875
  Models Used: 10
  Model R2 - Mean: 0.237, Max: 0.319, Count: 13
  Total Sequences Evaluated: 5618
    Oracle Count: 5568 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 88/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 5618

--- Round 88 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.844) ---
  CAGGGCAGCGGTGTACCCTC
  CGGGGGTGCCCACACCTAGT
  GGTCGGTGACCGCCCAACTG
  GTTTGCCCCGACGGGAGCCA
  ATGGCCGGCCGGCCATATCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 10.391
  Max reward: 21.126
  With intrinsic bonuses: 10.397

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=5.9299, entropy=0.0538, kl_div=0.0000
    Epoch 1: policy_loss=-0.0120, value_loss=5.9299, entropy=0.0543, kl_div=-0.0097

=== Surrogate Model Training ===
Total samples: 5682

Training on 5486 samples (removed 196 outliers)
Reward range: [9.25, 19.61], mean: 14.57
  Created 13 candidate models for data size 5486
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.246 (std: 0.223)
  rf-tuned-xl: R2 = 0.246 (std: 0.222)
  gb-tuned-l: R2 = 0.280 (std: 0.201)
  gb-tuned-xl: R2 = 0.280 (std: 0.201)
  xgb-xl: R2 = 0.210 (std: 0.229)
  xgb-l: R2 = 0.210 (std: 0.229)
  mlp-adaptive-xl: R2 = 0.279 (std: 0.210)
  mlp-l: R2 = 0.277 (std: 0.200)
  svr-rbf-xl: R2 = 0.319 (std: 0.202)
  svr-poly-l: R2 = 0.319 (std: 0.202)
  knn-tuned-sqrt: R2 = 0.170 (std: 0.210)
  knn-tuned-l: R2 = 0.170 (std: 0.210)
  ridge: R2 = 0.067 (std: 0.234)

Model-based training with 10 models
Best R2: 0.319, Mean R2: 0.236
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9851, entropy=0.0661, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1260
  Round 1/5: Mean predicted reward = 12.953
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9844, entropy=0.0624, kl_div=0.0000
    Epoch 1: policy_loss=-0.0222, value_loss=0.9844, entropy=0.0692, kl_div=0.0327
  Round 2/5: Mean predicted reward = 13.945
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.0528, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0585
  Round 3/5: Mean predicted reward = 14.151
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9843, entropy=0.0452, kl_div=0.0000
    Epoch 1: policy_loss=-0.0519, value_loss=0.9843, entropy=0.0402, kl_div=0.0450
  Round 4/5: Mean predicted reward = 14.317
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9841, entropy=0.0368, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0899
  Round 5/5: Mean predicted reward = 14.715

  === Progress Analysis ===
  Status: NORMAL

--- Round 88 Results ---
  Mean Oracle Reward: 10.382
  Min Oracle Reward: 0.000
  Max Oracle Reward: 21.226
  Std Oracle Reward: 5.272
  Sequence Diversity: 0.844
  Models Used: 10
  Model R2 - Mean: 0.236, Max: 0.319, Count: 13
  Total Sequences Evaluated: 5682
    Oracle Count: 5632 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 89/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 5682

--- Round 89 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.797) ---
  CGCTGAGCGACCGGGCTCTA
  CATGGCCTGTCGACGGACGC
  CGAGCTGGCCTCACAGGGTC
  GGGGTCTGGTCCCAAGACCC
  GGCGTCACTGCCAGCGCGAT
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.628
  Max reward: 16.931
  With intrinsic bonuses: 13.616

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9844, entropy=0.0357, kl_div=0.0000
    Epoch 1: policy_loss=-0.0395, value_loss=0.9844, entropy=0.0366, kl_div=-0.0416

=== Surrogate Model Training ===
Total samples: 5746

Training on 5548 samples (removed 198 outliers)
Reward range: [9.25, 19.52], mean: 14.56
  Created 13 candidate models for data size 5548
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.253 (std: 0.223)
  rf-tuned-xl: R2 = 0.253 (std: 0.219)
  gb-tuned-l: R2 = 0.291 (std: 0.204)
  gb-tuned-xl: R2 = 0.291 (std: 0.204)
  xgb-xl: R2 = 0.228 (std: 0.222)
  xgb-l: R2 = 0.228 (std: 0.222)
  mlp-adaptive-xl: R2 = 0.295 (std: 0.199)
  mlp-l: R2 = 0.291 (std: 0.209)
  svr-rbf-xl: R2 = 0.331 (std: 0.212)
  svr-poly-l: R2 = 0.331 (std: 0.212)
  knn-tuned-sqrt: R2 = 0.168 (std: 0.208)
  knn-tuned-l: R2 = 0.168 (std: 0.208)
  ridge: R2 = 0.083 (std: 0.237)

Model-based training with 10 models
Best R2: 0.331, Mean R2: 0.247
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1009.0387, entropy=0.0383, kl_div=0.0000
    Epoch 1: policy_loss=0.0383, value_loss=1009.0391, entropy=0.0392, kl_div=-0.0400
  Round 1/5: Mean predicted reward = -4.423
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9840, entropy=0.0402, kl_div=0.0000
    Epoch 1: policy_loss=-0.0128, value_loss=0.9840, entropy=0.0408, kl_div=-0.0067
  Round 2/5: Mean predicted reward = 14.661
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9838, entropy=0.0409, kl_div=0.0000
    Epoch 1: policy_loss=-0.0009, value_loss=0.9838, entropy=0.0413, kl_div=-0.0262
  Round 3/5: Mean predicted reward = 15.093
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9838, entropy=0.0406, kl_div=0.0000
    Epoch 1: policy_loss=-0.0053, value_loss=0.9838, entropy=0.0407, kl_div=0.0003
  Round 4/5: Mean predicted reward = 15.155
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:1.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9838, entropy=0.0416, kl_div=0.0000
    Epoch 1: policy_loss=-0.0207, value_loss=0.9838, entropy=0.0415, kl_div=0.0154
  Round 5/5: Mean predicted reward = 15.263

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 89 Results ---
  Mean Oracle Reward: 13.614
  Min Oracle Reward: 8.688
  Max Oracle Reward: 16.915
  Std Oracle Reward: 1.857
  Sequence Diversity: 0.797
  Models Used: 10
  Model R2 - Mean: 0.247, Max: 0.331, Count: 13
  Total Sequences Evaluated: 5746
    Oracle Count: 5696 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 90/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 5746

--- Round 90 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.875) ---
  GCCGAGCGAACGGCCTTTGC
  GCTGGGACACCGACGTCTCG
  AGCTCGGTACCCTCGCGAGG
  GGGCAGCTTACCGACGCCTG
  CCCGGCGCTTACGGAAGCTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.768
  Max reward: 17.253
  With intrinsic bonuses: 13.708

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9843, entropy=0.0433, kl_div=0.0000
    Epoch 1: policy_loss=-0.0392, value_loss=0.9843, entropy=0.0438, kl_div=0.0285

=== Surrogate Model Training ===
Total samples: 5810

Training on 5609 samples (removed 201 outliers)
Reward range: [9.27, 19.52], mean: 14.55
  Created 13 candidate models for data size 5609
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.251 (std: 0.235)
  rf-tuned-xl: R2 = 0.250 (std: 0.232)
  gb-tuned-l: R2 = 0.290 (std: 0.218)
  gb-tuned-xl: R2 = 0.290 (std: 0.218)
  xgb-xl: R2 = 0.217 (std: 0.239)
  xgb-l: R2 = 0.217 (std: 0.239)
  mlp-adaptive-xl: R2 = 0.298 (std: 0.214)
  mlp-l: R2 = 0.286 (std: 0.219)
  svr-rbf-xl: R2 = 0.329 (std: 0.215)
  svr-poly-l: R2 = 0.329 (std: 0.215)
  knn-tuned-sqrt: R2 = 0.165 (std: 0.207)
  knn-tuned-l: R2 = 0.165 (std: 0.207)
  ridge: R2 = 0.089 (std: 0.254)

Model-based training with 10 models
Best R2: 0.329, Mean R2: 0.244
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.885 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.115 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1676.1245, entropy=0.0381, kl_div=0.0000
    Epoch 1: policy_loss=0.0022, value_loss=1676.1274, entropy=0.0376, kl_div=-0.0161
  Round 1/5: Mean predicted reward = -19.290
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.885 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.115 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9839, entropy=0.0413, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1877
  Round 2/5: Mean predicted reward = 15.028
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.885 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.115 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9840, entropy=0.0358, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1075
  Round 3/5: Mean predicted reward = 14.984
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.885 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.115 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9839, entropy=0.0365, kl_div=0.0000
    Epoch 1: policy_loss=0.0087, value_loss=0.9839, entropy=0.0364, kl_div=-0.0285
  Round 4/5: Mean predicted reward = 15.097
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.000 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.885 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.115 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9840, entropy=0.0356, kl_div=0.0000
    Epoch 1: policy_loss=-0.0282, value_loss=0.9840, entropy=0.0358, kl_div=-0.0556
  Round 5/5: Mean predicted reward = 15.148

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 90 Results ---
  Mean Oracle Reward: 13.722
  Min Oracle Reward: 8.815
  Max Oracle Reward: 17.437
  Std Oracle Reward: 1.823
  Sequence Diversity: 0.875
  Models Used: 10
  Model R2 - Mean: 0.244, Max: 0.329, Count: 13
  Total Sequences Evaluated: 5810
    Oracle Count: 5760 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 91/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 5810
  Consistent improvement, increasing LR to 0.000327

--- Round 91 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.781) ---
  CGTGTCCGCGACATGGCGAC
  CGGCTGCGGTGCACCCGATA
  GGGACTCCTGACGCCCTGAG
  GTCAGTGCGTCCACCCGAGG
  CTCAACGACGTGGGCCTGCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.713
  Max reward: 17.086
  With intrinsic bonuses: 13.695

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9845, entropy=0.0354, kl_div=0.0000
    Epoch 1: policy_loss=-0.0291, value_loss=0.9845, entropy=0.0349, kl_div=-0.0319

=== Surrogate Model Training ===
Total samples: 5874

Training on 5670 samples (removed 204 outliers)
Reward range: [9.27, 19.52], mean: 14.55
  Created 13 candidate models for data size 5670
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.253 (std: 0.234)
  rf-tuned-xl: R2 = 0.251 (std: 0.236)
  gb-tuned-l: R2 = 0.291 (std: 0.215)
  gb-tuned-xl: R2 = 0.291 (std: 0.215)
  xgb-xl: R2 = 0.216 (std: 0.240)
  xgb-l: R2 = 0.216 (std: 0.240)
  mlp-adaptive-xl: R2 = 0.297 (std: 0.210)
  mlp-l: R2 = 0.297 (std: 0.212)
  svr-rbf-xl: R2 = 0.327 (std: 0.202)
  svr-poly-l: R2 = 0.327 (std: 0.202)
  knn-tuned-sqrt: R2 = 0.163 (std: 0.205)
  knn-tuned-l: R2 = 0.163 (std: 0.205)
  ridge: R2 = 0.099 (std: 0.251)

Model-based training with 10 models
Best R2: 0.327, Mean R2: 0.245
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.343 rf-tuned-xl:0.339 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.098 mlp-l:0.221 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1678.9740, entropy=0.0318, kl_div=0.0000
    Epoch 1: policy_loss=0.0401, value_loss=1678.9772, entropy=0.0298, kl_div=0.0159
  Round 1/5: Mean predicted reward = -9.463
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.343 rf-tuned-xl:0.339 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.098 mlp-l:0.221 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9840, entropy=0.0348, kl_div=0.0000
    Epoch 1: policy_loss=0.0016, value_loss=0.9840, entropy=0.0352, kl_div=0.0445
  Round 2/5: Mean predicted reward = 15.109
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.343 rf-tuned-xl:0.339 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.098 mlp-l:0.221 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9839, entropy=0.0305, kl_div=0.0000
    Epoch 1: policy_loss=-0.0421, value_loss=0.9839, entropy=0.0303, kl_div=-0.0139
  Round 3/5: Mean predicted reward = 15.279
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.343 rf-tuned-xl:0.339 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.098 mlp-l:0.221 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9840, entropy=0.0311, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.2366
  Round 4/5: Mean predicted reward = 15.166
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.343 rf-tuned-xl:0.339 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.098 mlp-l:0.221 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9840, entropy=0.0304, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0860
  Round 5/5: Mean predicted reward = 14.976

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 91 Results ---
  Mean Oracle Reward: 13.693
  Min Oracle Reward: 7.551
  Max Oracle Reward: 17.157
  Std Oracle Reward: 1.964
  Sequence Diversity: 0.781
  Models Used: 10
  Model R2 - Mean: 0.245, Max: 0.327, Count: 13
  Total Sequences Evaluated: 5874
    Oracle Count: 5824 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 92/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 5874
  Performance plateaued, reducing LR to 0.000100

--- Round 92 Configuration ---
Learning rate: 0.000100
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.750) ---
  GGGACCTCTCGGCCTGACGA
  TCCAGGCTAGGGGCCATCGC
  AGCAAGCTCTGGCTGCCCGG
  GACAGCGTCGGGCCTCTCAG
  GACTTGGCCTCCGGCAGGAC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.962
  Max reward: 17.198
  With intrinsic bonuses: 14.025

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9844, entropy=0.0298, kl_div=0.0000
    Epoch 1: policy_loss=-0.0194, value_loss=0.9844, entropy=0.0293, kl_div=0.0052

=== Surrogate Model Training ===
Total samples: 5938

Training on 5731 samples (removed 207 outliers)
Reward range: [9.28, 19.51], mean: 14.54
  Created 13 candidate models for data size 5731
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.244 (std: 0.238)
  rf-tuned-xl: R2 = 0.245 (std: 0.241)
  gb-tuned-l: R2 = 0.287 (std: 0.218)
  gb-tuned-xl: R2 = 0.287 (std: 0.218)
  xgb-xl: R2 = 0.228 (std: 0.229)
  xgb-l: R2 = 0.228 (std: 0.229)
  mlp-adaptive-xl: R2 = 0.284 (std: 0.214)
  mlp-l: R2 = 0.274 (std: 0.227)
  svr-rbf-xl: R2 = 0.316 (std: 0.195)
  svr-poly-l: R2 = 0.316 (std: 0.195)
  knn-tuned-sqrt: R2 = 0.164 (std: 0.211)
  knn-tuned-l: R2 = 0.164 (std: 0.211)
  ridge: R2 = 0.101 (std: 0.253)

Model-based training with 10 models
Best R2: 0.316, Mean R2: 0.242
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.589 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.411 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1824.8733, entropy=0.0290, kl_div=0.0000
    Epoch 1: policy_loss=0.0042, value_loss=1824.8744, entropy=0.0282, kl_div=0.0040
  Round 1/5: Mean predicted reward = -23.591
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.589 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.411 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9840, entropy=0.0292, kl_div=0.0000
    Epoch 1: policy_loss=0.0027, value_loss=0.9840, entropy=0.0297, kl_div=0.0013
  Round 2/5: Mean predicted reward = 14.857
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.589 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.411 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=0.0323, kl_div=0.0000
    Epoch 1: policy_loss=0.0011, value_loss=0.9841, entropy=0.0330, kl_div=0.0115
  Round 3/5: Mean predicted reward = 15.069
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.589 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.411 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9840, entropy=0.0295, kl_div=0.0000
    Epoch 1: policy_loss=-0.0117, value_loss=0.9840, entropy=0.0292, kl_div=-0.0051
  Round 4/5: Mean predicted reward = 15.036
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.589 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.411 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=0.0311, kl_div=0.0000
    Epoch 1: policy_loss=-0.0032, value_loss=0.9841, entropy=0.0310, kl_div=0.0175
  Round 5/5: Mean predicted reward = 15.029

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 92 Results ---
  Mean Oracle Reward: 13.973
  Min Oracle Reward: 9.288
  Max Oracle Reward: 17.194
  Std Oracle Reward: 1.686
  Sequence Diversity: 0.750
  Models Used: 10
  Model R2 - Mean: 0.242, Max: 0.316, Count: 13
  Total Sequences Evaluated: 5938
    Oracle Count: 5888 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 93/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 5938

--- Round 93 Configuration ---
Learning rate: 0.000110
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.766) ---
  CCGGTGATTCCCGCCGAAGG
  AGCTGGCCGCTGCACTCGGA
  CGCCCTTGGGAACCGTAGCG
  CCGGTCGCGCTAACAGTGCG
  CTATGACGCAGGCGCCGCTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.084
  Max reward: 17.263
  With intrinsic bonuses: 14.081

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9843, entropy=0.0290, kl_div=0.0000
    Epoch 1: policy_loss=-0.0267, value_loss=0.9843, entropy=0.0280, kl_div=-0.0085

=== Surrogate Model Training ===
Total samples: 6002

Training on 5787 samples (removed 215 outliers)
Reward range: [9.33, 19.40], mean: 14.53
  Created 13 candidate models for data size 5787
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.242 (std: 0.240)
  rf-tuned-xl: R2 = 0.239 (std: 0.240)
  gb-tuned-l: R2 = 0.283 (std: 0.212)
  gb-tuned-xl: R2 = 0.283 (std: 0.212)
  xgb-xl: R2 = 0.214 (std: 0.239)
  xgb-l: R2 = 0.214 (std: 0.239)
  mlp-adaptive-xl: R2 = 0.289 (std: 0.212)
  mlp-l: R2 = 0.283 (std: 0.216)
  svr-rbf-xl: R2 = 0.307 (std: 0.191)
  svr-poly-l: R2 = 0.307 (std: 0.191)
  knn-tuned-sqrt: R2 = 0.167 (std: 0.218)
  knn-tuned-l: R2 = 0.167 (std: 0.218)
  ridge: R2 = 0.103 (std: 0.252)

Model-based training with 10 models
Best R2: 0.307, Mean R2: 0.238
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.743 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.257 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=5613.6289, entropy=0.0259, kl_div=0.0000
    Epoch 1: policy_loss=0.0353, value_loss=5613.6318, entropy=0.0251, kl_div=-0.0154
  Round 1/5: Mean predicted reward = -26.400
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.743 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.257 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=0.0272, kl_div=0.0000
    Epoch 1: policy_loss=-0.0118, value_loss=0.9841, entropy=0.0269, kl_div=0.0000
  Round 2/5: Mean predicted reward = 15.318
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.743 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.257 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9841, entropy=0.0263, kl_div=0.0000
    Epoch 1: policy_loss=0.0007, value_loss=0.9841, entropy=0.0264, kl_div=0.0295
  Round 3/5: Mean predicted reward = 15.106
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.743 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.257 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=0.0265, kl_div=0.0000
    Epoch 1: policy_loss=-0.0101, value_loss=0.9841, entropy=0.0262, kl_div=-0.0053
  Round 4/5: Mean predicted reward = 15.045
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.743 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.257 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9841, entropy=0.0236, kl_div=0.0000
    Epoch 1: policy_loss=-0.0061, value_loss=0.9841, entropy=0.0236, kl_div=0.0074
  Round 5/5: Mean predicted reward = 14.984

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 93 Results ---
  Mean Oracle Reward: 14.084
  Min Oracle Reward: 7.749
  Max Oracle Reward: 17.484
  Std Oracle Reward: 1.736
  Sequence Diversity: 0.766
  Models Used: 10
  Model R2 - Mean: 0.238, Max: 0.307, Count: 13
  Total Sequences Evaluated: 6002
    Oracle Count: 5952 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 94/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 6002
  Consistent improvement, increasing LR to 0.000045

--- Round 94 Configuration ---
Learning rate: 0.000045
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.750) ---
  GGGGCCCGCACAAGCTTTCG
  GGCCGTAGCCTGTCCGAGCA
  GGTACGCGGCGCTACGCTAC
  GGCCGCTCACCATGCTGAGG
  CCGTCGACCTATCAGGGGCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.188
  Max reward: 17.179
  With intrinsic bonuses: 14.179

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9844, entropy=0.0272, kl_div=0.0000
    Epoch 1: policy_loss=-0.0252, value_loss=0.9844, entropy=0.0272, kl_div=-0.0014

=== Surrogate Model Training ===
Total samples: 6066

Training on 5852 samples (removed 214 outliers)
Reward range: [9.28, 19.40], mean: 14.53
  Created 13 candidate models for data size 5852
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.237 (std: 0.236)
  rf-tuned-xl: R2 = 0.234 (std: 0.236)
  gb-tuned-l: R2 = 0.275 (std: 0.209)
  gb-tuned-xl: R2 = 0.275 (std: 0.209)
  xgb-xl: R2 = 0.209 (std: 0.233)
  xgb-l: R2 = 0.209 (std: 0.233)
  mlp-adaptive-xl: R2 = 0.266 (std: 0.228)
  mlp-l: R2 = 0.274 (std: 0.208)
  svr-rbf-xl: R2 = 0.300 (std: 0.193)
  svr-poly-l: R2 = 0.300 (std: 0.193)
  knn-tuned-sqrt: R2 = 0.162 (std: 0.229)
  knn-tuned-l: R2 = 0.162 (std: 0.229)
  ridge: R2 = 0.104 (std: 0.254)

Model-based training with 10 models
Best R2: 0.300, Mean R2: 0.231
Running 5 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.834 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.166 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=1999.6991, entropy=0.0263, kl_div=0.0000
    Epoch 1: policy_loss=-0.0038, value_loss=1999.6996, entropy=0.0264, kl_div=-0.0088
  Round 1/5: Mean predicted reward = -24.101
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.834 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.166 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.0281, kl_div=0.0000
    Epoch 1: policy_loss=-0.0087, value_loss=0.9842, entropy=0.0280, kl_div=-0.0054
  Round 2/5: Mean predicted reward = 15.060
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.834 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.166 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9841, entropy=0.0250, kl_div=0.0000
    Epoch 1: policy_loss=0.0093, value_loss=0.9841, entropy=0.0247, kl_div=0.0053
  Round 3/5: Mean predicted reward = 15.055
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.834 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.166 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=0.0271, kl_div=0.0000
    Epoch 1: policy_loss=-0.0098, value_loss=0.9841, entropy=0.0278, kl_div=0.0062
  Round 4/5: Mean predicted reward = 14.983
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.834 gb-tuned-l:0.000 gb-tuned-xl:0.000 xgb-xl:0.000 xgb-l:0.000 mlp-adaptive-xl:0.000 mlp-l:0.166 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9841, entropy=0.0290, kl_div=0.0000
    Epoch 1: policy_loss=-0.0054, value_loss=0.9841, entropy=0.0299, kl_div=0.0285
  Round 5/5: Mean predicted reward = 14.865

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 94 Results ---
  Mean Oracle Reward: 14.142
  Min Oracle Reward: 8.967
  Max Oracle Reward: 17.153
  Std Oracle Reward: 1.843
  Sequence Diversity: 0.750
  Models Used: 10
  Model R2 - Mean: 0.231, Max: 0.300, Count: 13
  Total Sequences Evaluated: 6066
    Oracle Count: 6016 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 94, 'cumulative_calls': 6016, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 95/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 6066
  Performance plateaued, reducing LR to 0.000150

--- Round 95 Configuration ---
Learning rate: 0.000150
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.734) ---
  AACGTGGGTCCCGGGCTCCA
  TACGGAGCCGGTGACGCCCT
  GCTCAGGCGGCCTCGTCGAA
  AGCCAGAGCGCCGGTTGTCC
  AACCCCGCGGGTTATGGGCC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.077
  Max reward: 17.269
  With intrinsic bonuses: 14.056

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9843, entropy=0.0278, kl_div=0.0000
    Epoch 1: policy_loss=0.0104, value_loss=0.9843, entropy=0.0278, kl_div=0.0018

=== Surrogate Model Training ===
Total samples: 6130

Training on 5912 samples (removed 218 outliers)
Reward range: [9.33, 19.40], mean: 14.53
  Created 13 candidate models for data size 5912
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.210 (std: 0.245)
  rf-tuned-xl: R2 = 0.210 (std: 0.245)
  gb-tuned-l: R2 = 0.257 (std: 0.207)
  gb-tuned-xl: R2 = 0.257 (std: 0.207)
  xgb-xl: R2 = 0.180 (std: 0.239)
  xgb-l: R2 = 0.180 (std: 0.239)
  mlp-adaptive-xl: R2 = 0.251 (std: 0.209)
  mlp-l: R2 = 0.250 (std: 0.204)
  svr-rbf-xl: R2 = 0.281 (std: 0.198)
  svr-poly-l: R2 = 0.281 (std: 0.198)
  knn-tuned-sqrt: R2 = 0.157 (std: 0.228)
  knn-tuned-l: R2 = 0.157 (std: 0.228)
  ridge: R2 = 0.093 (std: 0.257)

Model-based training with 8 models
Best R2: 0.281, Mean R2: 0.213
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.912 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.088 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=5572.1992, entropy=0.0266, kl_div=0.0000
    Epoch 1: policy_loss=-0.0000, value_loss=5572.2021, entropy=0.0259, kl_div=-0.0175
  Round 1/3: Mean predicted reward = -26.904
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.912 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.088 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=0.0264, kl_div=0.0000
    Epoch 1: policy_loss=0.0002, value_loss=0.9842, entropy=0.0279, kl_div=0.0055
  Round 2/3: Mean predicted reward = 15.053
Current Method: dynamic
    Using validation-optimized weights
    Model weights: rf-tuned-l:0.000 rf-tuned-xl:0.912 gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:0.000 mlp-l:0.088 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.0275, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0574
  Round 3/3: Mean predicted reward = 15.173

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 95 Results ---
  Mean Oracle Reward: 14.094
  Min Oracle Reward: 4.608
  Max Oracle Reward: 17.396
  Std Oracle Reward: 2.181
  Sequence Diversity: 0.734
  Models Used: 8
  Model R2 - Mean: 0.213, Max: 0.281, Count: 13
  Total Sequences Evaluated: 6130
    Oracle Count: 6080 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 94, 'cumulative_calls': 6016, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 95, 'cumulative_calls': 6080, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 96/100
======================================================================
Learning Rate: 0.000272
Exploration Rate: 0.050
Total data collected: 6130
  Performance plateaued, reducing LR to 0.000136

--- Round 96 Configuration ---
Learning rate: 0.000136
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.766) ---
  CCACGCTCACGGGATGGTCG
  ACGCGCACGGTCGTACTGCG
  CATTGTGCGCCGGGAGACCC
  CTCTAGTGAGCGCCGGCAGC
  TGGCCGAACTGCACCTGCGG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.993
  Max reward: 17.109
  With intrinsic bonuses: 14.010

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9844, entropy=0.0274, kl_div=0.0000
    Epoch 1: policy_loss=-0.0128, value_loss=0.9844, entropy=0.0272, kl_div=0.0111

=== Surrogate Model Training ===
Total samples: 6194

Training on 5975 samples (removed 219 outliers)
Reward range: [9.33, 19.40], mean: 14.52
  Created 13 candidate models for data size 5975
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.196 (std: 0.227)
  rf-tuned-xl: R2 = 0.195 (std: 0.233)
  gb-tuned-l: R2 = 0.244 (std: 0.194)
  gb-tuned-xl: R2 = 0.244 (std: 0.194)
  xgb-xl: R2 = 0.171 (std: 0.219)
  xgb-l: R2 = 0.171 (std: 0.219)
  mlp-adaptive-xl: R2 = 0.231 (std: 0.195)
  mlp-l: R2 = 0.231 (std: 0.197)
  svr-rbf-xl: R2 = 0.269 (std: 0.198)
  svr-poly-l: R2 = 0.269 (std: 0.198)
  knn-tuned-sqrt: R2 = 0.148 (std: 0.221)
  knn-tuned-l: R2 = 0.148 (std: 0.221)
  ridge: R2 = 0.090 (std: 0.242)

Model-based training with 6 models
Best R2: 0.269, Mean R2: 0.201
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:1.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=3169.4946, entropy=0.0276, kl_div=0.0000
    Epoch 1: policy_loss=-0.0115, value_loss=3169.4966, entropy=0.0276, kl_div=-0.0331
  Round 1/3: Mean predicted reward = -26.124
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:1.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=0.0288, kl_div=0.0000
    Epoch 1: policy_loss=0.0017, value_loss=0.9842, entropy=0.0283, kl_div=0.0379
  Round 2/3: Mean predicted reward = 14.975
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-adaptive-xl:1.000 mlp-l:0.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.0270, kl_div=0.0000
    Epoch 1: policy_loss=-0.0060, value_loss=0.9842, entropy=0.0260, kl_div=0.0320
  Round 3/3: Mean predicted reward = 14.889

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 96 Results ---
  Mean Oracle Reward: 14.015
  Min Oracle Reward: 8.745
  Max Oracle Reward: 17.019
  Std Oracle Reward: 1.576
  Sequence Diversity: 0.766
  Models Used: 6
  Model R2 - Mean: 0.201, Max: 0.269, Count: 13
  Total Sequences Evaluated: 6194
    Oracle Count: 6144 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 94, 'cumulative_calls': 6016, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 95, 'cumulative_calls': 6080, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 96, 'cumulative_calls': 6144, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 97/100
======================================================================
Learning Rate: 0.000200
Exploration Rate: 0.050
Total data collected: 6194
  Performance plateaued, reducing LR to 0.000100

--- Round 97 Configuration ---
Learning rate: 0.000100
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.750) ---
  TCAGGACGCGGTGCCTAGCC
  GGTCTGACCCGACCTAGGGC
  GGTCTCTGCGCCGAACGCAG
  AGTGGCTCCCCGAGTGCACG
  CAGGACTCCCCGGTGCGATG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 13.928
  Max reward: 18.791
  With intrinsic bonuses: 13.906

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=-0.0000, value_loss=0.9843, entropy=0.0247, kl_div=0.0000
    Epoch 1: policy_loss=-0.0451, value_loss=0.9843, entropy=0.0243, kl_div=0.0076

=== Surrogate Model Training ===
Total samples: 6258

Training on 6039 samples (removed 219 outliers)
Reward range: [9.33, 19.40], mean: 14.52
  Created 13 candidate models for data size 6039
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.183 (std: 0.220)
  rf-tuned-xl: R2 = 0.182 (std: 0.222)
  gb-tuned-l: R2 = 0.230 (std: 0.188)
  gb-tuned-xl: R2 = 0.230 (std: 0.188)
  xgb-xl: R2 = 0.157 (std: 0.215)
  xgb-l: R2 = 0.157 (std: 0.215)
  mlp-adaptive-xl: R2 = 0.234 (std: 0.179)
  mlp-l: R2 = 0.222 (std: 0.194)
  svr-rbf-xl: R2 = 0.252 (std: 0.195)
  svr-poly-l: R2 = 0.252 (std: 0.195)
  knn-tuned-sqrt: R2 = 0.153 (std: 0.217)
  knn-tuned-l: R2 = 0.153 (std: 0.217)
  ridge: R2 = 0.086 (std: 0.237)

Model-based training with 6 models
Best R2: 0.252, Mean R2: 0.192
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.301 mlp-adaptive-xl:0.604 mlp-l:0.095 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=5048.3843, entropy=0.0251, kl_div=0.0000
    Epoch 1: policy_loss=0.0232, value_loss=5048.3877, entropy=0.0232, kl_div=0.0213
  Round 1/3: Mean predicted reward = -25.936
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.301 mlp-adaptive-xl:0.604 mlp-l:0.095 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.0203, kl_div=0.0000
    Epoch 1: policy_loss=-0.0037, value_loss=0.9842, entropy=0.0199, kl_div=-0.0032
  Round 2/3: Mean predicted reward = 14.898
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.301 mlp-adaptive-xl:0.604 mlp-l:0.095 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=0.0193, kl_div=0.0000
    Epoch 1: policy_loss=-0.0246, value_loss=0.9842, entropy=0.0192, kl_div=0.0059
  Round 3/3: Mean predicted reward = 14.818

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 97 Results ---
  Mean Oracle Reward: 13.940
  Min Oracle Reward: 9.920
  Max Oracle Reward: 18.803
  Std Oracle Reward: 1.681
  Sequence Diversity: 0.750
  Models Used: 6
  Model R2 - Mean: 0.192, Max: 0.252, Count: 13
  Total Sequences Evaluated: 6258
    Oracle Count: 6208 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 94, 'cumulative_calls': 6016, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 95, 'cumulative_calls': 6080, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 96, 'cumulative_calls': 6144, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 97, 'cumulative_calls': 6208, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 98/100
======================================================================
Learning Rate: 0.000110
Exploration Rate: 0.050
Total data collected: 6258
  Performance plateaued, reducing LR to 0.000055

--- Round 98 Configuration ---
Learning rate: 0.000055
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.719) ---
  CGTCCGGCGCGGATACGATC
  CCCGGAACTTGGCGGTAGCC
  TGGGCCCACAGCCTACGGGT
  TGCGCACGGGCCGATCTCAG
  CGAACGGCTCGCATCTGGCG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.540
  Max reward: 17.634
  With intrinsic bonuses: 14.548

Policy Update:
  Adaptive update: clip_ratio=0.20, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9843, entropy=0.0223, kl_div=0.0000
    Epoch 1: policy_loss=-0.0159, value_loss=0.9843, entropy=0.0219, kl_div=-0.0075

=== Surrogate Model Training ===
Total samples: 6322

Training on 6102 samples (removed 220 outliers)
Reward range: [9.33, 19.39], mean: 14.52
  Created 13 candidate models for data size 6102
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.162 (std: 0.216)
  rf-tuned-xl: R2 = 0.158 (std: 0.217)
  gb-tuned-l: R2 = 0.211 (std: 0.180)
  gb-tuned-xl: R2 = 0.211 (std: 0.180)
  xgb-xl: R2 = 0.138 (std: 0.206)
  xgb-l: R2 = 0.138 (std: 0.206)
  mlp-adaptive-xl: R2 = 0.199 (std: 0.172)
  mlp-l: R2 = 0.218 (std: 0.197)
  svr-rbf-xl: R2 = 0.207 (std: 0.163)
  svr-poly-l: R2 = 0.207 (std: 0.163)
  knn-tuned-sqrt: R2 = 0.137 (std: 0.218)
  knn-tuned-l: R2 = 0.137 (std: 0.218)
  ridge: R2 = 0.077 (std: 0.232)

Model-based training with 5 models
Best R2: 0.218, Mean R2: 0.169
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-l:1.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=3560.0950, entropy=0.0208, kl_div=0.0000
    Epoch 1: policy_loss=0.0032, value_loss=3560.0964, entropy=0.0208, kl_div=-0.0183
  Round 1/3: Mean predicted reward = -33.857
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-l:1.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=0.0213, kl_div=0.0000
    Epoch 1: policy_loss=-0.0015, value_loss=0.9842, entropy=0.0211, kl_div=-0.0057
  Round 2/3: Mean predicted reward = 14.978
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:0.000 gb-tuned-xl:0.000 mlp-l:1.000 svr-rbf-xl:0.000 svr-poly-l:0.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=0.0200, kl_div=0.0000
    Epoch 1: policy_loss=-0.0060, value_loss=0.9842, entropy=0.0199, kl_div=0.0026
  Round 3/3: Mean predicted reward = 14.868

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 98 Results ---
  Mean Oracle Reward: 14.559
  Min Oracle Reward: 10.750
  Max Oracle Reward: 17.752
  Std Oracle Reward: 1.636
  Sequence Diversity: 0.719
  Models Used: 5
  Model R2 - Mean: 0.169, Max: 0.218, Count: 13
  Total Sequences Evaluated: 6322
    Oracle Count: 6272 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 94, 'cumulative_calls': 6016, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 95, 'cumulative_calls': 6080, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 96, 'cumulative_calls': 6144, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 97, 'cumulative_calls': 6208, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 98, 'cumulative_calls': 6272, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 99/100
======================================================================
Learning Rate: 0.000038
Exploration Rate: 0.050
Total data collected: 6322

--- Round 99 Configuration ---
Learning rate: 0.000038
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.703) ---
  AGCCGGGGGATCCCCGTCAT
  CGCATCCGGCGCAGCGATTG
  AGTCCCGGGCCAGAGTCGCT
  CGCCGCCAATGCTCGGGGAT
  GTGCACCTGACCGGACGCTG
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.394
  Max reward: 17.569
  With intrinsic bonuses: 14.427

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9843, entropy=0.0211, kl_div=0.0000
    Epoch 1: policy_loss=-0.0138, value_loss=0.9843, entropy=0.0211, kl_div=-0.0026

=== Surrogate Model Training ===
Total samples: 6386

Training on 6165 samples (removed 221 outliers)
Reward range: [9.33, 19.40], mean: 14.52
  Created 13 candidate models for data size 6165
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.153 (std: 0.208)
  rf-tuned-xl: R2 = 0.152 (std: 0.207)
  gb-tuned-l: R2 = 0.196 (std: 0.172)
  gb-tuned-xl: R2 = 0.196 (std: 0.172)
  xgb-xl: R2 = 0.136 (std: 0.188)
  xgb-l: R2 = 0.136 (std: 0.188)
  mlp-adaptive-xl: R2 = 0.185 (std: 0.171)
  mlp-l: R2 = 0.190 (std: 0.165)
  svr-rbf-xl: R2 = 0.171 (std: 0.137)
  svr-poly-l: R2 = 0.171 (std: 0.137)
  knn-tuned-sqrt: R2 = 0.142 (std: 0.214)
  knn-tuned-l: R2 = 0.142 (std: 0.214)
  ridge: R2 = 0.070 (std: 0.219)
  Fallback: Using gb-tuned-l with R2 = 0.196

Model-based training with 1 models
Best R2: 0.196, Mean R2: 0.157
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=13010.5996, entropy=0.0198, kl_div=0.0000
    Epoch 1: policy_loss=-0.0150, value_loss=13010.6006, entropy=0.0192, kl_div=0.0000
  Round 1/3: Mean predicted reward = -37.139
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=0.0179, kl_div=0.0000
    Epoch 1: policy_loss=0.0050, value_loss=0.9842, entropy=0.0178, kl_div=-0.0002
  Round 2/3: Mean predicted reward = 15.014
Current Method: dynamic
    Using validation-optimized weights
    Model weights: gb-tuned-l:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=0.9842, entropy=0.0202, kl_div=0.0000
    Epoch 1: policy_loss=-0.0032, value_loss=0.9842, entropy=0.0201, kl_div=0.0005
  Round 3/3: Mean predicted reward = 14.985

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 99 Results ---
  Mean Oracle Reward: 14.418
  Min Oracle Reward: 7.786
  Max Oracle Reward: 17.243
  Std Oracle Reward: 1.977
  Sequence Diversity: 0.703
  Models Used: 1
  Model R2 - Mean: 0.157, Max: 0.196, Count: 13
  Total Sequences Evaluated: 6386
    Oracle Count: 6336 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 94, 'cumulative_calls': 6016, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 95, 'cumulative_calls': 6080, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 96, 'cumulative_calls': 6144, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 97, 'cumulative_calls': 6208, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 98, 'cumulative_calls': 6272, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 99, 'cumulative_calls': 6336, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
EXPERIMENT ROUND 100/100
======================================================================
Learning Rate: 0.000300
Exploration Rate: 0.050
Total data collected: 6386

--- Round 100 Configuration ---
Learning rate: 0.000300
Entropy coefficient: 0.0050
Exploration rate: 0.050

--- Generated Sequences (Diversity: 0.703) ---
  TTGGCTAGGACCGGCCCAGC
  CTGCCTGACCCCGGAAGTGG
  GCTGACCGCAGGGCCGACTT
  GCGAGCCGAGTCCCGGATTC
  GGGTGCGTGCTCCGACCAAC
  ... (64 total)

Oracle Evaluation:
  Mean reward: 14.779
  Max reward: 18.460
  With intrinsic bonuses: 14.739

Policy Update:
  Adaptive update: clip_ratio=0.10, entropy_coef=0.005
    Epoch 0: policy_loss=0.0000, value_loss=0.9843, entropy=0.0192, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0974

=== Surrogate Model Training ===
Total samples: 6450

Training on 6227 samples (removed 223 outliers)
Reward range: [9.33, 19.40], mean: 14.52
  Created 13 candidate models for data size 6227
Current R2 threshold: 0.2
  rf-tuned-l: R2 = 0.129 (std: 0.208)
  rf-tuned-xl: R2 = 0.129 (std: 0.204)
  gb-tuned-l: R2 = 0.173 (std: 0.165)
  gb-tuned-xl: R2 = 0.173 (std: 0.165)
  xgb-xl: R2 = 0.105 (std: 0.196)
  xgb-l: R2 = 0.105 (std: 0.196)
  mlp-adaptive-xl: R2 = 0.175 (std: 0.171)
  mlp-l: R2 = 0.196 (std: 0.181)
  svr-rbf-xl: R2 = 0.148 (std: 0.146)
  svr-poly-l: R2 = 0.148 (std: 0.146)
  knn-tuned-sqrt: R2 = 0.138 (std: 0.235)
  knn-tuned-l: R2 = 0.138 (std: 0.235)
  ridge: R2 = 0.056 (std: 0.214)
  Fallback: Using mlp-l with R2 = 0.196

Model-based training with 1 models
Best R2: 0.196, Mean R2: 0.140
Running 3 virtual training rounds
Current Method: dynamic
    Using validation-optimized weights
    Model weights: mlp-l:1.000 
  Adaptive update: clip_ratio=0.10, entropy_coef=0.003
    Epoch 0: policy_loss=0.0000, value_loss=3371.9919, entropy=0.0171, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.1725
  Round 1/3: Mean predicted reward = -32.203
Current Method: dynamic
    Using validation-optimized weights
    Model weights: mlp-l:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9842, entropy=0.0224, kl_div=0.0000
    Early stopping at epoch 1: KL divergence = 0.0548
  Round 2/3: Mean predicted reward = 14.746
Current Method: dynamic
    Using validation-optimized weights
    Model weights: mlp-l:1.000 
  Adaptive update: clip_ratio=0.20, entropy_coef=0.003
    Epoch 0: policy_loss=-0.0000, value_loss=0.9843, entropy=0.0174, kl_div=0.0000
    Epoch 1: policy_loss=0.6445, value_loss=0.9843, entropy=0.0156, kl_div=-0.2805
  Round 3/3: Mean predicted reward = 14.713

  === Progress Analysis ===
  Status: NORMAL
  • Reward trend declining. Consider resetting exploration parameters.

--- Round 100 Results ---
  Mean Oracle Reward: 14.766
  Min Oracle Reward: 8.508
  Max Oracle Reward: 18.501
  Std Oracle Reward: 2.097
  Sequence Diversity: 0.703
  Models Used: 1
  Model R2 - Mean: 0.140, Max: 0.196, Count: 13
  Total Sequences Evaluated: 6450
    Oracle Count: 6400 [{'round': 1, 'cumulative_calls': 64, 'new_calls': 64, 'best_reward_so_far': 16.930293639727388}, {'round': 2, 'cumulative_calls': 128, 'new_calls': 64, 'best_reward_so_far': 16.966627430391956}, {'round': 3, 'cumulative_calls': 192, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 4, 'cumulative_calls': 256, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 5, 'cumulative_calls': 320, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 6, 'cumulative_calls': 384, 'new_calls': 64, 'best_reward_so_far': 18.606706988388876}, {'round': 7, 'cumulative_calls': 448, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 8, 'cumulative_calls': 512, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 9, 'cumulative_calls': 576, 'new_calls': 64, 'best_reward_so_far': 19.17522332984715}, {'round': 10, 'cumulative_calls': 640, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 11, 'cumulative_calls': 704, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 12, 'cumulative_calls': 768, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 13, 'cumulative_calls': 832, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 14, 'cumulative_calls': 896, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 15, 'cumulative_calls': 960, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 16, 'cumulative_calls': 1024, 'new_calls': 64, 'best_reward_so_far': 19.513648942053294}, {'round': 17, 'cumulative_calls': 1088, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 18, 'cumulative_calls': 1152, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 19, 'cumulative_calls': 1216, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 20, 'cumulative_calls': 1280, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 21, 'cumulative_calls': 1344, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 22, 'cumulative_calls': 1408, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 23, 'cumulative_calls': 1472, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 24, 'cumulative_calls': 1536, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 25, 'cumulative_calls': 1600, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 26, 'cumulative_calls': 1664, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 27, 'cumulative_calls': 1728, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 28, 'cumulative_calls': 1792, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 29, 'cumulative_calls': 1856, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 30, 'cumulative_calls': 1920, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 31, 'cumulative_calls': 1984, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 32, 'cumulative_calls': 2048, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 33, 'cumulative_calls': 2112, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 34, 'cumulative_calls': 2176, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 35, 'cumulative_calls': 2240, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 36, 'cumulative_calls': 2304, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 37, 'cumulative_calls': 2368, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 38, 'cumulative_calls': 2432, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 39, 'cumulative_calls': 2496, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 40, 'cumulative_calls': 2560, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 41, 'cumulative_calls': 2624, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 42, 'cumulative_calls': 2688, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 43, 'cumulative_calls': 2752, 'new_calls': 64, 'best_reward_so_far': 20.487631943066646}, {'round': 44, 'cumulative_calls': 2816, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 45, 'cumulative_calls': 2880, 'new_calls': 64, 'best_reward_so_far': 20.979442649892313}, {'round': 46, 'cumulative_calls': 2944, 'new_calls': 64, 'best_reward_so_far': 21.248505381164243}, {'round': 47, 'cumulative_calls': 3008, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 48, 'cumulative_calls': 3072, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 49, 'cumulative_calls': 3136, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 50, 'cumulative_calls': 3200, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 51, 'cumulative_calls': 3264, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 52, 'cumulative_calls': 3328, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 53, 'cumulative_calls': 3392, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 54, 'cumulative_calls': 3456, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 55, 'cumulative_calls': 3520, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 56, 'cumulative_calls': 3584, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 57, 'cumulative_calls': 3648, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 58, 'cumulative_calls': 3712, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 59, 'cumulative_calls': 3776, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 60, 'cumulative_calls': 3840, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 61, 'cumulative_calls': 3904, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 62, 'cumulative_calls': 3968, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 63, 'cumulative_calls': 4032, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 64, 'cumulative_calls': 4096, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 65, 'cumulative_calls': 4160, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 66, 'cumulative_calls': 4224, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 67, 'cumulative_calls': 4288, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 68, 'cumulative_calls': 4352, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 69, 'cumulative_calls': 4416, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 70, 'cumulative_calls': 4480, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 71, 'cumulative_calls': 4544, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 72, 'cumulative_calls': 4608, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 73, 'cumulative_calls': 4672, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 74, 'cumulative_calls': 4736, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 75, 'cumulative_calls': 4800, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 76, 'cumulative_calls': 4864, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 77, 'cumulative_calls': 4928, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 78, 'cumulative_calls': 4992, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 79, 'cumulative_calls': 5056, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 80, 'cumulative_calls': 5120, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 81, 'cumulative_calls': 5184, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 82, 'cumulative_calls': 5248, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 83, 'cumulative_calls': 5312, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 84, 'cumulative_calls': 5376, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 85, 'cumulative_calls': 5440, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 86, 'cumulative_calls': 5504, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 87, 'cumulative_calls': 5568, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 88, 'cumulative_calls': 5632, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 89, 'cumulative_calls': 5696, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 90, 'cumulative_calls': 5760, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 91, 'cumulative_calls': 5824, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 92, 'cumulative_calls': 5888, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 93, 'cumulative_calls': 5952, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 94, 'cumulative_calls': 6016, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 95, 'cumulative_calls': 6080, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 96, 'cumulative_calls': 6144, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 97, 'cumulative_calls': 6208, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 98, 'cumulative_calls': 6272, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 99, 'cumulative_calls': 6336, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}, {'round': 100, 'cumulative_calls': 6400, 'new_calls': 64, 'best_reward_so_far': 21.49594166547982}]

======================================================================
DyNA PPO ALGORITHM COMPLETE! Time used 7305.54 seconds
======================================================================
Total rounds executed: 100
Total sequences evaluated: 6450
Best mean reward: 15.944 (achieved at round 47)

==================================================
TRAINING SUMMARY
==================================================
Total Rounds: 100
Final Mean Reward: 14.7658
Best Mean Reward: 15.9443
Best Max Reward: 21.2994
Initial Lr: 0.0003
Final Lr: 0.0003
Total Updates: 580
Final Diversity: 0.7031
Convergence Round: 5
==================================================

Generating learning curves...
Learning curves saved to experiments/20250924212213_r100_b64_l20_dynamic_dynamic/metrices_plot_dynamic_r100_b64_l20.png
Saving training metrics...
Metrics saved to experiments/20250924212213_r100_b64_l20_dynamic_dynamic/metrices_data_dynamic_r100_b64_l20.json

======================================================================
FINAL OPTIMIZED SEQUENCES
======================================================================

Deterministic (Exploitation):
  GGGGGCCGGCCGGCCGGCCG: 19.093
  GGGGGCCGGCCGGCCGGCCG: 19.176
  GGGGGCCGGCCGGCCGGCCG: 19.059
  GGGGGCCGGCCGGCCGGCCG: 18.843
  GGGGGCCGGCCGGCCGGCCG: 18.949

Stochastic (Exploration):
  GGGGGCCGGCCGGCCGGCCG: 19.005
  GGGGGCCGGCCGGCCGGCCG: 19.061
  GGGGGCCGGGCCGGCCGGCC: 18.503
  GGGGGCCGGCCGGCCGGCCG: 19.134
  GGGGGCCGGGCCGGCCGGCC: 18.505

Final Performance:
  Mean reward: 18.933
  Max reward: 19.176
  Std reward: 0.232

Best sequence found: GGGGGCCGGCCGGCCGGCCG
   Reward: 19.176

======================================================================
Training complete! Check 'learning_curves.png' and 'training_metrics.json'
======================================================================

=== Model Weight Evolution Analysis ===
Model evolution plot saved to experiments/20250924212213_r100_b64_l20_dynamic_dynamic/model_evolution_r100_b64_l20.png

=== Model Performance Summary ===

Final weight distribution (Round 100):
  mlp: 3.000

Overall model importance (average weight across all rounds):
  svr: 1.203
  rf: 0.873
  gb: 0.348
  mlp: 0.328
  knn: 0.152
  xgb: 0.150
  ridge: 0.106
Detailed performance data saved to model_performance_details.csv
